---
id: context-engineering
sidebar_position: 1
title: Context Engineering æ·±åº¦è°ƒç ”æŠ¥å‘Š
last_update:
  author: Aurelius
  date: 2025-12-22
  version: 1.1
  status: å¾…å®¡é˜…
tags:
  - Context Engineering
  - å­¦æœ¯è®ºæ–‡
  - ä¸»æµæ¡†æ¶
---

## 1. æ‰§è¡Œæ‘˜è¦

**Context Engineeringï¼ˆä¸Šä¸‹æ–‡å·¥ç¨‹ï¼‰** æ˜¯æ„å»ºå¯é ã€å¯æ‰©å±• AI Agent ç³»ç»Ÿçš„æ ¸å¿ƒå­¦ç§‘ã€‚å®ƒä»ä¼ ç»Ÿçš„"å†™ Prompt"æ¼”è¿›ä¸º**ç³»ç»Ÿæ€§åœ°è®¾è®¡å’Œä¼˜åŒ– AI ç³»ç»Ÿè¿è¡Œæ—¶æ‰€éœ€çš„æ•´ä¸ªåŠ¨æ€ä¿¡æ¯ç”Ÿæ€ç³»ç»Ÿ**â€”â€”æ¶µç›–ä¸Šä¸‹æ–‡çš„æ”¶é›†ï¼ˆCollectionï¼‰ã€ç®¡ç†ï¼ˆManagementï¼‰å’Œä½¿ç”¨ï¼ˆUsageï¼‰ã€‚

æœ¬æŠ¥å‘ŠåŸºäºï¼š

- **å­¦æœ¯è®ºæ–‡**ï¼šã€ŠContext Engineering 2.0: The Context of Context Engineeringã€‹[1] å’Œ ã€ŠUnderstanding and Using Contextã€‹[2]
- **ä¸»æµæ¡†æ¶æ–‡æ¡£**ï¼šGoogle ADK [3-6]ã€Agno [7-10]ã€LangGraph [11-12]

> [!IMPORTANT] > **æ ¸å¿ƒæ´å¯Ÿ**ï¼šContext Engineering ä¸ä»…ä»…æ˜¯ Prompt è®¾è®¡ï¼Œæ›´æ˜¯ä¸€ä¸ªæ¶µç›–**è®°å¿†ç³»ç»Ÿï¼ˆMemoryï¼‰ã€ä¼šè¯ç®¡ç†ï¼ˆSessionï¼‰ã€çŠ¶æ€æŒä¹…åŒ–ï¼ˆPersistenceï¼‰ã€çŸ¥è¯†æ£€ç´¢ï¼ˆRAGï¼‰**çš„å®Œæ•´æ¶æ„é—®é¢˜ã€‚å¯¹äº Agentic AI Engine é¡¹ç›®è€Œè¨€ï¼ŒOceanBase çš„ç»Ÿä¸€å­˜å‚¨æ¶æ„éœ€è¦åŒæ—¶è§£å†³è¿™äº›æŒ‘æˆ˜ã€‚

---

## 2. Context Engineering çš„æ¼”è¿›ä¸å®šä¹‰

### 2.1 å†å²å›é¡¾ï¼šä» HCI åˆ° HAI

Context Engineering å¹¶é Agent æ—¶ä»£çš„æ–°å‘æ˜ã€‚æ ¹æ® Dey (2001) çš„å¼€åˆ›æ€§å·¥ä½œ [2]ï¼Œæ—©åœ¨ 2000 å¹´ä»£åˆæœŸï¼Œç ”ç©¶è€…å°±å·²ç»åœ¨æ¢ç´¢"ä¸Šä¸‹æ–‡æ„ŸçŸ¥è®¡ç®—"ï¼ˆContext-Aware Computingï¼‰ã€‚

> "Context is a poorly used source of information in our computing environments. As a result, we have an impoverished understanding of what context is and how it can be used." â€” Dey [2]

**Dey çš„å®šä¹‰ (2001)** [2]ï¼š

> **Context** is any information that can be used to characterize the situation of an entity. An entity is a person, place, or object that is considered relevant to the interaction between a user and an application, including the user and applications themselves.

**SII-GAIR è®ºæ–‡çš„å®šä¹‰ (2025)** [1]ï¼š

$$C = \bigcup_{e \in E_{rel}} Char(e)$$

å…¶ä¸­ï¼š

- $E_{rel} \subseteq E$ æ˜¯ä¸äº¤äº’ç›¸å…³çš„å®ä½“é›†åˆ
- $Char(e)$ è¿”å›æè¿°å®ä½“ $e$ çš„ä¿¡æ¯é›†åˆ

**Context Engineering å®šä¹‰** [1]ï¼š

$$CE: (C, T) \rightarrow f_{context}$$

å…¶ä¸­ $f_{context}(C) = F(\phi_1, \phi_2, \ldots, \phi_n)(C)$ï¼Œ$F$ æ˜¯ç»„åˆå„ç§ä¸Šä¸‹æ–‡å·¥ç¨‹æ“ä½œ $\phi_i$ çš„å‡½æ•°ã€‚

### 2.2 å‘å±•é˜¶æ®µ

è®ºæ–‡ [1] å°† Context Engineering åˆ’åˆ†ä¸ºå››ä¸ªæ—¶ä»£ï¼š

```mermaid
gantt
    title Context Engineering å‘å±•æ—¶ä»£
    dateFormat YYYY
    section Era 1.0
    åŸå§‹è®¡ç®—æ—¶ä»£ (åˆšæ€§/é¢„å®šä¹‰æ ¼å¼) :done, 1990, 2020
    section Era 2.0
    Agent-Centric æ—¶ä»£ (è‡ªç„¶è¯­è¨€/åŠ¨æ€ä¸Šä¸‹æ–‡) :active, 2020, 2030
    section Era 3.0
    Human-Level æ™ºèƒ½ (æ·±åº¦æ„å›¾ç†è§£) :2030, 2040
    section Era 4.0
    Superhuman æ™ºèƒ½ (äººæœºè§’è‰²åè½¬) :2040, 2050
```

| æ—¶ä»£        | æ—¶é—´èŒƒå›´   | æ™ºèƒ½æ°´å¹³      | Context Engineering ç‰¹å¾                    |
| :---------- | :--------- | :------------ | :------------------------------------------ |
| **Era 1.0** | 1990s-2020 | åŸå§‹è®¡ç®—      | åˆšæ€§ã€é¢„å®šä¹‰æ ¼å¼ï¼ˆèœå•é€‰æ‹©ã€ä¼ æ„Ÿå™¨è¾“å…¥ï¼‰[1] |
| **Era 2.0** | 2020-è‡³ä»Š  | Agent-Centric | è‡ªç„¶è¯­è¨€ç†è§£ã€æ¨æ–­éšå«æ„å›¾ã€åŠ¨æ€ä¸Šä¸‹æ–‡ [1]  |
| Era 3.0     | æœªæ¥       | Human-Level   | æ·±åº¦æ„å›¾ç†è§£ã€æœ€å°æ˜¾å¼ä¸Šä¸‹æ–‡éœ€æ±‚ [1]        |
| Era 4.0     | é¥è¿œæœªæ¥   | Superhuman    | æœºå™¨å¼•å¯¼äººç±»ã€äººæœºè§’è‰²åè½¬ [1]              |

> [!NOTE]
> æˆ‘ä»¬å½“å‰å¤„äº **Era 2.0**ï¼Œæ ¸å¿ƒæŒ‘æˆ˜æ˜¯è®© Agent èƒ½å¤Ÿï¼š(1) ç†è§£è‡ªç„¶è¯­è¨€è¾“å…¥ï¼›(2) æ¨æ–­éšå«æ„å›¾ï¼›(3) å¤„ç†ä¸å®Œæ•´ä¿¡æ¯ï¼›(4) åœ¨æœ‰é™çš„ Context Window ä¸­åšå‡ºæœ€ä¼˜é€‰æ‹© [1]ã€‚

### 2.3 æœ¬é¡¹ç›®å®è·µï¼šç»Ÿä¸€å®šä¹‰

```python
# Agentic AI Engine é¡¹ç›®çš„ Context å®šä¹‰
from dataclasses import dataclass
from typing import Dict, List, Optional
from enum import Enum

class ContextScope(Enum):
    """ä¸Šä¸‹æ–‡ä½œç”¨åŸŸ"""
    INVOCATION = "invocation"  # å•æ¬¡è°ƒç”¨
    SESSION = "session"        # ä¼šè¯çº§åˆ«
    USER = "user"              # ç”¨æˆ·çº§åˆ«
    APP = "app"                # åº”ç”¨çº§åˆ«

@dataclass
class Context:
    """ç»Ÿä¸€ä¸Šä¸‹æ–‡æ•°æ®ç»“æ„"""
    # ç³»ç»ŸæŒ‡ä»¤
    system_instruction: str
    # ç”¨æˆ·è¾“å…¥
    user_message: str
    # å¯¹è¯å†å²ï¼ˆçŸ­æœŸè®°å¿†ï¼‰
    chat_history: List[Dict]
    # é•¿æœŸè®°å¿†
    memories: List[Dict]
    # æ£€ç´¢åˆ°çš„çŸ¥è¯†ï¼ˆRAGï¼‰
    knowledge: List[Dict]
    # å·¥å…·å®šä¹‰
    tools: List[Dict]
    # çŠ¶æ€
    state: Dict
    # ä½œç”¨åŸŸ
    scope: ContextScope
```

---

## 3. Context Engineering ä¸‰å¤§æ”¯æŸ±

æ ¹æ®è®ºæ–‡ [1] å’Œä¸»æµæ¡†æ¶å®è·µï¼ŒContext Engineering å¯åˆ†è§£ä¸ºä¸‰å¤§æ ¸å¿ƒç»´åº¦ï¼š

```mermaid
graph TB
    subgraph CE["ğŸ§  Context Engineering"]
        CC["ğŸ“¥ Collection<br>ä¸Šä¸‹æ–‡æ”¶é›†"]
        CM["ğŸ“¦ Management<br>ä¸Šä¸‹æ–‡ç®¡ç†"]
        CU["ğŸ” Usage<br>ä¸Šä¸‹æ–‡ä½¿ç”¨"]
    end

    CC --> CC1["ç”¨æˆ·è¾“å…¥"]
    CC --> CC2["ç³»ç»ŸæŒ‡ä»¤"]
    CC --> CC3["å¯¹è¯å†å²"]
    CC --> CC4["å¤–éƒ¨æ•°æ®/RAG"]
    CC --> CC5["å·¥å…·å®šä¹‰"]

    CM --> CM1["åˆ†å±‚è®°å¿†æ¶æ„"]
    CM --> CM2["ä¸Šä¸‹æ–‡å‹ç¼©"]
    CM --> CM3["ä¸Šä¸‹æ–‡éš”ç¦»"]
    CM --> CM4["æŒä¹…åŒ–å­˜å‚¨"]

    CU --> CU1["è¯­ä¹‰æ£€ç´¢"]
    CU --> CU2["æ„å›¾æ¨æ–­"]
    CU --> CU3["åŠ¨æ€ç»„è£…"]

    style CE fill:#1e3a5f,stroke:#60a5fa,color:#fff
    style CC fill:#065f46,stroke:#34d399,color:#fff
    style CM fill:#7c2d12,stroke:#fb923c,color:#fff
    style CU fill:#581c87,stroke:#c084fc,color:#fff
```

---

## 4. Context Collectionï¼ˆä¸Šä¸‹æ–‡æ”¶é›†ï¼‰

### 4.1 æ ¸å¿ƒæ¦‚å¿µ

ä¸Šä¸‹æ–‡æ”¶é›†æ˜¯æŒ‡ä»å„ç§æ¥æºè·å– Agent è¿è¡Œæ‰€éœ€çš„ä¿¡æ¯ã€‚è®ºæ–‡ [1] æŒ‡å‡ºï¼š

> "Context engineering aims to **collect** relevant context information through sensors or other channels."

### 4.2 å„æ¡†æ¶çš„æ”¶é›†ç­–ç•¥

#### 4.2.1 Google ADK

Google ADK å°†ä¸Šä¸‹æ–‡æ”¶é›†æŠ½è±¡ä¸ºå¤šä¸ªå±‚æ¬¡çš„ Context å¯¹è±¡ [3]ï¼š

| Context ç±»å‹          | æè¿°                         | å¯è®¿é—®ä½ç½®                 |
| :-------------------- | :--------------------------- | :------------------------- |
| **InvocationContext** | å®Œæ•´è°ƒç”¨ä¸Šä¸‹æ–‡ï¼ŒåŒ…å«æ‰€æœ‰ä¿¡æ¯ | Agent çš„ `_run_async_impl` |
| **CallbackContext**   | å›è°ƒä¸­çš„åªè¯»ä¸Šä¸‹æ–‡           | Agent/Model å›è°ƒ           |
| **ToolContext**       | å·¥å…·æ‰§è¡Œæ—¶çš„å¯å†™ä¸Šä¸‹æ–‡       | Function Tools             |
| **ReadonlyContext**   | åªè¯»ä¸Šä¸‹æ–‡ï¼Œç”¨äºè¡¨è¾¾å¼è¯„ä¼°   | Agent Config è¡¨è¾¾å¼        |

```python
# Google ADK ä¸Šä¸‹æ–‡æ”¶é›†ç¤ºä¾‹ [4]
from google.adk.agents import Agent
from google.adk.agents.callback_context import CallbackContext

class MyAgent(Agent):
    async def _run_async_impl(self, ctx):
        # ä» InvocationContext æ”¶é›†å„ç±»ä¿¡æ¯
        session = ctx.session                    # ä¼šè¯
        state = ctx.session.state                # ä¼šè¯çŠ¶æ€
        user_content = ctx.user_content          # ç”¨æˆ·è¾“å…¥
        agent = ctx.agent                        # Agent é…ç½®

        # ä» Memory Service æ£€ç´¢é•¿æœŸè®°å¿†
        if ctx.memory_service:
            memories = await ctx.memory_service.search_memory(
                query=user_content.parts[0].text
            )
```

#### 4.2.2 Agno

Agno çš„ä¸Šä¸‹æ–‡æ”¶é›†åŸºäº Agent å‚æ•°é…ç½® [7]ï¼š

| ç»„ä»¶                   | æè¿°                                   | é…ç½®æ–¹å¼                      |
| :--------------------- | :------------------------------------- | :---------------------------- |
| **System Message**     | ä¸»ä¸Šä¸‹æ–‡ï¼ˆdescription + instructionsï¼‰ | Agent æ„é€ å‚æ•°                |
| **User Message**       | ç”¨æˆ·è¾“å…¥                               | `Agent.run(input)`            |
| **Chat History**       | å¯¹è¯å†å²                               | `add_history_to_context=True` |
| **Additional Context** | Few-shot ç¤ºä¾‹ç­‰                        | `additional_context` å‚æ•°     |
| **Memory**             | é•¿æœŸè®°å¿†                               | `enable_user_memories=True`   |
| **Knowledge**          | å¤–éƒ¨çŸ¥è¯†åº“                             | `knowledge` å‚æ•°              |

```python
# Agno ä¸Šä¸‹æ–‡æ”¶é›†ç¤ºä¾‹ [7][8]
from agno.agent import Agent

agent = Agent(
    name="Helpful Assistant",
    description="You are a helpful assistant",
    instructions=["Help the user with their question"],

    # Context å¢å¼ºé€‰é¡¹
    add_datetime_to_context=True,
    add_location_to_context=True,
    add_name_to_context=True,
    add_session_summary_to_context=True,  # æ·»åŠ å†å²æ‘˜è¦
    add_memories_to_context=True,          # æ·»åŠ é•¿æœŸè®°å¿†
    add_session_state_to_context=True,     # æ·»åŠ ä¼šè¯çŠ¶æ€

    # å¤–éƒ¨çŸ¥è¯†
    knowledge=my_knowledge_base,
)
```

#### 4.2.3 LangGraph

LangGraph é€šè¿‡ State å’Œ Config æ”¶é›†ä¸Šä¸‹æ–‡ [11][12]ï¼š

```python
# LangGraph ä¸Šä¸‹æ–‡æ”¶é›†ç¤ºä¾‹ [12]
from langgraph.graph import StateGraph, MessagesState

def my_node(state: MessagesState, config, *, store):
    # ä» state è·å–æ¶ˆæ¯å†å²
    messages = state["messages"]

    # ä» config è·å–ç”¨æˆ·æ ‡è¯†
    user_id = config["configurable"]["user_id"]
    thread_id = config["configurable"]["thread_id"]

    # ä» store æ£€ç´¢é•¿æœŸè®°å¿†
    namespace = (user_id, "memories")
    memories = store.search(namespace, query=messages[-1].content)

    return {"messages": [...]}
```

### 4.3 æœ¬é¡¹ç›®å®è·µï¼šç»Ÿä¸€æ”¶é›†å™¨

```python
# Agentic AI Engine - ç»Ÿä¸€ä¸Šä¸‹æ–‡æ”¶é›†å™¨
from typing import List, Dict, Optional
from dataclasses import dataclass

@dataclass
class CollectionConfig:
    """æ”¶é›†é…ç½®"""
    include_system_instruction: bool = True
    include_chat_history: bool = True
    max_history_turns: int = 10
    include_memories: bool = True
    max_memories: int = 5
    include_knowledge: bool = True
    max_knowledge_chunks: int = 3

class ContextCollector:
    """ç»Ÿä¸€ä¸Šä¸‹æ–‡æ”¶é›†å™¨"""

    def __init__(
        self,
        session_service,      # ä¼šè¯æœåŠ¡
        memory_service,       # è®°å¿†æœåŠ¡
        knowledge_service,    # çŸ¥è¯†æœåŠ¡
        config: CollectionConfig = None
    ):
        self.session_service = session_service
        self.memory_service = memory_service
        self.knowledge_service = knowledge_service
        self.config = config or CollectionConfig()

    async def collect(
        self,
        user_id: str,
        session_id: str,
        user_message: str,
        agent_config: Dict
    ) -> Context:
        """æ”¶é›†å®Œæ•´ä¸Šä¸‹æ–‡"""

        # 1. ç³»ç»ŸæŒ‡ä»¤ï¼ˆæ¥è‡ª Agent é…ç½®ï¼‰
        system_instruction = agent_config.get("system_instruction", "")

        # 2. å¯¹è¯å†å²ï¼ˆçŸ­æœŸè®°å¿†ï¼‰
        chat_history = []
        if self.config.include_chat_history:
            session = await self.session_service.get_session(
                user_id=user_id,
                session_id=session_id
            )
            chat_history = session.events[-self.config.max_history_turns:]

        # 3. é•¿æœŸè®°å¿†
        memories = []
        if self.config.include_memories:
            memories = await self.memory_service.search_memory(
                user_id=user_id,
                query=user_message,
                limit=self.config.max_memories
            )

        # 4. çŸ¥è¯†æ£€ç´¢ (RAG)
        knowledge = []
        if self.config.include_knowledge:
            knowledge = await self.knowledge_service.search(
                query=user_message,
                limit=self.config.max_knowledge_chunks
            )

        return Context(
            system_instruction=system_instruction,
            user_message=user_message,
            chat_history=chat_history,
            memories=memories,
            knowledge=knowledge,
            tools=agent_config.get("tools", []),
            state=session.state if session else {},
            scope=ContextScope.SESSION
        )
```

---

## 5. Context Managementï¼ˆä¸Šä¸‹æ–‡ç®¡ç†ï¼‰

### 5.1 åˆ†å±‚è®°å¿†æ¶æ„

è®ºæ–‡ [1] æå‡ºäº†å…³é”®çš„è®°å¿†åˆ†å±‚æ¨¡å‹ï¼Œè¿™ä¸å„æ¡†æ¶çš„è®¾è®¡é«˜åº¦ä¸€è‡´ï¼š

#### 5.1.1 çŸ­æœŸè®°å¿† (Short-term Memory)

**å®šä¹‰** [1]ï¼š

$$M_s = f_{short}(c \in C : w_{temporal}(c) > \theta_s)$$

- é«˜æ—¶é—´ç›¸å…³æ€§
- å¿«é€Ÿæ£€ç´¢ï¼Œä½†å¯èƒ½å¿«é€Ÿå˜å¾—ä¸ç›¸å…³
- å¯¹åº”å„æ¡†æ¶çš„**å¯¹è¯å†å² (Chat History)** å’Œ **ä¼šè¯çŠ¶æ€ (Session State)**

#### 5.1.2 é•¿æœŸè®°å¿† (Long-term Memory)

**å®šä¹‰** [1]ï¼š

$$M_l = f_{long}(c \in C : w_{importance}(c) > \theta_l \land w_{temporal}(c) \leq \theta_s)$$

- é«˜é‡è¦æ€§
- ç»è¿‡æŠ½è±¡å’Œå‹ç¼©å¤„ç†
- å¯¹åº”å„æ¡†æ¶çš„ **Memory Service**

#### 5.1.3 è®°å¿†è¿ç§» (Memory Transfer)

**å®šä¹‰** [1]ï¼š

$$f_{transfer}: M_s \rightarrow M_l$$

å·©å›ºè¿‡ç¨‹ï¼šé«˜é¢‘è®¿é—®æˆ–é«˜é‡è¦æ€§çš„çŸ­æœŸè®°å¿†ç»å¤„ç†åæˆä¸ºé•¿æœŸè®°å¿†ã€‚

### 5.2 å„æ¡†æ¶çš„è®°å¿†å®ç°

#### 5.2.1 Google ADK è®°å¿†ä½“ç³»

```mermaid
graph TD
    subgraph ADK["Google ADK è®°å¿†ä½“ç³»"]
        IC[InvocationContext] --> S[Session]
        IC --> ST[State]
        IC --> M[Memory]

        S --> SE["Events<br>æ—¶é—´åºåˆ—æ¶ˆæ¯"]
        S --> SS["session.state<br>ä¼šè¯çº§ä¸´æ—¶æ•°æ®"]

        ST --> ST1["æ— å‰ç¼€: Session Scope"]
        ST --> ST2["user: User Scope"]
        ST --> ST3["app: App Scope"]
        ST --> ST4["temp: Invocation Scope"]

        M --> MM[MemoryService]
        MM --> MM1[InMemoryMemoryService]
        MM --> MM2[VertexAiMemoryBankService]
    end

    style ADK fill:#1e3a5f,stroke:#60a5fa,color:#fff
    style IC fill:#065f46,stroke:#34d399,color:#fff
    style MM fill:#7c2d12,stroke:#fb923c,color:#fff
```

**State å‰ç¼€ç³»ç»Ÿ** [5]ï¼š

| å‰ç¼€    | ä½œç”¨åŸŸ               | æŒä¹…æ€§                 | ç”¨ä¾‹               |
| :------ | :------------------- | :--------------------- | :----------------- |
| æ— å‰ç¼€  | å½“å‰ Session         | å–å†³äº SessionService  | ä»»åŠ¡è¿›åº¦ã€ä¸´æ—¶æ ‡å¿— |
| `user:` | è·¨è¯¥ç”¨æˆ·æ‰€æœ‰ Session | Database/VertexAI æŒä¹… | ç”¨æˆ·åå¥½ã€é…ç½®     |
| `app:`  | è·¨è¯¥åº”ç”¨æ‰€æœ‰ç”¨æˆ·     | Database/VertexAI æŒä¹… | å…¨å±€è®¾ç½®ã€æ¨¡æ¿     |
| `temp:` | å½“å‰ Invocation      | ä¸æŒä¹…                 | ä¸­é—´è®¡ç®—ã€ä¸´æ—¶æ•°æ® |

```python
# Google ADK State ä½¿ç”¨ç¤ºä¾‹ [5]
async def my_tool(ctx: ToolContext):
    # Session scope - ä»…å½“å‰ä¼šè¯
    ctx.state["task_progress"] = 50

    # User scope - è·¨ä¼šè¯æŒä¹…åŒ–
    ctx.state["user:preferred_language"] = "zh-CN"

    # App scope - å…¨å±€é…ç½®
    ctx.state["app:max_retries"] = 3

    # Temp scope - ä»…å½“å‰è°ƒç”¨
    ctx.state["temp:intermediate_result"] = {...}
```

#### 5.2.2 LangGraph è®°å¿†ä½“ç³»

LangGraph åŒºåˆ†ä¸¤ç§æŒä¹…åŒ–æœºåˆ¶ [11][12]ï¼š

| ç±»å‹                  | æœºåˆ¶         | èŒƒå›´      | ç”¨é€”                   |
| :-------------------- | :----------- | :-------- | :--------------------- |
| **Short-term Memory** | Checkpointer | Thread å†… | å¯¹è¯å†å²ã€çŠ¶æ€å¿«ç…§     |
| **Long-term Memory**  | Store        | è·¨ Thread | ç”¨æˆ·åå¥½ã€å­¦ä¹ åˆ°çš„çŸ¥è¯† |

```python
# LangGraph çŸ­æœŸè®°å¿† (Checkpointer) [12]
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.checkpoint.postgres import PostgresSaver

# æœ¬åœ°æµ‹è¯•
checkpointer = InMemorySaver()

# ç”Ÿäº§ç¯å¢ƒ
checkpointer = PostgresSaver(conn)

graph = builder.compile(checkpointer=checkpointer)

# ä½¿ç”¨ thread_id æ ‡è¯†å¯¹è¯
config = {"configurable": {"thread_id": "conversation-123"}}
graph.invoke(input_data, config)
```

```python
# LangGraph é•¿æœŸè®°å¿† (Store) [12]
from langgraph.store.memory import InMemoryStore
from langgraph_checkpoint_postgres import PostgresStore

store = InMemoryStore()

# ç¼–è¯‘æ—¶åŒæ—¶å¯ç”¨ checkpointer å’Œ store
graph = builder.compile(checkpointer=checkpointer, store=store)

# åœ¨èŠ‚ç‚¹ä¸­ä½¿ç”¨ store
def my_node(state, config, *, store):
    user_id = config["configurable"]["user_id"]
    namespace = (user_id, "memories")

    # å­˜å‚¨è®°å¿†
    store.put(namespace, "preference", {"food": "pizza"})

    # æ£€ç´¢è®°å¿† (æ”¯æŒè¯­ä¹‰æœç´¢)
    memories = store.search(namespace, query="what do I like?")
```

#### 5.2.3 Agno è®°å¿†ä½“ç³»

Agno æä¾›ä¸¤ç§ Memory æ¨¡å¼ [8]ï¼š

| æ¨¡å¼                 | é…ç½®                         | è¡Œä¸º                            |
| :------------------- | :--------------------------- | :------------------------------ |
| **Automatic Memory** | `enable_user_memories=True`  | è‡ªåŠ¨ä»å¯¹è¯ä¸­æå–å’Œå¬å›è®°å¿†      |
| **Agentic Memory**   | `enable_agentic_memory=True` | Agent è‡ªä¸»å†³å®šä½•æ—¶åˆ›å»º/æ›´æ–°è®°å¿† |

```python
# Agno Memory ç¤ºä¾‹ [8]
from agno.agent import Agent
from agno.db.postgres import PostgresDb

db = PostgresDb(
    db_url="postgresql://user:pass@localhost:5432/mydb",
    memory_table="agent_memories"
)

agent = Agent(
    db=db,
    enable_user_memories=True,  # è‡ªåŠ¨è®°å¿†
)

# è®°å¿†è‡ªåŠ¨ä»å¯¹è¯ä¸­æå–
agent.print_response(
    "My name is Sarah and I prefer email over phone calls.",
    user_id="user-123"
)

# è®°å¿†è‡ªåŠ¨å¬å›
agent.print_response(
    "What's the best way to reach me?",
    user_id="user-123"
)  # Agent ä¼šè®°ä½åå¥½
```

### 5.3 ä¸Šä¸‹æ–‡å‹ç¼©ç­–ç•¥

#### 5.3.1 å‹ç¼©æ–¹æ³•å¯¹æ¯”

| ç­–ç•¥                | æè¿°                 | ä¼˜ç¼ºç‚¹                       | æ¡†æ¶æ”¯æŒ             |
| :------------------ | :------------------- | :--------------------------- | :------------------- |
| **Trimming**        | ä¿ç•™æœ€è¿‘ K æ¡æ¶ˆæ¯    | âœ… ç®€å•ï¼›âŒ ä¸¢å¤±æ—©æœŸé‡è¦ä¿¡æ¯ | LangGraph, Agno      |
| **Summarization**   | å°†å†å²æ‘˜è¦ä¸ºç²¾ç®€æ–‡æœ¬ | âœ… ä¿ç•™è¯­ä¹‰ï¼›âŒ è®¡ç®—å¼€é”€     | ADK, Agno, LangGraph |
| **Sliding Window**  | æ»‘åŠ¨çª—å£æ‘˜è¦è€æ—§äº‹ä»¶ | âœ… å¹³è¡¡ä¿ç•™ä¸å‹ç¼©            | ADK                  |
| **Semantic Filter** | åŸºäºç›¸å…³æ€§è¿‡æ»¤       | âœ… ä¿ç•™é‡è¦ä¿¡æ¯ï¼›âŒ å¯èƒ½é—æ¼ | è‡ªå®šä¹‰å®ç°           |
| **QA å¯¹å‹ç¼©**       | å°†ä¸Šä¸‹æ–‡è½¬æ¢ä¸ºé—®ç­”å¯¹ | âœ… æ£€ç´¢å‹å¥½ï¼›âŒ ç ´åä¿¡æ¯æµ   | è‡ªå®šä¹‰å®ç°           |

#### 5.3.2 Google ADK å‹ç¼©é…ç½®

```python
# Google ADK Context Compaction [3]
from google.adk.apps.app import EventsCompactionConfig

app = App(
    name='my-agent',
    root_agent=root_agent,
    events_compaction_config=EventsCompactionConfig(
        compaction_interval=3,  # æ¯ 3 æ¬¡è°ƒç”¨è§¦å‘å‹ç¼©
        overlap_size=1,         # ä¿ç•™å‰ä¸€çª—å£çš„ 1 ä¸ªäº‹ä»¶
    ),
)
```

#### 5.3.3 LangGraph æ¶ˆæ¯ç®¡ç†

```python
# LangGraph æ¶ˆæ¯ä¿®å‰ª [12]
from langchain_core.messages import trim_messages

# åŸºäº token é™åˆ¶ä¿®å‰ª
trimmer = trim_messages(
    max_tokens=1000,
    strategy="last",  # ä¿ç•™æœ€æ–°æ¶ˆæ¯
    token_counter=len,
)

# åœ¨èŠ‚ç‚¹ä¸­ä½¿ç”¨
def agent_node(state):
    messages = trimmer.invoke(state["messages"])
    response = llm.invoke(messages)
    return {"messages": [response]}
```

### 5.4 ä¸Šä¸‹æ–‡éš”ç¦»

è®ºæ–‡ [1] æå‡ºé€šè¿‡ **Sub-Agent æ¶æ„** è§£å†³ä¸Šä¸‹æ–‡çª—å£é™åˆ¶ï¼š

> "Each sub-agent has its own focused context window, and the main agent coordinates through efficient communication."

#### 5.4.1 LangGraph Subgraph

```python
# LangGraph Subgraph ä¸Šä¸‹æ–‡éš”ç¦» [12]
from langgraph.graph import StateGraph

# å­å›¾æœ‰ç‹¬ç«‹çš„çŠ¶æ€å’Œä¸Šä¸‹æ–‡
def create_research_subgraph():
    builder = StateGraph(ResearchState)
    builder.add_node("search", search_node)
    builder.add_node("analyze", analyze_node)
    return builder.compile()

# ä¸»å›¾
main_builder = StateGraph(MainState)
main_builder.add_node("research", create_research_subgraph())
main_builder.add_node("respond", respond_node)
```

### 5.5 æœ¬é¡¹ç›®å®è·µï¼šç»Ÿä¸€ç®¡ç†å™¨

```python
# Agentic AI Engine - ç»Ÿä¸€ä¸Šä¸‹æ–‡ç®¡ç†å™¨
from enum import Enum
from typing import List, Dict

class CompressionStrategy(Enum):
    NONE = "none"
    TRIM = "trim"
    SUMMARIZE = "summarize"
    SLIDING_WINDOW = "sliding_window"

class ContextManager:
    """ç»Ÿä¸€ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""

    def __init__(
        self,
        oceanbase_client,
        llm_client,
        compression_strategy: CompressionStrategy = CompressionStrategy.SLIDING_WINDOW,
        max_context_tokens: int = 8000,
        window_size: int = 10,
        overlap_size: int = 2
    ):
        self.db = oceanbase_client
        self.llm = llm_client
        self.strategy = compression_strategy
        self.max_tokens = max_context_tokens
        self.window_size = window_size
        self.overlap_size = overlap_size

    async def compress_history(
        self,
        session_id: str,
        events: List[Dict]
    ) -> List[Dict]:
        """å‹ç¼©å¯¹è¯å†å²"""

        if self.strategy == CompressionStrategy.NONE:
            return events

        if self.strategy == CompressionStrategy.TRIM:
            return events[-self.window_size:]

        if self.strategy == CompressionStrategy.SUMMARIZE:
            # è·å–éœ€è¦æ‘˜è¦çš„è€äº‹ä»¶
            old_events = events[:-self.window_size]
            recent_events = events[-self.window_size:]

            if old_events:
                summary = await self._generate_summary(old_events)
                return [{"type": "summary", "content": summary}] + recent_events
            return recent_events

        if self.strategy == CompressionStrategy.SLIDING_WINDOW:
            # ADK é£æ ¼çš„æ»‘åŠ¨çª—å£
            if len(events) <= self.window_size:
                return events

            # åˆ†æ‰¹æ¬¡ç®¡ç†
            batches = []
            for i in range(0, len(events) - self.window_size, self.window_size - self.overlap_size):
                batch = events[i:i + self.window_size]
                summary = await self._generate_summary(batch)
                batches.append({"type": "summary", "content": summary})

            # æœ€åä¸€ä¸ªçª—å£ä¿ç•™å®Œæ•´
            batches.extend(events[-self.window_size:])
            return batches

    async def transfer_to_long_term(
        self,
        user_id: str,
        session_id: str,
        events: List[Dict]
    ) -> List[str]:
        """è®°å¿†è¿ç§»ï¼šçŸ­æœŸ â†’ é•¿æœŸ"""

        # ä½¿ç”¨ LLM æå–é‡è¦ä¿¡æ¯
        insights = await self._extract_insights(events)

        memory_ids = []
        for insight in insights:
            # å‘é‡åŒ–å¹¶å­˜å‚¨
            embedding = await self._embed(insight["content"])

            memory_id = await self.db.execute("""
                INSERT INTO agent_memories
                (user_id, content, embedding, importance_score, topics)
                VALUES (?, ?, ?, ?, ?)
                RETURNING memory_id
            """, [
                user_id,
                insight["content"],
                embedding,
                insight["importance"],
                insight["topics"]
            ])
            memory_ids.append(memory_id)

        return memory_ids

    async def _generate_summary(self, events: List[Dict]) -> str:
        """ç”Ÿæˆæ‘˜è¦"""
        prompt = f"Summarize the following conversation:\n{events}"
        return await self.llm.generate(prompt)

    async def _extract_insights(self, events: List[Dict]) -> List[Dict]:
        """æå–é‡è¦æ´å¯Ÿ"""
        prompt = f"""Extract important user preferences, facts, and learnings from this conversation.
        Return as JSON list with fields: content, importance (0-1), topics (list).
        Conversation: {events}"""
        return await self.llm.generate_json(prompt)
```

---

## 6. Context Usageï¼ˆä¸Šä¸‹æ–‡ä½¿ç”¨ï¼‰

### 6.1 æ£€ç´¢ä¸é€‰æ‹©ç­–ç•¥

è®ºæ–‡ [1] å¼ºè°ƒå¤šç»´åº¦çš„æ£€ç´¢ä¾æ®ï¼š

| æ£€ç´¢ä¾æ®                 | æè¿°                       | å®ç°æ–¹å¼      |
| :----------------------- | :------------------------- | :------------ |
| **è¯­ä¹‰ç›¸ä¼¼åº¦**           | åŸºäºå‘é‡åµŒå…¥çš„ç›¸ä¼¼åº¦æœç´¢   | Vector Search |
| **æ—¶é—´é‚»è¿‘æ€§ (Recency)** | æœ€è¿‘ä½¿ç”¨çš„ä¿¡æ¯ä¼˜å…ˆçº§æ›´é«˜   | æ—¶é—´æˆ³æ’åº    |
| **è®¿é—®é¢‘ç‡ (Frequency)** | é«˜é¢‘è®¿é—®çš„ä¿¡æ¯ä¿æŒé«˜å¯ç”¨æ€§ | è®¿é—®è®¡æ•°å™¨    |
| **é‡è¦æ€§è¯„åˆ†**           | é¢„è®¡ç®—çš„é‡è¦æ€§æƒé‡         | LLM è¯„ä¼°      |
| **é€»è¾‘ä¾èµ–**             | è¿½è¸ªæ¨ç†æ­¥éª¤ä¹‹é—´çš„ä¾èµ–å…³ç³» | ä¾èµ–å›¾        |
| **ä¿¡æ¯å»é‡**             | è¿‡æ»¤ä¼ è¾¾ç›¸åŒå«ä¹‰çš„é‡å¤ä¿¡æ¯ | è¯­ä¹‰å»é‡      |

### 6.2 æ··åˆæ£€ç´¢å®ç°

```python
# Agentic AI Engine - æ··åˆæ£€ç´¢
class HybridRetriever:
    """æ··åˆæ£€ç´¢å™¨ï¼šè¯­ä¹‰ + æ—¶é—´ + é¢‘ç‡"""

    def __init__(self, oceanbase_client):
        self.db = oceanbase_client

    async def retrieve(
        self,
        user_id: str,
        query: str,
        query_embedding: List[float],
        weights: Dict[str, float] = None
    ) -> List[Dict]:
        """
        æ··åˆæ£€ç´¢ï¼Œæ”¯æŒæƒé‡è°ƒæ•´

        Args:
            weights: {"semantic": 0.5, "recency": 0.3, "frequency": 0.2}
        """
        weights = weights or {
            "semantic": 0.5,
            "recency": 0.3,
            "frequency": 0.2
        }

        # OceanBase æ··åˆæ£€ç´¢ SQL
        result = await self.db.execute("""
            SELECT
                memory_id,
                content,
                topics,
                -- ç»¼åˆè¯„åˆ†
                (
                    ? * (1 - vec_l2_distance(embedding, ?)) +
                    ? * (1 - DATEDIFF(NOW(), updated_at) / 30.0) +
                    ? * (access_count / (SELECT MAX(access_count) FROM agent_memories WHERE user_id = ?))
                ) AS relevance_score
            FROM agent_memories
            WHERE user_id = ?
              AND vec_l2_distance(embedding, ?) < 0.8
            ORDER BY relevance_score DESC
            LIMIT 10
        """, [
            weights["semantic"], query_embedding,
            weights["recency"],
            weights["frequency"], user_id,
            user_id,
            query_embedding
        ])

        return result
```

### 6.3 åŠ¨æ€ä¸Šä¸‹æ–‡ç»„è£…

```mermaid
graph LR
    subgraph Inputs["è¾“å…¥æº"]
        I1["System Instruction"]
        I2["User Message"]
        I3["Chat History"]
        I4["Memories"]
        I5["Knowledge (RAG)"]
        I6["Tools"]
    end

    subgraph Assembler["Context Assembler"]
        A1["Token é¢„ç®—è®¡ç®—"]
        A2["ä¼˜å…ˆçº§æ’åº"]
        A3["æˆªæ–­ä¸å¡«å……"]
        A4["æ ¼å¼åŒ–è¾“å‡º"]
    end

    subgraph Output["è¾“å‡º"]
        O1["Formatted Prompt"]
    end

    I1 --> A1
    I2 --> A1
    I3 --> A1
    I4 --> A1
    I5 --> A1
    I6 --> A1
    A1 --> A2 --> A3 --> A4 --> O1

    style Inputs fill:#065f46,stroke:#34d399,color:#fff
    style Assembler fill:#7c2d12,stroke:#fb923c,color:#fff
    style Output fill:#581c87,stroke:#c084fc,color:#fff
```

```python
# Agentic AI Engine - åŠ¨æ€ä¸Šä¸‹æ–‡ç»„è£…å™¨
from typing import List, Dict, Optional
import tiktoken

class ContextAssembler:
    """åŠ¨æ€ä¸Šä¸‹æ–‡ç»„è£…å™¨"""

    def __init__(
        self,
        max_tokens: int = 8000,
        reserved_output_tokens: int = 1000,
        tokenizer: str = "cl100k_base"
    ):
        self.max_tokens = max_tokens
        self.reserved = reserved_output_tokens
        self.encoding = tiktoken.get_encoding(tokenizer)

        # å„éƒ¨åˆ†ä¼˜å…ˆçº§ï¼ˆæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
        self.priorities = {
            "system_instruction": 1,
            "tools": 2,
            "user_message": 3,
            "memories": 4,
            "knowledge": 5,
            "chat_history": 6
        }

    def count_tokens(self, text: str) -> int:
        return len(self.encoding.encode(text))

    def assemble(self, context: Context) -> str:
        """ç»„è£…æœ€ç»ˆä¸Šä¸‹æ–‡"""

        available_tokens = self.max_tokens - self.reserved
        components = []
        used_tokens = 0

        # æŒ‰ä¼˜å…ˆçº§æ’åºç»„è£…
        parts = [
            ("system_instruction", context.system_instruction),
            ("tools", self._format_tools(context.tools)),
            ("user_message", context.user_message),
            ("memories", self._format_memories(context.memories)),
            ("knowledge", self._format_knowledge(context.knowledge)),
            ("chat_history", self._format_history(context.chat_history)),
        ]

        parts.sort(key=lambda x: self.priorities[x[0]])

        for name, content in parts:
            tokens_needed = self.count_tokens(content)

            if used_tokens + tokens_needed <= available_tokens:
                components.append((name, content))
                used_tokens += tokens_needed
            else:
                # å°è¯•æˆªæ–­
                remaining = available_tokens - used_tokens
                truncated = self._truncate(content, remaining)
                if truncated:
                    components.append((name, truncated))
                    used_tokens += self.count_tokens(truncated)
                break

        return self._format_prompt(components)

    def _format_prompt(self, components: List[tuple]) -> str:
        """æ ¼å¼åŒ–æœ€ç»ˆ Prompt"""
        sections = {
            "system_instruction": "## System Instructions\n{content}\n",
            "tools": "## Available Tools\n{content}\n",
            "memories": "## Relevant Memories\n{content}\n",
            "knowledge": "## Retrieved Knowledge\n{content}\n",
            "chat_history": "## Conversation History\n{content}\n",
            "user_message": "## Current User Message\n{content}\n",
        }

        result = []
        for name, content in components:
            if content and name in sections:
                result.append(sections[name].format(content=content))

        return "\n".join(result)

    def _truncate(self, text: str, max_tokens: int) -> str:
        """æ™ºèƒ½æˆªæ–­"""
        tokens = self.encoding.encode(text)
        if len(tokens) <= max_tokens:
            return text
        return self.encoding.decode(tokens[:max_tokens]) + "..."
```

### 6.4 ä¸»åŠ¨æ„å›¾æ¨æ–­

è®ºæ–‡ [1] å¼ºè°ƒ Context Engineering åº”ä½¿ Agent èƒ½å¤Ÿ**ä¸»åŠ¨æ¨æ–­**ç”¨æˆ·æœªæ˜ç¡®è¡¨è¾¾çš„éœ€æ±‚ï¼š

> "Proactive Intent Inference: learn user preference from dialogue history and personal data; infer hidden goals from related queries; detect user struggles and offer proactive assistance."

```python
# Agentic AI Engine - æ„å›¾æ¨æ–­å™¨
class IntentInferrer:
    """ä¸»åŠ¨æ„å›¾æ¨æ–­å™¨"""

    def __init__(self, llm_client, memory_service):
        self.llm = llm_client
        self.memory = memory_service

    async def infer_hidden_intent(
        self,
        user_id: str,
        current_query: str,
        chat_history: List[Dict]
    ) -> Dict:
        """æ¨æ–­ç”¨æˆ·éšè—æ„å›¾"""

        # æ£€ç´¢ç”¨æˆ·åå¥½
        preferences = await self.memory.search_memory(
            user_id=user_id,
            query="user preferences and habits"
        )

        prompt = f"""Analyze the user's query and conversation history to infer their hidden intent.

User Query: {current_query}

Recent Conversation:
{chat_history}

Known User Preferences:
{preferences}

Infer:
1. Explicit Intent: What the user is directly asking for
2. Hidden Intent: What the user might actually need but didn't explicitly say
3. Potential Follow-ups: What the user might ask next
4. Proactive Suggestions: What help we can offer proactively

Return as JSON.
"""
        return await self.llm.generate_json(prompt)
```

---

## 7. ä¸»æµæ¡†æ¶å¯¹æ¯”æ€»ç»“

### 7.1 æ ¸å¿ƒæ¦‚å¿µæ˜ å°„

| æ¦‚å¿µ           | Google ADK [3-6]       | Agno [7-10]                   | LangGraph [11-12]         |
| :------------- | :--------------------- | :---------------------------- | :------------------------ |
| **ä¼šè¯å®¹å™¨**   | Session                | Session (session_id)          | Thread (checkpointer)     |
| **ä¸´æ—¶çŠ¶æ€**   | session.state          | session_state                 | State (graph state)       |
| **å¯¹è¯å†å²**   | session.events         | chat_history                  | messages                  |
| **é•¿æœŸè®°å¿†**   | MemoryService          | Memory (enable_user_memories) | Store                     |
| **çŸ¥è¯†åº“/RAG** | (éœ€è‡ªè¡Œå®ç°)           | Knowledge                     | VectorStore / Retriever   |
| **ä¸Šä¸‹æ–‡ç¼“å­˜** | ContextCacheConfig     | ä¾èµ– LLM Provider             | ä¾èµ– LLM Provider         |
| **ä¸Šä¸‹æ–‡å‹ç¼©** | EventsCompactionConfig | session_summary               | trim_messages / summarize |
| **æŒä¹…åŒ–**     | SessionService         | Database                      | Checkpointer              |

### 7.2 å„æ¡†æ¶ä¼˜åŠ£åŠ¿

| æ¡†æ¶           | ä¼˜åŠ¿                                                                           | åŠ£åŠ¿                                              |
| :------------- | :----------------------------------------------------------------------------- | :------------------------------------------------ |
| **Google ADK** | âœ… æ¸…æ™°çš„ Service æŠ½è±¡<br>âœ… ä¸ Vertex AI æ·±åº¦é›†æˆ<br>âœ… å¤šè¯­è¨€æ”¯æŒ [3]        | âŒ MemoryBank å¼ºä¾èµ– Vertex AI<br>âŒ ç¤¾åŒºç”Ÿæ€è¾ƒæ–° |
| **Agno**       | âœ… å¼€å‘ä½“éªŒæä½³ï¼ˆé…ç½®é©±åŠ¨ï¼‰<br>âœ… Memory å¼€ç®±å³ç”¨<br>âœ… Team å¤š Agent æ”¯æŒ [7] | âŒ ç›¸å¯¹å°é—­çš„ç”Ÿæ€<br>âŒ æ–‡æ¡£æ·±åº¦æœ‰é™              |
| **LangGraph**  | âœ… çŠ¶æ€ç®¡ç†ä¼˜ç§€<br>âœ… å¤æ‚å·¥ä½œæµæ”¯æŒ<br>âœ… ç¤¾åŒºæ´»è·ƒ [11]                       | âŒ é…ç½®å¤æ‚åº¦é«˜<br>âŒ è°ƒè¯•å›°éš¾                    |

### 7.3 é€‰å‹å»ºè®®

```mermaid
graph TD
    Q1{éœ€è¦ Google Cloud é›†æˆ?}
    Q2{éœ€è¦å¤æ‚å·¥ä½œæµ?}
    Q3{éœ€è¦å¿«é€Ÿå¼€å‘?}

    Q1 -->|æ˜¯| ADK["é€‰æ‹© Google ADK"]
    Q1 -->|å¦| Q2

    Q2 -->|æ˜¯| LG["é€‰æ‹© LangGraph"]
    Q2 -->|å¦| Q3

    Q3 -->|æ˜¯| AGNO["é€‰æ‹© Agno"]
    Q3 -->|å¦| CUSTOM["è‡ªå®šä¹‰å®ç°"]

    style ADK fill:#4285f4,stroke:#1a73e8,color:#fff
    style LG fill:#ff6b35,stroke:#e85a2e,color:#fff
    style AGNO fill:#10b981,stroke:#059669,color:#fff
    style CUSTOM fill:#6366f1,stroke:#4f46e5,color:#fff
```

---

## 8. æŠ€æœ¯æ¶æ„å»ºè®®

### 8.1 OceanBase ç»Ÿä¸€å­˜å‚¨æ¶æ„

åŸºäºè°ƒç ”ï¼Œå»ºè®®ä»¥ä¸‹ç»Ÿä¸€ Schema è®¾è®¡ï¼š

```mermaid
erDiagram
    agent_sessions ||--o{ session_events : contains
    agent_sessions ||--o| session_state : has
    agent_sessions }o--|| agent_memories : consolidates_to
    users ||--o{ agent_sessions : owns
    users ||--o{ agent_memories : owns

    users {
        string user_id PK
        string name
        json preferences
        timestamp created_at
    }

    agent_sessions {
        string session_id PK
        string user_id FK
        string app_name
        string agent_id
        timestamp created_at
        timestamp updated_at
    }

    session_events {
        bigint event_id PK
        string session_id FK
        string event_type
        json event_data
        int token_count
        timestamp created_at
    }

    session_state {
        string session_id FK
        json session_data
        json user_data
        json app_data
        timestamp updated_at
    }

    agent_memories {
        string memory_id PK
        string user_id FK
        string app_name
        text content
        vector embedding
        json topics
        float importance_score
        int access_count
        timestamp created_at
        timestamp updated_at
    }
```

### 8.2 ç»Ÿä¸€ Service æ¥å£è®¾è®¡

```python
# Agentic AI Engine - ç»Ÿä¸€ Service æ¥å£
from abc import ABC, abstractmethod
from typing import List, Dict, Optional

class BaseSessionService(ABC):
    """ä¼šè¯æœåŠ¡æŠ½è±¡åŸºç±»"""

    @abstractmethod
    async def create_session(
        self, user_id: str, app_name: str, agent_id: str
    ) -> str: ...

    @abstractmethod
    async def get_session(
        self, session_id: str
    ) -> Optional[Dict]: ...

    @abstractmethod
    async def append_event(
        self, session_id: str, event_type: str, event_data: Dict
    ) -> int: ...

    @abstractmethod
    async def update_state(
        self, session_id: str, state_delta: Dict
    ) -> None: ...

class BaseMemoryService(ABC):
    """è®°å¿†æœåŠ¡æŠ½è±¡åŸºç±»"""

    @abstractmethod
    async def add_memory(
        self, user_id: str, content: str, topics: List[str], importance: float
    ) -> str: ...

    @abstractmethod
    async def search_memory(
        self, user_id: str, query: str, limit: int = 10
    ) -> List[Dict]: ...

    @abstractmethod
    async def update_access(
        self, memory_id: str
    ) -> None: ...

class OceanBaseSessionService(BaseSessionService):
    """OceanBase ä¼šè¯æœåŠ¡å®ç°"""

    def __init__(self, connection_pool):
        self.pool = connection_pool

    async def create_session(self, user_id: str, app_name: str, agent_id: str) -> str:
        session_id = str(uuid.uuid4())
        await self.pool.execute("""
            INSERT INTO agent_sessions (session_id, user_id, app_name, agent_id)
            VALUES (?, ?, ?, ?)
        """, [session_id, user_id, app_name, agent_id])
        return session_id

    async def append_event(self, session_id: str, event_type: str, event_data: Dict) -> int:
        result = await self.pool.execute("""
            INSERT INTO session_events (session_id, event_type, event_data, token_count)
            VALUES (?, ?, ?, ?)
            RETURNING event_id
        """, [session_id, event_type, json.dumps(event_data), self._count_tokens(event_data)])
        return result[0]["event_id"]

class OceanBaseMemoryService(BaseMemoryService):
    """OceanBase è®°å¿†æœåŠ¡å®ç°"""

    def __init__(self, connection_pool, embedding_client):
        self.pool = connection_pool
        self.embedder = embedding_client

    async def search_memory(self, user_id: str, query: str, limit: int = 10) -> List[Dict]:
        query_embedding = await self.embedder.embed(query)

        return await self.pool.execute("""
            SELECT
                memory_id, content, topics, importance_score,
                vec_l2_distance(embedding, ?) as distance
            FROM agent_memories
            WHERE user_id = ?
            ORDER BY distance ASC
            LIMIT ?
        """, [query_embedding, user_id, limit])
```

### 8.3 è®°å¿†æ£€ç´¢ SQL ç¤ºä¾‹

```sql
-- æ··åˆæ£€ç´¢ï¼šè¯­ä¹‰ç›¸ä¼¼åº¦ + æ—¶é—´é‚»è¿‘æ€§ + è®¿é—®é¢‘ç‡
SELECT
    memory_id,
    content,
    topics,
    -- ç»¼åˆè¯„åˆ† (å€¼è¶Šå°è¶Šç›¸å…³)
    (
        0.5 * vec_l2_distance(embedding, :query_embedding) +
        0.3 * (DATEDIFF(NOW(), updated_at) / 30.0) +
        0.2 * (1.0 - access_count / (SELECT MAX(access_count) FROM agent_memories WHERE user_id = :user_id))
    ) AS relevance_score
FROM agent_memories
WHERE user_id = :user_id
  AND app_name = :app_name
  AND vec_l2_distance(embedding, :query_embedding) < 0.8
ORDER BY relevance_score ASC
LIMIT 10;
```

---

## 9. ä¸é¡¹ç›® Roadmap çš„ç»“åˆå»ºè®®

### 9.1 Phase 2: Memory Management

**è®ºæ–‡æŒ‡å¯¼**ï¼šè®°å¿†åˆ†å±‚æ¶æ„ + è®°å¿†è¿ç§»æœºåˆ¶ [1]

**è¡ŒåŠ¨å»ºè®®**ï¼š

1. **çŸ­æœŸè®°å¿† (Session Log)**

   - ä½¿ç”¨ OceanBase è¡¨å­˜å‚¨ `session_events`ï¼ˆappend-onlyï¼‰
   - åˆ©ç”¨ OceanBase äº‹åŠ¡ä¿è¯ `state_delta` çš„åŸå­åº”ç”¨

2. **é•¿æœŸè®°å¿† (Insights)**

   - è®¾è®¡ `agent_memories` è¡¨ï¼ŒåŒ…å«å‘é‡åˆ—
   - å®ç° Memory Transfer å‡½æ•°

3. **è®°å¿†é€‰æ‹©ç­–ç•¥**
   - å®ç°åŸºäº Recency + Frequency + Semantic Similarity çš„æ··åˆæ£€ç´¢
   - åˆ©ç”¨ `DBMS_HYBRID_SEARCH` å®ç° SQL å±‚é¢çš„æ··åˆæ£€ç´¢

### 9.2 Phase 3: Context Engineering (RAG & Assembler)

**è®ºæ–‡æŒ‡å¯¼**ï¼šContext Compression + Context Isolation + Proactive Inference [1]

**è¡ŒåŠ¨å»ºè®®**ï¼š

1. **ç»Ÿä¸€æ£€ç´¢é“¾è·¯**

   - åœ¨å•æ¬¡ SQL æŸ¥è¯¢ä¸­åŒæ—¶æ£€ç´¢ Session Context + Long-term Memory
   - å®ç° `OceanBaseMemoryService.search_memory()` è¿”å› Fused Context

2. **ä¸Šä¸‹æ–‡å‹ç¼©**

   - å‚è€ƒ ADK çš„ EventsCompactionConfig è®¾è®¡
   - åœ¨ OceanBase ä¸­å¯é€šè¿‡ Stored Procedure æˆ–åº”ç”¨å±‚å®ç°æ»‘åŠ¨çª—å£æ‘˜è¦

3. **åŠ¨æ€ä¸Šä¸‹æ–‡ç»„è£… (Context Budgeting)**
   - åœ¨æ•°æ®åº“å±‚ä¼°ç®— Token å¤§å°
   - å®ç° Top-K æˆªæ–­ï¼Œç¡®ä¿ä¸è¶…è¿‡ Context Window

### 9.3 Phase 4: Framework Integration

**è®ºæ–‡æŒ‡å¯¼**ï¼šä¸Šä¸‹æ–‡å…±äº« + è·¨ Agent é€šä¿¡ [1]

**è¡ŒåŠ¨å»ºè®®**ï¼š

1. **ADK Adapter ä¼˜å…ˆ**

   - å®ç° `OceanBaseSessionService` å’Œ `OceanBaseMemoryService`
   - éµå¾ª ADK çš„ Service æŠ½è±¡ï¼Œç¡®ä¿ä¸ Google ç”Ÿæ€çš„å…¼å®¹æ€§

2. **å¤šæ¡†æ¶æ”¯æŒ**

   - ä¸º LangGraph å®ç° `Checkpointer` + `Store` åŒè§’è‰²
   - ä¸º Agno å®ç° `Database` æ¥å£

3. **A2A Protocol é¢„ç ”**
   - å…³æ³¨ Google çš„ Agent-to-Agent å¼€æ”¾åè®®
   - è€ƒè™‘ OceanBase ä½œä¸º Agent é—´ä¸Šä¸‹æ–‡å…±äº«çš„ä¸­å¤®å­˜å‚¨

---

## 10. è¶‹åŠ¿ä¸æŒ‘æˆ˜

### 10.1 Era 3.0 æŒ‘æˆ˜

æ ¹æ®è®ºæ–‡ [1] é¢„æµ‹ï¼Œæœªæ¥çš„ Context Engineering å°†é¢ä¸´ï¼š

1. **ç»ˆèº«ä¸Šä¸‹æ–‡ä¿å­˜**ï¼šå¦‚ä½•å¯é å­˜å‚¨ç”¨æˆ·ä¸€ç”Ÿçš„äº¤äº’ä¸Šä¸‹æ–‡ï¼Ÿ
2. **è¯­ä¹‰ä¸€è‡´æ€§**ï¼šéšç€æ•°æ®è§„æ¨¡è†¨èƒ€ï¼Œå¦‚ä½•ä¿æŒè¯­ä¹‰çš„å‡†ç¡®æ€§ï¼Ÿ
3. **åŠ¨æ€æ›´æ–°**ï¼šå¦‚ä½•å¤„ç†è¿‡æ—¶ä¿¡æ¯å’ŒçŸ¥è¯†å†²çªï¼Ÿ
4. **éšç§ä¸å®‰å…¨**ï¼šå¦‚ä½•åœ¨ä¿æŠ¤ç”¨æˆ·éšç§çš„åŒæ—¶æä¾›ä¸ªæ€§åŒ–æœåŠ¡ï¼Ÿ

### 10.2 OceanBase çš„æ½œåœ¨ä¼˜åŠ¿

1. **å¼ºä¸€è‡´æ€§ (ACID)**ï¼šäº‹åŠ¡çº§ä¿è¯é¿å…"è®°å¿†åˆ†è£‚"
2. **HTAP èƒ½åŠ›**ï¼šé«˜é¢‘å†™å…¥ + å¤æ‚åˆ†ææŸ¥è¯¢çš„ç»Ÿä¸€å¤„ç†
3. **å¤šåœ°å¤šæ´» (Paxos)**ï¼šè·¨åŒºåŸŸè®°å¿†ä¸€è‡´æ€§
4. **Hybrid Search**ï¼šSQL + Vector çš„åŸç”Ÿæ··åˆæ£€ç´¢
5. **é«˜å¯ç”¨æ€§**ï¼š99.999% SLA ä¿éšœå…³é”®è®°å¿†ä¸ä¸¢å¤±

---

## 11. ç»“è®º

Context Engineering æ˜¯ AI Agent ç³»ç»Ÿä»"ç©å…·"è¿ˆå‘"ç”Ÿäº§"çš„å…³é”®æŠ€æœ¯ã€‚æœ¬æŠ¥å‘Šç³»ç»Ÿæ€§åœ°æ¢³ç†äº†ï¼š

1. **ç†è®ºæ¡†æ¶**ï¼šä» Dey (2001) çš„å®šä¹‰åˆ° SII-GAIR (2025) çš„å½¢å¼åŒ–æ¼”è¿›
2. **ä¸‰å¤§æ”¯æŸ±**ï¼šCollectionã€Managementã€Usage çš„å®Œæ•´æŠ€æœ¯æ ˆ
3. **æ¡†æ¶å¯¹æ¯”**ï¼šGoogle ADKã€Agnoã€LangGraph çš„å®ç°ç­–ç•¥
4. **é¡¹ç›®å®è·µ**ï¼šOceanBase ç»Ÿä¸€å­˜å‚¨ + ç»Ÿä¸€ Service æ¥å£çš„æ¶æ„è®¾è®¡

> [!TIP] > **ä¸‹ä¸€æ­¥è¡ŒåŠ¨**ï¼š
>
> 1. éªŒè¯ OceanBase Vector æŸ¥è¯¢æ€§èƒ½
> 2. å®ç° `OceanBaseSessionService` å’Œ `OceanBaseMemoryService`
> 3. æ„å»º Context Assembler ç»„ä»¶
> 4. é›†æˆè‡³ Google ADK æ¡†æ¶

---

## å‚è€ƒæ–‡çŒ®

[1] SII-GAIR. (2025). _Context Engineering 2.0: The Context of Context Engineering_. arXiv preprint. [æœ¬åœ°æ–‡ä»¶](../assets/context-engineering/Context%20Engineering%202.0:%20The%20Context%20of%20Context%20Engineering.pdf)

[2] Dey, A. K. (2001). _Understanding and Using Context_. Personal and Ubiquitous Computing, 5(1), 4-7. [æœ¬åœ°æ–‡ä»¶](../assets/context-engineering/Understanding%20and%20Using%20Context.pdf)

[3] Google ADK - Context. https://google.github.io/adk-docs/context/

[4] Google ADK - Sessions, State, Memory Overview. https://google.github.io/adk-docs/sessions/

[5] Google ADK - State. https://google.github.io/adk-docs/sessions/state/

[6] Google ADK - Memory. https://google.github.io/adk-docs/sessions/memory/

[7] Agno - Context Engineering. https://docs.agno.com/basics/context/overview

[8] Agno - Memory. https://docs.agno.com/basics/memory/overview

[9] Agno - Knowledge. https://docs.agno.com/basics/knowledge/overview

[10] Agno - Sessions. https://docs.agno.com/basics/sessions

[11] LangGraph - Overview. https://docs.langchain.com/oss/python/langgraph/overview

[12] LangGraph - Persistence & Memory. https://langchain-ai.github.io/langgraph/ (é€šè¿‡æµè§ˆå™¨é‡‡é›†)
