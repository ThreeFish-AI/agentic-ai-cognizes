（由 TurboScribe.ai 转录。解除限制以移除此消息。）

欢迎回到深度探讨。今天我们将深入探索，超越所有关于 AI 智能体的肤浅讨论。是的。

你知道，就是那种"写一个好的提示词，然后看看会发生什么"的简单想法。我们要深入挖掘真正让它们可靠的核心架构。我们谈论的是上下文工程。

没错。你知道，这真的是现代 AI 的机械心脏。多年来，人们把构建智能体当作某种提示词魔法。

我们今天的使命是向你展示，上下文工程（CE）不是简单的技巧。它是将 AI 智能体从有趣的玩具转变为可靠的、可扩展的生产系统所需的核心系统性学科。一个能够处理复杂、多步骤任务的系统。

好的，让我们来解析一下。我们借鉴了一些非常重要的资料来源。

我们正在看基础性的工作，一些来自 2000 年代早期的经典学术论文，然后将其一直连接到最近的概念形式化。那篇技术报告，《上下文工程 2.0》。是的，然后我们将看看主要的生产框架，比如 Google 的智能体开发工具包（ADK）、Agno、LanGraph，它们如何在现实世界中实际实现这些想法。所以对你听众来说，目标很简单。

我们希望你离开这次深度探讨时，对复杂的智能体如何记忆、学习，然后在多个会话中高效应用这些知识有一个清晰的、系统性的理解。因为你需要这个来构建可靠的系统，而不仅仅是酷炫的演示。没错，不仅仅是演示。

好的，如果我们要构建一个架构，我们需要知道我们在构建什么的基础上。上下文这个学术概念甚至从哪里开始？嗯，为此，我们必须回到过去。我们必须从 2001 年开始，由一位名为 Day 的研究人员开创的上下文感知计算。

这是，什么，前 LLM 时代？早得多。是的。但 Day 真的很有远见。

他认为，为了让计算机真正有用，它们必须理解它们所处的情境。好的。他称上下文是我们计算环境中信息利用不足的来源。

哇，现在感觉 incredibly 相关。我是说，今天的每个智能体都在拼命努力将相关信息塞进有限的上下文窗口中。这是同样的西兰花。

戏剧性地放大了。正是，Day 的基础性定义确实为今天的复杂性奠定了基础。他将上下文定义为，这是关键，任何可用于表征实体情境的信息。

一个实体，这不仅仅是用户，对吧？你要带走的关键见解是，实体不仅仅是打字的人。它包括应用程序、可用的工具、位置、与该交互相关的任何对象。所以如果上下文是，嗯，如果是表征情境的一切，那么上下文工程不仅仅是关于过滤提示词。

不。它是关于过滤其他一切。准确地说，那个广泛的定义直接引导我们到现代的形式化定义。

你可以忘记数学符号，但这个想法很强大。核心思想是什么？上下文工程只是一个系统性的过程，在 AI 甚至看到特定任务的提示词之前，清理、压缩和选择绝对最好的可用信息。它是一个优化引擎。

它是，它是一个信息优化引擎。那个引擎执行什么操作？关键流程是什么？所以操作涵盖整个生命周期。它是收集原始上下文，存储和管理它，然后是真正困难的部分，只选择最相关的部分。

然后你会到令人兴奋的部分。是什么？自烘焙概念。我喜欢这个术语。

在架构术语中，自烘焙意味着什么？它是将这些短暂的短期记忆转化为持久的长期智慧的机制。啊，好的。它是过去上下文的集成和重用。

至关重要的是，系统还必须根据反馈动态调整其自己的内部规则。它不断地自我优化。那个自烘焙过程，感觉就像从历史概念到现代智能体复杂性的过渡。

概述 CE 四个时代的最近报告确实显示了这种进展，不是吗？确实。1.0 时代，大约是 90 年代到 2020 年。它是僵化的。

上下文基于简单的、预定义的格式、传感器输入、菜单选择。但是当大语言模型到来时，我们直接跳进了 2.0 时代。以智能体为中心的计算。我们现在正处于 2.0 时代。

它只是由复杂性定义。要求能够理解自然语言、处理隐式或隐藏的用户意图的智能体。并在信息不完整的情况下操作。

是的。作为今天的工程师，你面临的最大的技术挑战是在那个有限的、受限的上下文窗口内进行最佳的、几乎瞬时的上下文选择。这是与令牌限制的持续斗争。

所以如果 2.0 时代是现在，我们要去哪里？3.0 时代听起来像科幻小说。需要最少的显式上下文的人类水平智能。那么要达到那里需要什么？这种转变需要解决巨大的工程障碍。

第一个是终身上下文保留。你如何可靠地存储用户的整个历史？所有。第二个，你必须保持，术语是什么？语义一致性？是的，这在规模上是一场噩梦。

实际上这意味着什么？它意味着处理知识冲突。所以如果智能体两年前从你那里学到了一件事，但过去六个月的互动表明你改变了主意。它如何更新它的理解？正是。

系统如何在不与它所知道的相矛盾的情况下更新自己？或者在实际需要时未能检索到旧信息？那是 3.0 时代的复杂性。好的，这是一个巨大的架构提升。为了理解我们现在如何处理那个规模，我们需要变得实际。

资料来源将上下文工程分解为三个支柱。是的，支柱一是上下文收集。获取信息。

简单地为智能体的运行时环境收集所有必要的、通常是杂乱的信息。它是输入阶段。它出奇地复杂，因为上下文来自六个非常不同的来源。

这个列表非常重要，因为它表明它从来不仅仅是一个数据流。前两个是显而易见的。你有用户输入。

你当前的任务。和系统指令，智能体不可变的规则和角色。是的。

然后你有智能体的内部记忆。第三个是对话历史。所以当前会话的短期记忆。

运行记录。第四个是长期记忆。跨会话的持久信息。

由专门的服务管理。然后我们到外部世界。第五个是外部数据，或 RAG。

你来自向量数据库或其他知识库的实时知识。最后。第六个，工具定义和输出格式。

智能体需要确切知道它的工具做什么以及最终输出格式需要看起来像什么。像特定的 JSON 模式。所有这六个都必须收集和协调。

这惊人的数据量直接将我们带到支柱二。上下文管理。你必须组织它、压缩它、存储它，所有这些都针对那个上下文窗口约束。

这就是分层记忆架构的用武之地。它是基础的。你可以把它想象成人类记忆。

我们有短期记忆高时间相关性。像你的会话状态，聊天的最后五分钟。快速检索，但很快变得无关。

是的。然后你有长期记忆。这是抽象的、压缩的、高重要性信息的持久存储。

这两层之间的过渡是关键架构部分。它叫做记忆转移。这是整合过程。

系统分析短期流。它识别高频或高重要性事件，然后将它们处理成有意义的见解。然后将它们移动到长期存储。

是的。这就像 Google 的记忆库异步地将整个聊天会话转化为持久的见解。但是你不能将所有这些发送到 LLM，所以压缩是不可避免的。

智能体使用的主要策略是什么？有四个核心策略。最简单的是修剪。只保留最近的，比如说，K 条消息。

简单，但你可能会失去重要的早期上下文。是的，正是。然后你有摘要，将历史浓缩成自然语言。

它保留了含义，但你失去了细节。好的，更高级的框架像 Google ADK，它们经常使用滑动窗口方法。这是一个智能混合。

是的。它总结较旧的对话块，同时保持最近的消息完整细节。和最有针对性的。

语义过滤器。这是关键。它仅根据与当前任务的相关性选择性过滤上下文。

这就是让智能体能够运行复杂的 10 步操作而不会忘记初始目标的原因。是的，它过滤掉了第二步到第九步期间产生的所有噪音。这种效率通过上下文隔离得到进一步提高。

我们在子智能体架构中看到了这一点。与其用巨大的上下文窗口使一个主智能体过载来完成一个巨大的任务，你只需要分割劳动。所以每个子智能体都有自己的专注的、较小的上下文窗口。

正是。它针对其特定功能量身定制，这显著降低了整体认知负载和每步的令牌使用。主智能体只是协调过程。

使用定义的通道，像 LanGraph 的子图设计。好的，所以我们收集了数据，我们管理和压缩了它。现在最后的测试，这是支柱三，上下文使用。

我们如何在完美的时间选择完美的信息片段？这似乎是最困难的部分。确实是。上下文使用由检索和选择主导。

这里的关键见解是，有效的智能体不依赖于简单的基于向量的搜索。它必须是多维度的。必须是。

这些维度是什么？它们同时查看四个标准。第一，语义相似性，这是你的标准向量搜索。第二，时间最近性，优先考虑新信息。

有道理。第三，访问频率，保持重要东西的便利性。第四，重要性评分。

这是预先计算权重以确定记忆块有多重要的地方。好的，现在这对我来说变得真正有趣了。主动意图推断。

这是智能体开始甚至在你没说出来之前就预见你需要什么的地方。听起来像魔法。它不是魔法。

它只是应用于上下文的非常复杂的数据分析。这意味着智能体通过分析你的查询历史来学习你的风格、你的兴趣、你的决策模式。所以它通过看到模式来推断隐藏的目标。

是的，对于生产系统，这对于可靠性至关重要。它意味着在检测到用户困扰时主动提供帮助，比如犹豫或多次尝试请求某事失败。这就是反应式工具和真正的有用智能体之间的区别。

所有这些中的最后技术步骤是动态上下文组装。这是在发送最终提示词之前将所有那些选择的、压缩的、加权的部分拉到一起。是的。

所以让我们转向，看看大框架实际上如何实现这些东西。看到这三个支柱如何映射到 ADK、Agno 和 LanGraph，真的很有启发性。你可以立即看到概念映射。

对于主会话状态，会话容器在 Google ADK 中称为会话。但在 LanGraph 中，他们称之为线程。它通常由中央检查点或服务管理以保存其状态。

知识类型之间的区别如此关键，特别是在 Agno 中。是的，Agno 特别地将知识（你用于事实的外部 RAG 数据）与记忆分开。记忆是关于用户学习的信息。

从互动历史中得出的他们的偏好。这种分离确保智能体知道什么是真实的，用户喜欢什么之间的区别。另一个关键架构决策是状态管理的粒度有多细。

Google ADK 似乎做得很好。他们通过在其状态对象上使用前缀来实现细粒度作用域。你可以将数据标记为用户，以便在该用户的会话中持久化。

或者应用程序使其在所有用户中持久化。这种控制对于管理规模至关重要。LanGraph，从工作流角度出发，提供了这种巨大的专门记忆机制来处理压缩。

是的，像对话缓冲窗口记忆用于那种滑动窗口方法。或特定的向量存储记忆类型用于跨会话语义检索。整个讨论只是在呼喊数据管理挑战。

确实。这将我们直接带到最后一部分，为鲁棒性工程，生产层。资料来源谈到了为什么高技能工程团队正在看这些统一的三合一数据库解决方案。

痛点是架构孤岛。你有高频聊天会话写入、复杂的 RAG 向量搜索和为记忆转移运行的分析查询。三个单独的数据库创建延迟和数据一致性风险。

关键问题是一致性。如果你的短期记忆说一件事，但另一个数据库中的长期记忆尚未更新，你会得到不一致的状态。资料来源称之为记忆分裂。

正是。统一存储解决方案通过提供三个技术优势来解决这个问题。第一，强一致性或 AC，它保证记忆分裂不会发生。

第二个是 HTP 能力。混合事务分析处理。这至关重要。

它让你能够在同一系统中以速度处理那些高频会话写入和自烘焙见解的复杂分析。你需要能够与你的客户交谈并同时分析他们所说的。

同时。第三，混合搜索。结合传统 SQL 查询（如最近性和频率）与向量搜索（如语义）的能力。

本地地。本地地。这让你可以在一个高效步骤中运行那些复杂的多维检索策略。

上下文工程根本上是数据库和分布式系统设计，这一认识直接导致了报告中的可操作路线图。每个团队应该优先考虑哪两个行动？第一，正式实施我们谈论过的记忆转移函数。确保高重要性的短期记忆可靠地整合到长期存储中。

第二。设计统一的检索链接。你不应该为会话历史和长期记忆点击单独的 API。

系统需要执行一个同时击中两者的单一高效查询。其结果就是他们所谓的融合上下文。融合上下文是生产 CE 的最终目标。

智能体每次都会收到一个完美组装的、相关的、准确的信息包。这将我们带回到起点。我们从 Day 的上下文的基本定义开始。

我们追溯了收集、管理和使用的三个支柱。我们看到了框架如何应用这些复杂的概念来构建可靠的智能体。上下文工程是将 AI 从沙盒带到生产的路线图。

它确保智能体在正确的时间以正确的格式获得正确的信息。所以 3.0 时代的最终成功取决于解决这个终身上下文问题。考虑到所涉及的信息的巨大规模，你的整个偏好和数据历史，智能体将如何管理语义一致性？它们将如何确保旧事实和兴趣保持准确和相关，同时保护你的隐私，因为它们存储你的整个互动历史？那是所有中最深入的探讨。

（由 TurboScribe.ai 转录。解除限制以移除此消息。）
