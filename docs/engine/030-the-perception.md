---
id: the-perception-implementation
sidebar_position: 3.0
title: Phase 3ï¼šThe Perception éªŒè¯å®æ–½æ–¹æ¡ˆ
last_update:
  author: Aurelius Huang
  created_at: 2026-01-09
  updated_at: 2026-01-13
  version: 1.2
  status: Reviewed
tags:
  - The Perception
  - Unified Search
  - Fusion Retrieval
  - Implementation Plan
  - PostgreSQL
  - Hybrid Search
---

> [!NOTE]
>
> **æ–‡æ¡£å®šä½**ï¼šæœ¬æ–‡æ¡£æ˜¯ [000-roadmap.md](./000-roadmap.md) Phase 3 çš„è¯¦ç»†å·¥ç¨‹å®æ–½æ–¹æ¡ˆï¼Œç”¨äºæŒ‡å¯¼ã€Œ**The Perception (ç¥ç»æ„ŸçŸ¥)**ã€çš„å®Œæ•´è½åœ°éªŒè¯å·¥ä½œã€‚æ¶µç›–æŠ€æœ¯è°ƒç ”ã€æ¶æ„è®¾è®¡ã€ä»£ç å®ç°ã€æµ‹è¯•éªŒè¯ç­‰å…¨æµç¨‹ã€‚
>
> **å‰ç½®ä¾èµ–**ï¼šæœ¬é˜¶æ®µä¾èµ– [010-the-pulse.md](./010-the-pulse.md) Phase 1 å’Œ [020-the-hippocampus.md](./020-the-hippocampus.md) Phase 2 çš„å®Œæˆï¼Œéœ€å¤ç”¨å…¶ç»Ÿä¸€å­˜å‚¨åŸºåº§ (Unified Schema) å’Œè®°å¿†ç®¡ç†èƒ½åŠ›ã€‚

---

## 1. æ‰§è¡Œæ‘˜è¦

### 1.1 å®šä½ä¸ç›®æ ‡ (Phase 3)

**Phase 3: The Perception** æ˜¯æ•´ä¸ªéªŒè¯è®¡åˆ’çš„æ£€ç´¢æ ¸å¿ƒé˜¶æ®µï¼Œå¯¹æ ‡äººç±»å¤§è„‘çš„**æ„ŸçŸ¥ç³»ç»Ÿ (Perception System)** â€”â€” è´Ÿè´£ä»æµ·é‡ä¿¡æ¯ä¸­å¿«é€Ÿå®šä½å’Œè¯†åˆ«ç›®æ ‡çš„ç¥ç»ä¸­æ¢ã€‚æ ¸å¿ƒç›®æ ‡æ˜¯ï¼š

1. **æ„å»º One-Shot Integrated æ£€ç´¢é“¾è·¯**ï¼šå®ç°å•æ¬¡ SQL æŸ¥è¯¢èåˆ Semantic (å‘é‡) + Keyword (BM25) + Structural (å…ƒæ•°æ®) ä¸‰ç§æ£€ç´¢ä¿¡å·
2. **éªŒè¯ RRF èåˆç®—æ³•**ï¼šå®ç° Reciprocal Rank Fusion ç®—æ³•ï¼Œåˆå¹¶å¤šè·¯å¬å›ç»“æœ
3. **éªŒè¯é«˜è¿‡æ»¤æ¯”åœºæ™¯**ï¼šéªŒè¯ HNSW è¿­ä»£æ‰«æåœ¨ 99% è¿‡æ»¤æ¯”ä¸‹çš„å¬å›ç‡ä¸æ€§èƒ½
4. **éªŒè¯ L1 Reranking**ï¼šé›†æˆè½»é‡çº§ Cross-Encoder æ¨¡å‹ï¼Œæå‡æ£€ç´¢ç²¾åº¦

```mermaid
graph LR
    subgraph "Phase 3: The Perception"
        F[Phase 1/2 åŸºåº§<br>Session + Memory] --> P1[Fusion Retrieval<br>èåˆæ£€ç´¢]
        F --> P2[High-Selectivity<br>é«˜è¿‡æ»¤æ¯”å¬å›]
        F --> P3[L1 Reranking<br>è¯­ä¹‰é‡æ’]
    end

    P1 & P2 & P3 --> V[Verification<br>éªŒæ”¶é€šè¿‡]
    V --> Phase4[Phase 4: Realm of Mind]

    style F fill:#065f46,stroke:#34d399,color:#fff
    style P1 fill:#7c2d12,stroke:#fb923c,color:#fff
    style P2 fill:#7c2d12,stroke:#fb923c,color:#fff
    style P3 fill:#7c2d12,stroke:#fb923c,color:#fff
```

### 1.2 æ ¸å¿ƒè®¾è®¡ (Core Architecture)

æœ¬ç« èŠ‚é˜è¿° The Perception çš„æ ¸å¿ƒè®¾è®¡ç†å¿µï¼Œéµå¾ª **æ­£äº¤åˆ†è§£ (Orthogonal Decomposition)** åŸåˆ™ï¼Œå°†æ£€ç´¢è¿‡ç¨‹è§£è€¦ä¸ºä¿¡å·æå–ã€å¤šè·¯å¬å›ä¸åˆ†å±‚æ’åºä¸‰ä¸ªç‹¬ç«‹ç»´åº¦ã€‚

#### 1.2.1 æ£€ç´¢ä¿¡å·æ­£äº¤æ€§ (Signal Orthogonality)

æˆ‘ä»¬å°†æ£€ç´¢ä¿¡å·è§£æ„ä¸ºä¸‰ä¸ªäº’ä¸é‡å çš„ç»´åº¦ï¼Œç¡®ä¿åœ¨ä¸åŒè®¤çŸ¥ç²’åº¦ä¸Šå®ç°å…¨è¦†ç›–ï¼š

| ç»´åº¦       | ä¿¡å·ç±»å‹ (Signal)     | è®¤çŸ¥å±‚é¢                                             | æŠ€æœ¯å®ç° (PostgreSQL)                                                                 |
| :--------- | :-------------------- | :--------------------------------------------------- | :------------------------------------------------------------------------------------ |
| **è¯­ä¹‰å±‚** | **Semantic Search**   | éšæ€§æ„å›¾ã€æ¦‚å¿µè”æƒ³<br>è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢ï¼ˆå‘é‡è·ç¦»ï¼‰     | `vector` (HNSW): `embedding <=> query_embedding`<br>æ•æ‰ "What you mean"              |
| **è¯æ³•å±‚** | **Keyword Search**    | æ˜¾æ€§å…³é”®è¯ã€ä¸“æœ‰åè¯<br>åŒ¹é…æ£€ç´¢ï¼ˆBM25/å…¨æ–‡æœç´¢ï¼‰    | `tsvector` (BM25): `to_tsvector @@ plainto_tsquery`<br>æ•æ‰ "What you said"           |
| **ç»“æ„å±‚** | **Structural Filter** | æ—¶ç©ºçº¦æŸã€æƒé™è¾¹ç•Œ<br>ç»“æ„åŒ–å…ƒæ•°æ®è¿‡æ»¤ï¼ˆJSONB/æ ‡é‡ï¼‰ | `jsonb` (GIN/B-Tree): `metadata @> '{"key": "value}'`<br>æ•æ‰ "Context & Constraints" |
| **ç©ºé—´å±‚** | **Spatial Search**    | åœ°ç†ä½ç½®ã€ç‰©ç†ç©ºé—´<br>LBS èŒƒå›´æ£€ç´¢ (Radius Search)   | `geography` (GiST): `ST_DWithin(loc, $p, $r)`<br>æ•æ‰ "Where it is"                   |

#### 1.2.2 æ„ŸçŸ¥é“¾è·¯ (Perception Pipeline)

æ£€ç´¢é“¾è·¯é‡‡ç”¨ **æ¼æ–—å‹æ¶æ„ (Funnel Architecture)**ï¼Œé€šè¿‡ä¸¤é˜¶æ®µå¤„ç†å®ç°ç”±ç²—åˆ°ç²¾çš„ **ç†µå‡ (Entropy Reduction)** è¿‡ç¨‹ã€‚

```mermaid
flowchart TB
    subgraph Input ["æ„ŸçŸ¥è¾“å…¥ (Sensory Input)"]
        Q[User Query]
        H[Conversation History]
    end

    subgraph Runtime ["Agent Runtime"]
        direction TB
        QR[Query Rewrite<br>æŒ‡ä»£æ¶ˆè§£ & æ„å›¾è¡¥å…¨]

        subgraph Extractor ["Signal Extraction (ä¿¡å·æå–)"]
            E_Vec[Vector Generation]
            E_Kwd[Keyword Extraction]
            E_Meta[Filter Parsing]
            E_Geo[Spatial Parsing]
        end

        subgraph Storage ["Cognizes Engine"]
            direction TB

            subgraph Signals ["æ­£äº¤å¬å› (Orthogonal Retrieval)"]
                S1[Semantic<br>HNSW]
                S2[Keyword<br>BM25]
                S3[Structural<br>JSONB]
                S4[Spatial<br>GiST]
            end

            RRF[RRF Fusion<br>å€’æ•°æ’åèåˆ]
        end

        L1[L1 Reranking<br>Cross-Encoder ç²¾æ’]
    end

    %% Flow
    Q & H --> QR
    QR --> E_Vec & E_Kwd & E_Meta & E_Geo

    E_Vec --> S1
    E_Kwd --> S2
    E_Meta --> S3
    E_Geo --> S4

    S1 & S2 & S3 & S4 --> RRF
    RRF -- "L0 Candidates (Top-50)" --> L1
    L1 -- "Final Results (Top-10)" --> Output([Context Chunks])

    %% Styling
    style Input fill:#1e3a5f,stroke:#60a5fa,color:#fff
    style Runtime fill:#7c2d12,stroke:#fb923c,color:#fff
    style Storage fill:#065f46,stroke:#34d399,color:#fff
```

#### 1.2.3 Two-Stage Retrieval (ä¸¤é˜¶æ®µæ£€ç´¢)

> [!IMPORTANT]
>
> **å¯¹æ ‡ Roadmap Pillar III**ï¼šThe Perception é‡‡ç”¨ä¸¤é˜¶æ®µæ£€ç´¢æ¶æ„ï¼Œåˆ†ç¦»â€œå¬å›â€ä¸â€œæ’åºâ€å…³æ³¨ç‚¹ï¼Œå¹³è¡¡æ€§èƒ½ã€å»¶è¿Ÿä¸ç²¾åº¦ã€‚

| é˜¶æ®µ                    | å®šä½                             | è¿è¡Œç¯å¢ƒ      | å»¶è¿Ÿé¢„ç®— (Latency) | å…³é”®æŒ‡æ ‡           | ç®—æ³•/æ¨¡å‹                    |
| :---------------------- | :------------------------------- | :------------ | :----------------- | :----------------- | :--------------------------- |
| **L0 ç²—æ’ (Recall)**    | **å¹¿åº¦ä¼˜å…ˆ**ï¼šç¡®ä¿ä¸æ¼æ‰ç›¸å…³ä¿¡æ¯ | PostgreSQL    | < 50ms             | Recall@50 > 95%    | HNSW + BM25 + RRF            |
| **L1 ç²¾æ’ (Precision)** | **æ·±åº¦ä¼˜å…ˆ**ï¼šä¸ä»…ç›¸å…³ï¼Œæ›´è¦ç²¾å‡† | Agent Runtime | < 200ms            | Precision@10 > 95% | BGE-Reranker (Cross-Encoder) |

### 1.3 æ‰§è¡Œå¯¼å›¾ (Execution Map)

#### 1.3.1 ä»»åŠ¡-æ–‡æ¡£é”šå®š

> [!NOTE]
>
> æœ¬æ‰§è¡Œå¯¼å›¾å¯¹é½ [001-task-checklist.md](./001-task-checklist.md) çš„ Phase 3 ä»»åŠ¡é›†ï¼Œå°†éªŒè¯å·¥ä½œåˆ’åˆ†ä¸º **Core Engine (æ ¸å¿ƒå¼•æ“)**ã€**Knowledge Base (çŸ¥è¯†åº“)** ä¸ **Support System (æ”¯æ’‘ç³»ç»Ÿ)** ä¸‰å¤§æ­£äº¤æµã€‚

| å®æ–½æµ (Stream)                               | ä»»åŠ¡æ¨¡å—            | ä»»åŠ¡ ID          | å¯¹åº”ç« èŠ‚ Anchor                                                                 |
| :-------------------------------------------- | :------------------ | :--------------- | :------------------------------------------------------------------------------ |
| **1. Core Engine**<br>_(Dynamic Memory)_      | Hybrid Search SQL   | P3-1-1 ~ P3-1-5  | [4.1 Step 1: Fusion Retrieval å®ç°](#41-step-1-fusion-retrieval-å®ç°)           |
|                                               | RRF Algorithm       | P3-1-6 ~ P3-1-9  | [4.1.2 RRF èåˆç®—æ³•](#412-rrf-èåˆç®—æ³•-reciprocal-rank-fusion)                  |
|                                               | High-Selectivity    | P3-2-1 ~ P3-2-4  | [4.2 Step 2: High-Selectivity Filtering](#42-step-2-high-selectivity-filtering) |
|                                               | L1 Reranking        | P3-2-5 ~ P3-2-8  | [4.3 Step 3: L1 Reranking å®ç°](#43-step-3-l1-reranking-å®ç°)                   |
| **2. Knowledge Base**<br>_(Static Knowledge)_ | KB Schema Design    | P3-4-7 ~ P3-4-10 | [3. Architecture: Perception Schema](#3-æ¶æ„è®¾è®¡perception-schema)              |
|                                               | RAG Pipeline        | P3-5-1 ~ P3-5-5  | [4.4 Step 4: Knowledge RAG Pipeline](#)                                         |
|                                               | Hybrid Validation   | P3-5-6 ~ P3-5-13 | [4.4.2 Hybrid Search èåˆ](#)                                                   |
| **3. Support System**<br>_(Observability)_    | AG-UI Visualization | P3-4-1 ~ P3-4-6  | [4.5 Step 5: Glass-Box Visualization](#)                                        |
| **4. Delivery**                               | éªŒæ”¶ä¸æ–‡æ¡£          | P3-3-1 ~ P3-3-4  | [5. éªŒæ”¶æ ‡å‡†](#5-éªŒæ”¶æ ‡å‡†) + [6. äº¤ä»˜ç‰©](#6-äº¤ä»˜ç‰©æ¸…å•)                         |

#### 1.3.2 å·¥æœŸè§„åˆ’ (1.5 Days)

> [!IMPORTANT]
>
> **Timeline Adjustment**: ç”±äºå¢åŠ äº† Knowledge Base (RAG) ä¸ Visualization (AG-UI) çš„éªŒè¯èŒƒå›´ï¼ŒPhase 3 é¢„ä¼°å·¥æœŸè°ƒæ•´ä¸º **1.5 Days**ã€‚

| é˜¶æ®µ    | å®æ–½å†…å®¹ (Activity)                                                 | å…³é”®äº§å‡º (Deliverables)                      | é¢„ä¼°å·¥æœŸ |
| :------ | :------------------------------------------------------------------ | :------------------------------------------- | :------- |
| **3.1** | **Core Retrieval Construction**<br>(Fusion SQL + RRF + HNSW Tuning) | `hybrid_search.sql`<br>`rrf_fusion.py`       | 0.5 Day  |
| **3.2** | **Precision Engineering**<br>(Reranking + High-Selectivity)         | `reranker.py`<br>Recall/Precision Benchmarks | 0.25 Day |
| **3.3** | **Knowledge Base Integration**<br>(KB Schema + RAG Pipeline)        | `knowledge_schema.sql`<br>`rag_pipeline.py`  | 0.5 Day  |
| **3.4** | **System Visualization**<br>(AG-UI Events + End-to-End Test)        | `SearchVisualizer` Class<br>Test Report      | 0.25 Day |

---

## 2. æ ¸å¿ƒå‚è€ƒæ¨¡å‹ï¼šæ£€ç´¢æœºåˆ¶æ„ŸçŸ¥ç³»ç»Ÿ

### 2.1 å¯¹æ ‡åˆ†æï¼šGoogle Vertex AI

åŸºäº Google Vertex AI RAG Engine å’Œ ADK æ–‡æ¡£<sup>[[1]](#ref1)</sup>çš„æ·±åº¦è°ƒç ”ï¼Œæˆ‘ä»¬å°†å¤åˆ»ä»¥ä¸‹æ ¸å¿ƒèƒ½åŠ›ï¼Œæ„å»º **PostgreSQL-Native** çš„æ„ŸçŸ¥åŸºåº§ï¼š

| æ ¸å¿ƒç»„ä»¶      | Google Vertex AI èƒ½åŠ›       | PostgreSQL å¤åˆ»ç­–ç•¥ (Glass-Box)                    |
| :------------ | :-------------------------- | :------------------------------------------------- |
| **Vector DB** | æ‰˜ç®¡å‘é‡æ£€ç´¢æœåŠ¡ (ScaNN)    | **PGVector** (HNSW ç´¢å¼•)                           |
| **Corpus**    | è¯­æ–™åº“ç®¡ç† (Managed Corpus) | `knowledge_base` (Static) + `memories` (Dynamic)   |
| **Retrieval** | æ··åˆæ£€ç´¢ (Hybrid Search)    | **One-Shot SQL** (`vector` + `tsvector` + `jsonb`) |
| **Fusion**    | ç»“æœèåˆ (Result Merging)   | **RRF Algorithm** (Reciprocal Rank Fusion)         |
| **Ranking**   | é‡æ’ API (Ranking API)      | **Cross-Encoder** (Local Inference)                |

#### 2.1.1 RAG æ¶æ„ç®¡é“ (Architecture Pipeline)

```mermaid
sequenceDiagram
    participant User
    participant Runtime as Agent Runtime
    participant Engine as Cognizes Engine
    participant Rerank as L1 Reranker

    User->>Runtime: Inquiry
    Runtime->>Engine: retrieve(query, filters)

    rect rgb(6, 95, 70)
        note right of Engine: L0 Retrieval (PostgreSQL)
        par Parallel Execution
            Engine->>Engine: Semantic Search (HNSW)
            Engine->>Engine: Keyword Search (BM25)
        end
        Engine->>Engine: RRF Fusion (Top-100)
    end

    Engine-->>Runtime: L0 Candidates

    rect rgb(124, 45, 18)
        note right of Runtime: L1 Precision (Python)
        Runtime->>Rerank: Cross-Encode(Query, Candidates)
        Rerank-->>Runtime: Re-scored Results
    end

    Runtime->>User: Synthesized Response
```

### 2.2 æ··åˆæ£€ç´¢ç­–ç•¥ (Hybrid Retrieval)

æ··åˆæ£€ç´¢é€šè¿‡ç»“åˆ **Semantic (è¯­ä¹‰)** ä¸ **Lexical (è¯æ³•)** ä¸¤ç§æ­£äº¤çš„æ£€ç´¢ä¿¡å·ï¼Œè§£å†³å•ä¸€æ£€ç´¢æ¨¡å¼çš„ç›²åŒºã€‚

| ä¿¡å·ç»´åº¦     | æŠ€æœ¯å®ç°         | ä¼˜åŠ¿åœºæ™¯                      | ç›²åŒº                         |
| :----------- | :--------------- | :---------------------------- | :--------------------------- |
| **Semantic** | Embedding (HNSW) | æ¦‚å¿µè”æƒ³ã€è·¨è¯­è¨€ã€æ„å›¾ç†è§£    | ä¸“æœ‰åè¯ã€ç²¾ç¡®åŒ¹é…ã€ä½é¢‘è¯   |
| **Lexical**  | BM25 (GIN)       | ç²¾ç¡®å…³é”®è¯ã€ä»£ç ç‰‡æ®µã€ID åŒ¹é… | åŒä¹‰è¯ã€è¯­ä¹‰æ¼‚ç§»ã€ä¸Šä¸‹æ–‡ç¼ºå¤± |

#### 2.2.1 PostgreSQL One-Shot Implementation

ä¸åŒäºä¼ ç»Ÿæ¶æ„éœ€åˆ†åˆ«æŸ¥è¯¢ Vector DB å’Œ Search Engineï¼ŒPostgreSQL æ”¯æŒé€šè¿‡ **CTE (Common Table Expressions)** å®ç°å•æ¬¡ SQL äº¤äº’çš„æ··åˆæ£€ç´¢ï¼š

```sql
WITH semantic AS (
    SELECT id, 1 - (embedding <=> $emb) as score FROM docs ORDER BY embedding <=> $emb LIMIT 50
),
keyword AS (
    SELECT id, ts_rank_cd(tsv, $query) as score FROM docs WHERE tsv @@ $query ORDER BY score DESC LIMIT 50
)
-- RRF Fusion Logic in SQL ...
```

### 2.3 èåˆç®—æ³• (RRF Algorithm)

**Reciprocal Rank Fusion (RRF)** æ˜¯ä¸€ç§æ— éœ€è°ƒå‚çš„ç¨³å¥èåˆç®—æ³•ï¼Œå…¬å¼å¦‚ä¸‹ï¼š

$$
    \text{Score}_{RRF}(d) = \sum_{r \in R} \frac{1}{k + rank_r(d)}
$$

å…¶ä¸­ï¼š

- $d$ æ˜¯æ–‡æ¡£
- $R$ æ˜¯æ‰€æœ‰æ£€ç´¢å™¨çš„æ’ååˆ—è¡¨
- $r(d)$ æ˜¯æ–‡æ¡£ $d$ åœ¨æ£€ç´¢å™¨ä¸­çš„æ’å (ä» 1 å¼€å§‹)
- $k$ æ˜¯å¹³æ»‘å¸¸æ•° (é€šå¸¸å– 60)

> [!TIP]
>
> **Why RRF?** ç›¸æ¯”çº¿æ€§åŠ æƒ (Weighted Sum)ï¼ŒRRF ä¸ä¾èµ–åˆ†æ•°çš„ç»å¯¹å€¼ï¼ˆå‘é‡è·ç¦» vs BM25 åˆ†æ•°å¾ˆéš¾å½’ä¸€åŒ–ï¼‰ï¼Œä»…ä¾èµ–ç›¸å¯¹æ’åï¼Œé²æ£’æ€§æ›´å¼ºã€‚å³ä½¿æŸä¸€æ£€ç´¢è·¯ "å¤±æ•ˆ"ï¼ˆè¿”å›æ— å…³ç»“æœï¼‰ï¼ŒRRF ä¹Ÿèƒ½ä¿è¯ç›¸å…³æ–‡æ¡£è¢«å¦ä¸€è·¯ "æå›"ã€‚
>
> **RRF ç¤ºä¾‹è®¡ç®—**
>
> | æ–‡æ¡£ | å‘é‡æ£€ç´¢æ’å | å…³é”®è¯æ£€ç´¢æ’å | RRF åˆ†æ•° (k=60)              |
> | :--- | :----------- | :------------- | :--------------------------- |
> | A    | 1            | 3              | 1/(60+1) + 1/(60+3) = 0.0325 |
> | B    | 2            | 1              | 1/(60+2) + 1/(60+1) = 0.0325 |
> | C    | 3            | 2              | 1/(60+3) + 1/(60+2) = 0.0322 |
> | D    | 5            | -              | 1/(60+5) = 0.0154            |
>
> **è§‚å¯Ÿ**ï¼šæ–‡æ¡£ A å’Œ B çš„ RRF åˆ†æ•°ç›¸åŒï¼Œè¯´æ˜ RRF å¯¹ä¸åŒæ£€ç´¢å™¨çš„æ’åç»™äºˆç­‰æƒé‡ã€‚

### 2.4 å·¥ç¨‹æŒ‘æˆ˜ï¼šé«˜è¿‡æ»¤æ¯” (High-Selectivity)

> [!WARNING]
> **The Top-K Trap**: åœ¨ "Strict Filtering" (å¦‚ç§æœ‰è®°å¿†æ£€ç´¢) åœºæ™¯ä¸‹ï¼Œè‹¥ç¬¦åˆæ¡ä»¶çš„æ•°æ®æå°‘ (e.g., 0.1%)ï¼Œç”±äº HNSW çš„è¿‘ä¼¼æœ€è¿‘é‚»ç‰¹æ€§ï¼Œæ ‡å‡† Top-K æŸ¥è¯¢å¯èƒ½è¿”å›ç©ºé›†ã€‚

**è§£å†³æ–¹æ¡ˆ**: å¯ç”¨ PGVector 0.8.0+ çš„ **Iterative Index Scan**ã€‚å³åœ¨ç´¢å¼•æ‰«ææœªæ»¡è¶³ `LIMIT` æ—¶ï¼Œè‡ªåŠ¨æ‰©å¤§æœç´¢åŠå¾„ï¼Œç›´åˆ°æ‰¾åˆ°è¶³å¤Ÿçš„ç¬¦åˆå…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶çš„è®°å½•ã€‚

```sql
SET hnsw.iterative_scan = relaxed_order; -- ç‰ºç‰²ä¸¥æ ¼é¡ºåºæ¢å–å¬å›ç‡
SET hnsw.max_scan_tuples = 20000;        -- è®¾å®šæ‰«æä¸Šé™é˜²æ­¢å…¨è¡¨æ‰«æ
```

### 2.5 ç²¾æ’ç­–ç•¥ (L1 Reranking)

L0 æ£€ç´¢å…³æ³¨ **Recall (å¬å›ç‡)**ï¼ŒL1 é‡æ’å…³æ³¨ **Precision (å‡†ç¡®ç‡)**ã€‚

| é˜¶æ®µ             | æ¨¡å‹æ¶æ„          | ç‰¹æ€§                                 | å»¶è¿Ÿé¢„ç®— |
| :--------------- | :---------------- | :----------------------------------- | :------- |
| **L0 Recall**    | Bi-Encoder        | å‘é‡é¢„è®¡ç®—ï¼Œæå¿«                     | < 50ms   |
| **L1 Precision** | **Cross-Encoder** | Query-Doc è”åˆç¼–ç ï¼Œæ·±åº¦äº¤äº’ï¼Œé«˜ç²¾åº¦ | < 200ms  |

**é€‰å‹å»ºè®®**:

- **Base**: `BAAI/bge-reranker-base` (Balance)
- **High-Performance**: `BAAI/bge-reranker-v2-m3` (Multi-Lingual)

---

## 3. æ¶æ„è®¾è®¡ï¼šPerception Schema

### 3.1 Knowledge vs Memory åŒå­˜å‚¨æ¶æ„

> [!IMPORTANT]
>
> **æ ¸å¿ƒåŒºåˆ†**ï¼šThe Perception éœ€è¦æ”¯æŒä¸¤ç§ä¸åŒç±»å‹çš„æ£€ç´¢åœºæ™¯ï¼Œå¯¹åº”ä¸åŒçš„å­˜å‚¨è¡¨ï¼š
>
> - **Knowledge Base**ï¼ˆé™æ€çŸ¥è¯†ï¼‰ï¼šé¢„å…ˆå¯¼å…¥çš„å¤–éƒ¨æ–‡æ¡£ï¼Œå…¨å±€/ç§Ÿæˆ·çº§å…±äº«ï¼ŒæŒä¹…åŒ–å­˜å‚¨
> - **Memory**ï¼ˆåŠ¨æ€è®°å¿†ï¼‰ï¼šAgent ä¸ç”¨æˆ·äº¤äº’ç”Ÿæˆï¼Œç”¨æˆ·çº§ç§æœ‰ï¼Œæœ‰é—å¿˜æ›²çº¿

#### 3.1.1 Knowledge vs Memory æ¦‚å¿µå¯¹æ¯”

| ç»´åº¦         | **Knowledge (çŸ¥è¯†)**                   | **Memory (è®°å¿†)**                   |
| :----------- | :------------------------------------- | :---------------------------------- |
| **æ¥æº**     | é¢„å…ˆå¯¼å…¥çš„å¤–éƒ¨æ–‡æ¡£ï¼ˆPDF/Markdown/FAQï¼‰ | Agent ä¸ç”¨æˆ·äº¤äº’åŠ¨æ€ç”Ÿæˆ            |
| **ç‰¹ç‚¹**     | é™æ€ã€å…±äº«ã€ç»“æ„åŒ–/éç»“æ„åŒ–            | åŠ¨æ€ã€ä¸ªäººåŒ–ã€æƒ…æ™¯åŒ–                |
| **ç”Ÿå‘½å‘¨æœŸ** | **æŒä¹…åŒ–**ï¼Œä¸ä¼šè‡ªåŠ¨é—å¿˜               | **æœ‰é—å¿˜æ›²çº¿**ï¼Œä½é¢‘è®¿é—®ä¼šè¡°å‡      |
| **æ‰€æœ‰æƒ**   | å…¨å±€/ç§Ÿæˆ·çº§åˆ«ï¼ˆå¤šç”¨æˆ·å…±äº«ï¼‰            | ç”¨æˆ·çº§åˆ«ï¼ˆä¸ªäººç§æœ‰ï¼‰                |
| **å…¸å‹åœºæ™¯** | ä¼ä¸šæ–‡æ¡£ã€FAQã€äº§å“æ‰‹å†Œã€æ”¿ç­–æ³•è§„      | å¯¹è¯å†å²ã€ç”¨æˆ·åå¥½ã€æƒ…æ™¯è®°å¿†        |
| **å¯¹æ ‡ç³»ç»Ÿ** | RAGFlow Corpusã€Dify RAG Engine        | LangGraph `Store`ã€ADK `MemoryBank` |
| **å­˜å‚¨è¡¨**   | `knowledge_base`                       | `memories` + `facts`                |

#### 3.1.2 åŒå­˜å‚¨ ER å›¾ (Dual-Store Schema)

```mermaid
erDiagram
    %% 1. Dynamic Memory Stream (åŠ¨æ€è®°å¿†æµ)
    threads ||--o{ memories : "generates"
    memories ||--o{ facts : "extracts"

    threads {
        uuid id PK "ä¼šè¯ ID (Session Container)"
        varchar user_id "ç”¨æˆ·æ ‡è¯†"
        varchar app_name "åº”ç”¨æ ‡è¯†"
        jsonb state "å½“å‰ä¸Šä¸‹æ–‡çŠ¶æ€"
        int version "OCC ç‰ˆæœ¬å·"
    }

    memories {
        uuid id PK "è®°å¿† ID"
        uuid thread_id FK "æ¥æºä¼šè¯ (Source Trace)"
        varchar user_id FK "ç”¨æˆ·æ ‡è¯†"
        varchar app_name FK "åº”ç”¨æ ‡è¯†"
        text content "è®°å¿†å†…å®¹ (Snapshot/Summary)"
        vector embedding "å‘é‡åµŒå…¥ (1536D)"
        tsvector search_vector "å…¨æ–‡æœç´¢å‘é‡"
        jsonb metadata "å…ƒæ•°æ®"
        float retention_score "é—å¿˜æ›²çº¿åˆ†æ•°"
        timestamp created_at "åˆ›å»ºæ—¶é—´"
    }

    facts {
        uuid id PK "äº‹å® ID"
        uuid memory_id FK "æ¥æºè®°å¿†"
        text fact_content "æå–çš„äº‹å®"
        vector embedding "å‘é‡åµŒå…¥"
        tsvector search_vector "å…¨æ–‡æœç´¢å‘é‡"
        varchar key "äº‹å®é”® (e.g. 'preference')"
        jsonb value "ç»“æ„åŒ–å€¼ (Semantic Knowledge)"
        float confidence "ç½®ä¿¡åº¦"
    }

    %% 2. Static Knowledge Base (é™æ€çŸ¥è¯†åº“)
    corpus ||--o{ knowledge_base : "contains"

    corpus {
        uuid id PK "è¯­æ–™åº“ ID"
        varchar app_name FK "åº”ç”¨æ ‡è¯†"
        varchar name "è¯­æ–™åº“åç§°"
        text description "æè¿°"
        jsonb config "é…ç½® (chunking, embedding)"
        timestamp created_at "åˆ›å»ºæ—¶é—´"
    }

    knowledge_base {
        uuid id PK "çŸ¥è¯†å— ID"
        uuid corpus_id FK "æ‰€å±è¯­æ–™åº“"
        varchar app_name FK "åº”ç”¨æ ‡è¯†"
        text content "é™æ€çŸ¥è¯†åˆ‡ç‰‡"
        vector embedding "å‘é‡åµŒå…¥ (1536D)"
        tsvector search_vector "å…¨æ–‡ç´¢å¼• (GIN)"
        text source_uri "æ¥æºæ–‡ä»¶ URI"
        jsonb metadata "ç»“æ„åŒ–å…ƒæ•°æ® (Complex Filter)"
        int chunk_index "åˆ†å—åºå·"
        timestamp created_at "åˆ›å»ºæ—¶é—´"
    }
```

ä¸Šå›¾å±•ç¤ºäº† Perception Engine çš„ **"åŒå­˜å‚¨-ä¸‰ä¿¡å·" (Dual-Store, Tri-Signal)** æ­£äº¤æ¶æ„ï¼š

1. **å­˜å‚¨æ­£äº¤æ€§ (Storage Orthogonality)**ï¼š
   - **å·¦ä¾§ (Dynamic Memory)**ï¼šä»¥ `threads` ä¸ºæºå¤´ï¼Œè®°å½• User-Agent çš„äº¤äº’å†å²ã€‚æ•°æ®æ˜¯**æµå¼ç”Ÿé•¿**çš„ï¼Œå…·æœ‰**æ—¶æ•ˆæ€§**ï¼ˆéœ€é—å¿˜ï¼‰ï¼ŒæœåŠ¡äº "Personal Context"ã€‚
   - **å³ä¾§ (Static Knowledge)**ï¼šä»¥ `corpus` ä¸ºå®¹å™¨ï¼Œå­˜å‚¨é¢„ç½®çš„é¢†åŸŸçŸ¥è¯†ã€‚æ•°æ®æ˜¯**é™æ€å¯¼å…¥**çš„ï¼Œå…·æœ‰**æƒå¨æ€§**ï¼ˆä¸é—å¿˜ï¼‰ï¼ŒæœåŠ¡äº "Domain Capability"ã€‚
2. **ä¿¡å·å®Œå¤‡æ€§ (Signal Completeness)**ï¼š
   - `memories` å’Œ `knowledge_base` è¡¨å‡åŒæ—¶åŒ…å« `embedding` (è¯­ä¹‰ä¿¡å·)ã€`search_vector` (è¯æ³•ä¿¡å·) å’Œ `metadata/state` (ç»“æ„åŒ–ä¿¡å·)ï¼Œç¡®ä¿äº†æ£€ç´¢é“¾è·¯åœ¨ç‰©ç†å±‚é¢çš„**åŒæ„æ€§**ï¼Œä»è€Œæ”¯æŒä¸Šå±‚ç»Ÿä¸€çš„ **Hybrid Search** æ¥å£ã€‚
3. **æº¯æºæ€§ (Traceability)**ï¼š
   - åŠ¨æ€è®°å¿†é€šè¿‡ `thread_id` ä¸¥æ ¼é”šå®šåˆ°åŸå§‹ä¼šè¯ï¼Œä¸ä»…èƒ½å›ç­” "ç”¨æˆ·å–œå¥½ä»€ä¹ˆ"ï¼Œè¿˜èƒ½è¿½æº¯ "è¿™æ˜¯åœ¨å“ªæ¬¡å¯¹è¯ä¸­æå–çš„"ï¼Œå®ç°äº†è®°å¿†çš„å¯è§£é‡Šæ€§ã€‚

#### 3.1.3 æ£€ç´¢åœºæ™¯å¯¹åº”

| æ£€ç´¢åœºæ™¯           | å­˜å‚¨è¡¨           | è¿‡æ»¤æ¡ä»¶                | å…¸å‹æŸ¥è¯¢                 |
| :----------------- | :--------------- | :---------------------- | :----------------------- |
| **Knowledge æ£€ç´¢** | `knowledge_base` | `corpus_id`, `app_name` | "å…¬å¸å¹´å‡æ”¿ç­–æ˜¯ä»€ä¹ˆ?"    |
| **Memory æ£€ç´¢**    | `memories`       | `user_id`, `app_name`   | "ç”¨æˆ·ä¹‹å‰è¯´è¿‡ä»€ä¹ˆåå¥½?"  |
| **Unified æ£€ç´¢**   | ä¸¤è¡¨è”åˆ         | `app_name` + RRF èåˆ   | ç»“åˆçŸ¥è¯†åº“ä¸ç”¨æˆ·è®°å¿†å›ç­” |

### 3.2 Knowledge Base Schema è®¾è®¡

> [!NOTE]
>
> **NEW**: æ–°å¢ `corpus` å’Œ `knowledge_base` è¡¨ï¼Œç”¨äºå­˜å‚¨é™æ€çŸ¥è¯†ï¼Œä¸ `memories` è¡¨ï¼ˆåŠ¨æ€è®°å¿†ï¼‰åˆ†ç¦»ã€‚

#### 3.2.1 Corpus è¡¨ (è¯­æ–™åº“)

```sql
-- è¯­æ–™åº“ç®¡ç†è¡¨
CREATE TABLE IF NOT EXISTS corpus (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    app_name VARCHAR(255) NOT NULL,
    name VARCHAR(255) NOT NULL,
    description TEXT,
    config JSONB DEFAULT '{}',  -- chunking_strategy, embedding_model, etc.
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),

    UNIQUE(app_name, name)
);

-- ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_corpus_app_name ON corpus(app_name);

COMMENT ON TABLE corpus IS 'è¯­æ–™åº“ç®¡ç†è¡¨ï¼Œç”¨äºç®¡ç† Knowledge Base çš„é¡¶å±‚å®¹å™¨';
```

#### 3.2.2 Knowledge Base è¡¨ (çŸ¥è¯†å—)

```sql
-- çŸ¥è¯†å—å­˜å‚¨è¡¨ (é™æ€çŸ¥è¯†)
CREATE TABLE IF NOT EXISTS knowledge_base (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    corpus_id UUID NOT NULL REFERENCES corpus(id) ON DELETE CASCADE,
    app_name VARCHAR(255) NOT NULL,

    -- å†…å®¹å­—æ®µ
    content TEXT NOT NULL,
    embedding vector(1536),
    search_vector tsvector,

    -- æ¥æºè¿½æº¯
    source_uri TEXT,                -- åŸå§‹æ–‡ä»¶è·¯å¾„/URL
    chunk_index INTEGER DEFAULT 0,   -- åˆ†å—åºå·

    -- å…ƒæ•°æ®
    metadata JSONB DEFAULT '{}',     -- author, tags, version, etc.

    -- æ—¶é—´æˆ³
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- å‘é‡ç´¢å¼• (HNSW)
CREATE INDEX IF NOT EXISTS idx_kb_embedding
    ON knowledge_base USING hnsw (embedding vector_cosine_ops)
    WITH (m = 16, ef_construction = 64);

-- å…¨æ–‡ç´¢å¼• (GIN)
CREATE INDEX IF NOT EXISTS idx_kb_search_vector
    ON knowledge_base USING GIN (search_vector);

-- è¿‡æ»¤ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_kb_corpus_app
    ON knowledge_base(corpus_id, app_name);

-- è‡ªåŠ¨æ›´æ–° search_vector è§¦å‘å™¨
CREATE OR REPLACE FUNCTION kb_search_vector_trigger()
RETURNS trigger AS $$
BEGIN
    NEW.search_vector := to_tsvector('english', COALESCE(NEW.content, ''));
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_kb_search_vector
    BEFORE INSERT OR UPDATE ON knowledge_base
    FOR EACH ROW
    EXECUTE FUNCTION kb_search_vector_trigger();

COMMENT ON TABLE knowledge_base IS 'çŸ¥è¯†å—å­˜å‚¨è¡¨ï¼Œç”¨äº RAG Pipeline çš„é™æ€çŸ¥è¯†æ£€ç´¢';
```

### 3.3 Memory Schema æ‰©å±•

> [!NOTE]
>
> **å»¶ç»­ Phase 2**ï¼šå¤ç”¨ Hippocampus å·²å»ºç«‹çš„ `memories` å’Œ `facts` è¡¨ï¼Œä»…éœ€æ·»åŠ å…¨æ–‡æœç´¢æ”¯æŒã€‚

#### 3.3.1 æ–°å¢ tsvector åˆ—

```sql
-- åœ¨ memories è¡¨æ·»åŠ å…¨æ–‡æœç´¢å‘é‡åˆ—
ALTER TABLE memories ADD COLUMN IF NOT EXISTS
    search_vector tsvector;

-- åˆ›å»ºè§¦å‘å™¨è‡ªåŠ¨æ›´æ–° search_vector
CREATE OR REPLACE FUNCTION memories_search_vector_trigger()
RETURNS trigger AS $$
BEGIN
    NEW.search_vector := to_tsvector('english', COALESCE(NEW.content, ''));
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_memories_search_vector
    BEFORE INSERT OR UPDATE ON memories
    FOR EACH ROW
    EXECUTE FUNCTION memories_search_vector_trigger();

-- åˆ›å»º GIN ç´¢å¼•åŠ é€Ÿå…¨æ–‡æœç´¢
CREATE INDEX IF NOT EXISTS idx_memories_search_vector
    ON memories USING GIN (search_vector);
```

### 3.4 ç´¢å¼•ç­–ç•¥

| å­˜å‚¨è¡¨           | åˆ—              | ç´¢å¼•ç±»å‹ | ç”¨é€”       |
| :--------------- | :-------------- | :------- | :--------- |
| `knowledge_base` | `embedding`     | HNSW     | è¯­ä¹‰æ£€ç´¢   |
| `knowledge_base` | `search_vector` | GIN      | å…³é”®è¯æ£€ç´¢ |
| `knowledge_base` | `corpus_id`     | BTREE    | è¯­æ–™åº“è¿‡æ»¤ |
| `memories`       | `embedding`     | HNSW     | è¯­ä¹‰æ£€ç´¢   |
| `memories`       | `search_vector` | GIN      | å…³é”®è¯æ£€ç´¢ |
| `memories`       | `user_id`       | BTREE    | ç”¨æˆ·è¿‡æ»¤   |

> [!IMPORTANT]
>
> **ä¸‰é‡ç´¢å¼•ç­–ç•¥**ï¼šä¸ºæ”¯æŒ One-Shot Hybrid Searchï¼Œéœ€è¦åŒæ—¶ç»´æŠ¤ä¸‰ç±»ç´¢å¼•ã€‚

| ç´¢å¼•ç±»å‹     | ç›®æ ‡åˆ—                | ç´¢å¼•ç®—æ³• | ç”¨é€”            |
| :----------- | :-------------------- | :------- | :-------------- |
| **å‘é‡ç´¢å¼•** | `embedding`           | HNSW     | è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢  |
| **å…¨æ–‡ç´¢å¼•** | `search_vector`       | GIN      | BM25 å…³é”®è¯æ£€ç´¢ |
| **æ ‡é‡ç´¢å¼•** | `user_id`, etc.       | BTREE    | å…ƒæ•°æ®è¿‡æ»¤      |
| **å¤åˆç´¢å¼•** | `(user_id, app_name)` | BTREE    | é«˜é¢‘è¿‡æ»¤åœºæ™¯    |

### 3.5 JSONB Complex Predicates è®¾è®¡

> [!IMPORTANT]
>
> **å¯¹æ ‡ Roadmap Pillar III**: Complex Predicates æ”¯æŒåŸºäº JSONB çš„ä»»æ„æ·±åº¦çš„å¸ƒå°”é€»è¾‘è¿‡æ»¤ï¼Œæ˜¯ The Perception åŒºåˆ«äºç®€å•å‘é‡æ£€ç´¢çš„æ ¸å¿ƒèƒ½åŠ›ã€‚

#### 3.5.1 JSONB è¿‡æ»¤è¯­æ³•å‚è€ƒ

| åœºæ™¯             | SQL è¯­æ³•                                      | è¯´æ˜                     |
| :--------------- | :-------------------------------------------- | :----------------------- | ------------ |
| **ç®€å•é”®å€¼åŒ¹é…** | `metadata @> '{"type": "note"}'`              | åŒ…å«æŒ‡å®šé”®å€¼å¯¹           |
| **åµŒå¥—å¯¹è±¡åŒ¹é…** | `metadata @> '{"author": {"role": "admin"}}'` | ä»»æ„æ·±åº¦åµŒå¥—             |
| **æ•°ç»„å…ƒç´ åŒ…å«** | `metadata @> '{"tags": ["important"]}'`       | æ•°ç»„åŒ…å«æŒ‡å®šå…ƒç´          |
| **è·¯å¾„å–å€¼æ¯”è¾ƒ** | `metadata->'author'->>'role' = 'admin'`       | æå–è·¯å¾„å€¼è¿›è¡Œæ¯”è¾ƒ       |
| **æ•°å€¼èŒƒå›´è¿‡æ»¤** | `(metadata->>'priority')::int > 5`            | ç±»å‹è½¬æ¢åæ•°å€¼æ¯”è¾ƒ       |
| **å­˜åœ¨æ€§æ£€æŸ¥**   | `metadata ? 'urgent'`                         | æ£€æŸ¥ key æ˜¯å¦å­˜åœ¨        |
| **å¤šé”®å­˜åœ¨æ£€æŸ¥** | `metadata ?& array['type', 'status']`         | åŒæ—¶å­˜åœ¨å¤šä¸ª key         |
| **ä»»ä¸€é”®å­˜åœ¨**   | `metadata ?                                   | array['vip', 'premium']` | å­˜åœ¨ä»»ä¸€ key |

#### 3.5.2 ä¸»æµä¸šåŠ¡åœºæ™¯ç¤ºä¾‹

> [!NOTE]
>
> ä»¥ä¸‹ä¸šåŠ¡åœºæ™¯ç»è¿‡æ­£äº¤åˆ†æï¼Œè¦†ç›– RAG ç³»ç»Ÿçš„ä¸»æµè¿‡æ»¤éœ€æ±‚ç»´åº¦ã€‚

##### åœºæ™¯ 1ï¼šå¤šç§Ÿæˆ·éš”ç¦» (Multi-Tenant Isolation)

```sql
-- ä¸šåŠ¡éœ€æ±‚ï¼šSaaS å¹³å°ä¸­æ¯ä¸ªç§Ÿæˆ·åªèƒ½æ£€ç´¢è‡ªå·±çš„çŸ¥è¯†åº“
-- è¿‡æ»¤æ¡ä»¶ï¼štenant_id (å¼ºè¿‡æ»¤ï¼Œé«˜é€‰æ‹©æ€§)
SELECT id, content, embedding <=> $query_embedding AS distance
FROM memories
WHERE
    metadata @> '{"tenant_id": "org_acme_corp"}'
    AND user_id = $user_id
ORDER BY embedding <=> $query_embedding
LIMIT 10;

-- ä¼˜åŒ–ï¼šä¸ºé«˜é¢‘ç§Ÿæˆ·åˆ›å»ºéƒ¨åˆ†ç´¢å¼•
CREATE INDEX idx_memories_tenant_acme
    ON memories USING hnsw (embedding vector_cosine_ops)
    WHERE metadata @> '{"tenant_id": "org_acme_corp"}';
```

##### åœºæ™¯ 2ï¼šæƒé™æ§åˆ¶ (Access Control)

```sql
-- ä¸šåŠ¡éœ€æ±‚ï¼šæ ¹æ®ç”¨æˆ·è§’è‰²è¿‡æ»¤å¯è®¿é—®çš„çŸ¥è¯†
-- è¿‡æ»¤æ¡ä»¶ï¼šaccess_level, department (ç»„åˆæ¡ä»¶)
SELECT id, content, embedding <=> $query_embedding AS distance
FROM memories
WHERE
    -- è®¿é—®çº§åˆ«æ£€æŸ¥ï¼šç”¨æˆ·çº§åˆ« >= æ–‡æ¡£çº§åˆ«
    (metadata->>'access_level')::int <= $user_access_level
    -- éƒ¨é—¨å½’å±æ£€æŸ¥ï¼šç”¨æˆ·æ‰€å±éƒ¨é—¨æˆ–å…¬å¼€æ–‡æ¡£
    AND (
        metadata @> '{"visibility": "public"}'
        OR metadata->'departments' @> $user_department::jsonb
    )
ORDER BY embedding <=> $query_embedding
LIMIT 10;
```

##### åœºæ™¯ 3ï¼šæ—¶é—´èŒƒå›´è¿‡æ»¤ (Time-Based Filtering)

```sql
-- ä¸šåŠ¡éœ€æ±‚ï¼šåªæ£€ç´¢ç‰¹å®šæ—¶é—´æ®µå†…çš„è®°å¿†
-- è¿‡æ»¤æ¡ä»¶ï¼šcreated_at, updated_at (èŒƒå›´è¿‡æ»¤)
SELECT id, content, embedding <=> $query_embedding AS distance
FROM memories
WHERE
    -- æ—¶é—´èŒƒå›´è¿‡æ»¤
    created_at >= $start_time AND created_at <= $end_time
    -- å¯é€‰ï¼šåªè¦æœ€è¿‘æ›´æ–°çš„
    AND (updated_at IS NULL OR updated_at >= NOW() - INTERVAL '7 days')
    -- å…ƒæ•°æ®æ—¶é—´æˆ³è¿‡æ»¤ï¼ˆå­˜å‚¨åœ¨ JSONB ä¸­çš„ä¸šåŠ¡æ—¶é—´ï¼‰
    AND (metadata->>'event_time')::timestamp >= $event_start
ORDER BY embedding <=> $query_embedding
LIMIT 10;

-- ä¼˜åŒ–ï¼šåˆ›å»ºå¤åˆç´¢å¼•è¦†ç›–æ—¶é—´èŒƒå›´æŸ¥è¯¢
CREATE INDEX idx_memories_created_at_embedding
    ON memories (created_at DESC, user_id);
```

##### åœºæ™¯ 4ï¼šæ ‡ç­¾ç³»ç»Ÿ (Tag-Based Filtering)

```sql
-- ä¸šåŠ¡éœ€æ±‚ï¼šæ ¹æ®æ ‡ç­¾ç»„åˆè¿‡æ»¤çŸ¥è¯†
-- è¿‡æ»¤æ¡ä»¶ï¼štags æ•°ç»„ (åŒ…å«/æ’é™¤é€»è¾‘)
SELECT id, content, embedding <=> $query_embedding AS distance
FROM memories
WHERE
    -- å¿…é¡»åŒ…å«æ‰€æœ‰æŒ‡å®šæ ‡ç­¾ (AND è¯­ä¹‰)
    metadata @> '{"tags": ["machine-learning", "research"]}'
    -- æ’é™¤ç‰¹å®šæ ‡ç­¾
    AND NOT metadata @> '{"tags": ["deprecated"]}'
    -- å¯é€‰ï¼šåŒ…å«ä»»ä¸€æ ‡ç­¾ (OR è¯­ä¹‰ï¼Œéœ€åº”ç”¨å±‚å¤„ç†)
ORDER BY embedding <=> $query_embedding
LIMIT 10;

-- ä¼˜åŒ–ï¼šGIN ç´¢å¼•æ”¯æŒæ•°ç»„åŒ…å«æŸ¥è¯¢
CREATE INDEX idx_memories_tags
    ON memories USING GIN ((metadata->'tags'));
```

##### åœºæ™¯ 5ï¼šå¤åˆæ¡ä»¶ä¸ä¼˜å…ˆçº§ (Complex Business Logic)

```sql
-- ä¸šåŠ¡éœ€æ±‚ï¼šä¼ä¸šçŸ¥è¯†åº“çš„å¤æ‚æ£€ç´¢æ¡ä»¶
-- è¿‡æ»¤æ¡ä»¶ï¼šå¤šç»´åº¦ç»„åˆ (è§’è‰² + çŠ¶æ€ + ç±»å‹ + ä¼˜å…ˆçº§)
SELECT id, content, embedding <=> $query_embedding AS distance
FROM memories
WHERE
    -- æ–‡æ¡£ç±»å‹
    metadata @> '{"doc_type": "policy"}'
    -- çŠ¶æ€ï¼šå·²å‘å¸ƒ
    AND metadata @> '{"status": "published"}'
    -- åˆ›å»ºè€…è§’è‰²ï¼šç®¡ç†å‘˜æˆ–ä¸“å®¶
    AND (
        metadata @> '{"author": {"role": "admin"}}'
        OR metadata @> '{"author": {"role": "expert"}}'
    )
    -- ä¼˜å…ˆçº§ >= é«˜
    AND (metadata->>'priority')::int >= 3
    -- æœªè¿‡æœŸ
    AND (
        metadata->>'expires_at' IS NULL
        OR (metadata->>'expires_at')::timestamp > NOW()
    )
ORDER BY embedding <=> $query_embedding
LIMIT 10;
```

#### 3.5.3 JSONB ç´¢å¼•ç­–ç•¥

```sql
-- 1. GIN ç´¢å¼•ï¼šæ”¯æŒ @>ã€?ã€?&ã€?| æ“ä½œç¬¦
CREATE INDEX idx_memories_metadata_gin
    ON memories USING GIN (metadata);

-- 2. è¡¨è¾¾å¼ç´¢å¼•ï¼šé’ˆå¯¹é«˜é¢‘æŸ¥è¯¢è·¯å¾„
-- åœºæ™¯ï¼šé¢‘ç¹æŒ‰ author.role è¿‡æ»¤
CREATE INDEX idx_memories_author_role
    ON memories ((metadata->'author'->>'role'));

-- 3. éƒ¨åˆ†ç´¢å¼•ï¼šé’ˆå¯¹ç‰¹å®šä¸šåŠ¡åœºæ™¯
-- åœºæ™¯ï¼šä»…ç´¢å¼• admin ç”¨æˆ·çš„è®°å¿†ï¼ˆå‡å°‘ç´¢å¼•å¤§å°ï¼‰
CREATE INDEX idx_memories_admin_only
    ON memories USING hnsw (embedding vector_cosine_ops)
    WHERE metadata @> '{"author": {"role": "admin"}}';
```

### 3.6 æ ¸å¿ƒ SQL å‡½æ•°è®¾è®¡

#### 3.6.1 One-Shot Hybrid Search å‡½æ•°

```sql
-- æ ¸å¿ƒå‡½æ•°ï¼šOne-Shot æ··åˆæ£€ç´¢
CREATE OR REPLACE FUNCTION hybrid_search(
    p_user_id VARCHAR(255),
    p_app_name VARCHAR(255),
    p_query TEXT,
    p_query_embedding vector(1536),
    p_limit INTEGER DEFAULT 50,
    p_semantic_weight FLOAT DEFAULT 0.7,
    p_keyword_weight FLOAT DEFAULT 0.3,
    p_metadata_filter JSONB DEFAULT NULL
)
RETURNS TABLE (
    id UUID,
    content TEXT,
    semantic_score FLOAT,
    keyword_score FLOAT,
    combined_score FLOAT,
    metadata JSONB
) AS $$
BEGIN
    RETURN QUERY
    WITH
    -- 1. è¯­ä¹‰æ£€ç´¢ (å‘é‡)
    semantic_results AS (
        SELECT
            m.id,
            m.content,
            1 - (m.embedding <=> p_query_embedding) AS score,
            m.metadata
        FROM memories m
        WHERE m.user_id = p_user_id
          AND m.app_name = p_app_name
          AND (p_metadata_filter IS NULL OR m.metadata @> p_metadata_filter)
        ORDER BY m.embedding <=> p_query_embedding
        LIMIT p_limit * 2  -- å¬å› 2 å€ç”¨äºèåˆ
    ),
    -- 2. å…³é”®è¯æ£€ç´¢ (BM25)
    keyword_results AS (
        SELECT
            m.id,
            m.content,
            ts_rank_cd(m.search_vector, plainto_tsquery('english', p_query)) AS score,
            m.metadata
        FROM memories m
        WHERE m.user_id = p_user_id
          AND m.app_name = p_app_name
          AND m.search_vector @@ plainto_tsquery('english', p_query)
          AND (p_metadata_filter IS NULL OR m.metadata @> p_metadata_filter)
        ORDER BY score DESC
        LIMIT p_limit * 2
    ),
    -- 3. åˆå¹¶å»é‡
    combined AS (
        SELECT
            COALESCE(s.id, k.id) AS id,
            COALESCE(s.content, k.content) AS content,
            COALESCE(s.score, 0) AS semantic_score,
            COALESCE(k.score, 0) AS keyword_score,
            COALESCE(s.metadata, k.metadata) AS metadata
        FROM semantic_results s
        FULL OUTER JOIN keyword_results k ON s.id = k.id
    )
    -- 4. åŠ æƒèåˆæ’åº
    SELECT
        c.id,
        c.content,
        c.semantic_score,
        c.keyword_score,
        (c.semantic_score * p_semantic_weight + c.keyword_score * p_keyword_weight) AS combined_score,
        c.metadata
    FROM combined c
    ORDER BY combined_score DESC
    LIMIT p_limit;
END;
$$ LANGUAGE plpgsql;
```

#### 3.6.2 RRF èåˆå‡½æ•°

```sql
-- RRF (Reciprocal Rank Fusion) èåˆå‡½æ•°
CREATE OR REPLACE FUNCTION rrf_search(
    p_user_id VARCHAR(255),
    p_app_name VARCHAR(255),
    p_query TEXT,
    p_query_embedding vector(1536),
    p_limit INTEGER DEFAULT 50,
    p_k INTEGER DEFAULT 60  -- RRF å¹³æ»‘å¸¸æ•°
)
RETURNS TABLE (
    id UUID,
    content TEXT,
    rrf_score FLOAT,
    semantic_rank INTEGER,
    keyword_rank INTEGER,
    metadata JSONB
) AS $$
BEGIN
    RETURN QUERY
    WITH
    -- 1. è¯­ä¹‰æ£€ç´¢ + æ’å
    semantic_ranked AS (
        SELECT
            m.id, m.content, m.metadata,
            ROW_NUMBER() OVER (ORDER BY m.embedding <=> p_query_embedding) AS rank
        FROM memories m
        WHERE m.user_id = p_user_id AND m.app_name = p_app_name
        ORDER BY m.embedding <=> p_query_embedding
        LIMIT p_limit * 3
    ),
    -- 2. å…³é”®è¯æ£€ç´¢ + æ’å
    keyword_ranked AS (
        SELECT
            m.id, m.content, m.metadata,
            ROW_NUMBER() OVER (
                ORDER BY ts_rank_cd(m.search_vector, plainto_tsquery('english', p_query)) DESC
            ) AS rank
        FROM memories m
        WHERE m.user_id = p_user_id
          AND m.app_name = p_app_name
          AND m.search_vector @@ plainto_tsquery('english', p_query)
        ORDER BY ts_rank_cd(m.search_vector, plainto_tsquery('english', p_query)) DESC
        LIMIT p_limit * 3
    ),
    -- 3. RRF èåˆ
    rrf_combined AS (
        SELECT
            COALESCE(s.id, k.id) AS id,
            COALESCE(s.content, k.content) AS content,
            COALESCE(s.metadata, k.metadata) AS metadata,
            s.rank AS semantic_rank,
            k.rank AS keyword_rank,
            -- RRF å…¬å¼: sum(1 / (k + rank))
            COALESCE(1.0 / (p_k + s.rank), 0) +
            COALESCE(1.0 / (p_k + k.rank), 0) AS rrf_score
        FROM semantic_ranked s
        FULL OUTER JOIN keyword_ranked k ON s.id = k.id
    )
    -- 4. æŒ‰ RRF åˆ†æ•°æ’åº
    SELECT
        c.id,
        c.content,
        c.rrf_score,
        c.semantic_rank::INTEGER,
        c.keyword_rank::INTEGER,
        c.metadata
    FROM rrf_combined c
    ORDER BY c.rrf_score DESC
    LIMIT p_limit;
END;
$$ LANGUAGE plpgsql;
```

### 3.7 Knowledge Base ä¸“ç”¨æ£€ç´¢å‡½æ•°

```sql
-- Knowledge Base ä¸“ç”¨æ··åˆæ£€ç´¢å‡½æ•°
CREATE OR REPLACE FUNCTION kb_hybrid_search(
    p_corpus_id UUID,
    p_app_name VARCHAR(255),
    p_query TEXT,
    p_query_embedding vector(1536),
    p_limit INTEGER DEFAULT 50,
    p_semantic_weight FLOAT DEFAULT 0.7,
    p_keyword_weight FLOAT DEFAULT 0.3
)
RETURNS TABLE (
    id UUID,
    content TEXT,
    source_uri TEXT,
    semantic_score FLOAT,
    keyword_score FLOAT,
    combined_score FLOAT,
    metadata JSONB
) AS $$
BEGIN
    RETURN QUERY
    WITH
    semantic_results AS (
        SELECT
            kb.id, kb.content, kb.source_uri,
            1 - (kb.embedding <=> p_query_embedding) AS score,
            kb.metadata
        FROM knowledge_base kb
        WHERE kb.corpus_id = p_corpus_id AND kb.app_name = p_app_name
        ORDER BY kb.embedding <=> p_query_embedding
        LIMIT p_limit * 2
    ),
    keyword_results AS (
        SELECT
            kb.id, kb.content, kb.source_uri,
            ts_rank_cd(kb.search_vector, plainto_tsquery('english', p_query)) AS score,
            kb.metadata
        FROM knowledge_base kb
        WHERE kb.corpus_id = p_corpus_id
          AND kb.app_name = p_app_name
          AND kb.search_vector @@ plainto_tsquery('english', p_query)
        ORDER BY score DESC
        LIMIT p_limit * 2
    ),
    combined AS (
        SELECT
            COALESCE(s.id, k.id) AS id,
            COALESCE(s.content, k.content) AS content,
            COALESCE(s.source_uri, k.source_uri) AS source_uri,
            COALESCE(s.score, 0) AS semantic_score,
            COALESCE(k.score, 0) AS keyword_score,
            COALESCE(s.metadata, k.metadata) AS metadata
        FROM semantic_results s
        FULL OUTER JOIN keyword_results k ON s.id = k.id
    )
    SELECT
        c.id, c.content, c.source_uri,
        c.semantic_score, c.keyword_score,
        (c.semantic_score * p_semantic_weight + c.keyword_score * p_keyword_weight) AS combined_score,
        c.metadata
    FROM combined c
    ORDER BY combined_score DESC
    LIMIT p_limit;
END;
$$ LANGUAGE plpgsql;
```

#### 8.0.3 åŒå­˜å‚¨æ£€ç´¢æµ‹è¯•ç”¨ä¾‹

| æµ‹è¯•ç”¨ä¾‹ ID | æµ‹è¯•åœºæ™¯                 | æ£€ç´¢å‡½æ•°             | éªŒæ”¶æ ‡å‡†                       |
| :---------- | :----------------------- | :------------------- | :----------------------------- |
| DUAL-01     | Knowledge ç‹¬ç«‹æ£€ç´¢       | `kb_hybrid_search()` | ä»…è¿”å› `knowledge_base` è¡¨æ•°æ® |
| DUAL-02     | Memory ç‹¬ç«‹æ£€ç´¢          | `hybrid_search()`    | ä»…è¿”å› `memories` è¡¨æ•°æ®       |
| DUAL-03     | Unified è”åˆæ£€ç´¢         | `unified_search()`   | ä¸¤è¡¨æ•°æ® RRF èåˆ              |
| DUAL-04     | Knowledge ä¸å½±å“ Memory  | äº¤å‰æµ‹è¯•             | ä¸¤è¡¨æ•°æ®éš”ç¦»ï¼Œæ— äº¤å‰æ±¡æŸ“       |
| DUAL-05     | Corpus è¿‡æ»¤ vs User è¿‡æ»¤ | å¯¹æ¯”æµ‹è¯•             | å„è‡ªè¿‡æ»¤æ¡ä»¶æ­£ç¡®ç”Ÿæ•ˆ           |

### 3.8 RAG Pipeline æ¶æ„

> [!NOTE]
>
> **å¯¹æ ‡ Roadmap Pillar III**ï¼šRAG Pipeline æ˜¯ Knowledge Base çš„æ ¸å¿ƒæ£€ç´¢é“¾è·¯ï¼Œå®ç°ã€Œæ–‡æ¡£æ‘„å…¥ â†’ æ£€ç´¢ â†’ ç”Ÿæˆã€çš„å®Œæ•´é—­ç¯ã€‚

#### 3.8.1 Pipeline å®Œæ•´æµç¨‹

```mermaid
flowchart TB
    subgraph ç¦»çº¿é˜¶æ®µ["ğŸ“¦ ç¦»çº¿é˜¶æ®µ (Indexing)"]
        D[æ–‡æ¡£é›†åˆ] --> Parse[æ–‡æ¡£è§£æ]
        Parse --> Chunk[åˆ†å—ç­–ç•¥]
        Chunk --> Embed[å‘é‡åŒ–]
        Embed --> Index[(knowledge_base)]
        Chunk --> Meta[å…ƒæ•°æ®æå–]
        Meta --> Index
    end

    subgraph åœ¨çº¿é˜¶æ®µ["âš¡ åœ¨çº¿é˜¶æ®µ (Retrieval + Generation)"]
        Q[ç”¨æˆ·æŸ¥è¯¢] --> QEmbed[æŸ¥è¯¢å‘é‡åŒ–]
        QEmbed --> Search[Hybrid Search]
        Index --> Search
        Search --> Rerank[L1 é‡æ’åº]
        Rerank --> Select[Top-K é€‰æ‹©]
        Select --> Augment[Prompt å¢å¼º]
        Q --> Augment
        Augment --> LLM[LLM ç”Ÿæˆ]
        LLM --> Answer[å›ç­” + å¼•ç”¨]
    end

    style ç¦»çº¿é˜¶æ®µ fill:#e3f2fd,color:#000
    style åœ¨çº¿é˜¶æ®µ fill:#e8f5e9,color:#000
```

#### 3.8.2 RAGPipeline æ ¸å¿ƒæ¥å£

**å®ç°æ–‡ä»¶**ï¼š`src/cognizes/engine/perception/rag_pipeline.py`

```python
class RAGPipeline:
    """å®Œæ•´çš„ RAG Pipeline å®ç°"""

    async def index_document(
        self,
        content: str,
        source_uri: str,
        corpus_id: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> IndexingResult:
        """æ–‡æ¡£ç´¢å¼•å…¥åº“"""

    async def retrieve(
        self,
        query: str,
        top_k: int = 10,
        semantic_weight: float = 0.7,
        keyword_weight: float = 0.3,
    ) -> List[RetrievalResult]:
        """æ··åˆæ£€ç´¢"""

    async def query(
        self,
        query: str,
        top_k: int = 5,
        system_prompt: Optional[str] = None,
    ) -> RAGResponse:
        """ç«¯åˆ°ç«¯ RAG æŸ¥è¯¢ (æ£€ç´¢ + ç”Ÿæˆ)"""
```

#### 3.8.3 åŒå­˜å‚¨è§£è€¦æ¶æ„

| å­˜å‚¨è¡¨           | æ•°æ®ç±»å‹     | è¿‡æ»¤ç»´åº¦                | æ£€ç´¢å‡½æ•°             |
| :--------------- | :----------- | :---------------------- | :------------------- |
| `knowledge_base` | é™æ€çŸ¥è¯†æ–‡æ¡£ | `corpus_id`, `app_name` | `kb_hybrid_search()` |
| `memories`       | ç”¨æˆ·ä¼šè¯è®°å¿† | `user_id`, `app_name`   | `hybrid_search()`    |

---

### 3.9 æ–‡æ¡£æ‘„å…¥æ¶æ„

**å®ç°æ–‡ä»¶**ï¼š`src/cognizes/engine/perception/ingestion.py`

#### 3.9.1 æ‘„å…¥æµç¨‹

```mermaid
flowchart LR
    subgraph Input["è¾“å…¥å±‚"]
        MD[Markdown]
        TXT[TXT]
        PDF[PDF]
    end

    subgraph Parse["è§£æå±‚"]
        MD --> MP[MarkdownParser]
        TXT --> TP[TextParser]
        PDF --> PP[PDFParser]
    end

    subgraph Process["å¤„ç†å±‚"]
        MP --> DOC[Document]
        TP --> DOC
        PP --> DOC
        DOC --> CHUNK[Chunking]
        CHUNK --> EMBED[Embedding]
    end

    subgraph Store["å­˜å‚¨å±‚"]
        EMBED --> KB[(knowledge_base)]
    end

    style Input fill:#fff3e0,color:#000
    style Parse fill:#e3f2fd,color:#000
    style Process fill:#e8f5e9,color:#000
    style Store fill:#fce4ec,color:#000
```

#### 3.9.2 DocumentIngester æ¥å£

```python
class DocumentIngester:
    """é«˜å±‚æ–‡æ¡£æ‘„å…¥æœåŠ¡"""

    def ingest_text(
        self,
        content: str,
        source_uri: str = "inline.txt",
        generate_embeddings: bool = True,
    ) -> IngestedDocument:
        """æ‘„å…¥æ–‡æœ¬å†…å®¹"""

    def ingest_files(
        self,
        file_paths: List[Path],
        generate_embeddings: bool = True,
    ) -> List[IngestedDocument]:
        """æ‰¹é‡æ‘„å…¥æ–‡ä»¶"""
```

#### 3.9.3 å…ƒæ•°æ®æŠ½å–è§„èŒƒ

| å…ƒæ•°æ®å­—æ®µ    | ç±»å‹   | æ¥æº         | ç”¨é€”       |
| :------------ | :----- | :----------- | :--------- |
| `source_uri`  | string | æ–‡ä»¶è·¯å¾„/URL | å¼•ç”¨æº¯æº   |
| `title`       | string | æ–‡æ¡£é¦–è¡Œ/H1  | æ˜¾ç¤ºæ ‡é¢˜   |
| `mime_type`   | string | æ–‡ä»¶æ‰©å±•å   | è§£æå™¨é€‰æ‹© |
| `doc_id`      | string | å†…å®¹å“ˆå¸Œ     | å»é‡æ ‡è¯†   |
| `chunk_index` | int    | åˆ†å—ç´¢å¼•     | ä¸Šä¸‹æ–‡å®šä½ |

---

### 3.10 Chunking ç­–ç•¥ä½“ç³»

**å®ç°æ–‡ä»¶**ï¼š`src/cognizes/engine/perception/chunking.py`

#### 3.10.1 å››ç§ç­–ç•¥å¯¹æ¯”

| ç­–ç•¥                    | æ–¹æ³•                 | ä¼˜ç‚¹         | ç¼ºç‚¹         | é€‚ç”¨åœºæ™¯  |
| :---------------------- | :------------------- | :----------- | :----------- | :-------- |
| **FixedLengthChunker**  | å›ºå®š Token æ•°åˆ‡åˆ†    | ç®€å•ã€å¯é¢„æµ‹ | å¯èƒ½å‰²è£‚è¯­ä¹‰ | é€šç”¨æ–‡æœ¬  |
| **RecursiveChunker**    | æŒ‰åˆ†éš”ç¬¦ä¼˜å…ˆçº§é€’å½’   | å°Šé‡è‡ªç„¶è¾¹ç•Œ | å¤§å°ä¸å‡åŒ€   | æŠ€æœ¯æ–‡æ¡£  |
| **SemanticChunker**     | Embedding ç›¸ä¼¼åº¦åˆ¤æ–­ | è¯­ä¹‰å®Œæ•´     | è®¡ç®—æˆæœ¬é«˜   | é•¿ç¯‡æ–‡ç«   |
| **HierarchicalChunker** | çˆ¶å­ Chunk ç»“æ„      | ä¸Šä¸‹æ–‡ä¸°å¯Œ   | å­˜å‚¨å¼€é”€å¤§   | æ³•å¾‹/åˆåŒ |

#### 3.10.2 ç­–ç•¥é€‰å‹å†³ç­–æ ‘

```mermaid
flowchart TD
    Start{æ–‡æ¡£ç±»å‹?} --> Tech[æŠ€æœ¯æ–‡æ¡£]
    Start --> Long[é•¿ç¯‡æ–‡ç« ]
    Start --> Legal[æ³•å¾‹/åˆåŒ]
    Start --> General[é€šç”¨æ–‡æœ¬]

    Tech --> Recursive[RecursiveChunker<br>chunk_size=256]
    Long --> Semantic[SemanticChunker<br>similarity_threshold=0.85]
    Legal --> Hierarchical[HierarchicalChunker<br>parent=1024, child=256]
    General --> Fixed[FixedLengthChunker<br>chunk_size=512]

    style Recursive fill:#e8f5e9,color:#000
    style Semantic fill:#e3f2fd,color:#000
    style Hierarchical fill:#fff3e0,color:#000
    style Fixed fill:#fce4ec,color:#000
```

#### 3.10.3 å‚æ•°è°ƒä¼˜æŒ‡å—

| å‚æ•°             | é»˜è®¤å€¼     | è°ƒä¼˜å»ºè®®                    |
| :--------------- | :--------- | :-------------------------- |
| `chunk_size`     | 512 tokens | çŸ­æ–‡æ¡£ 256ï¼Œé•¿æ–‡æ¡£ 1024     |
| `chunk_overlap`  | 50 tokens  | é€šå¸¸ä¸º chunk_size çš„ 10-20% |
| `min_chunk_size` | 50 tokens  | é¿å…è¿‡çŸ­æ— æ„ä¹‰å—            |

---

### 3.11 Rerank ç²¾æ’å±‚

**å®ç°æ–‡ä»¶**ï¼š`src/cognizes/engine/perception/reranker.py`

#### 3.11.1 ä¸¤é˜¶æ®µæ£€ç´¢æ¶æ„

```mermaid
flowchart LR
    Query[æŸ¥è¯¢] --> L0[L0: Hybrid Search<br>Top-50 ç²—æ’]
    L0 --> Rerank[L1: Cross-Encoder<br>ç²¾æ’]
    Rerank --> L1[Top-10 ç²¾é€‰]
    L1 --> LLM[LLM ç”Ÿæˆ]

    style L0 fill:#e3f2fd,color:#000
    style Rerank fill:#ffeb3b,color:#000
    style L1 fill:#e8f5e9,color:#000
```

#### 3.11.2 Reranker æ¨¡å‹é€‰å‹

| æ¨¡å‹                        | ç‰¹ç‚¹          | æ¨èåœºæ™¯ |
| :-------------------------- | :------------ | :------- |
| **BAAI/bge-reranker-base**  | æ€§èƒ½/æ•ˆç‡å¹³è¡¡ | é€šç”¨åœºæ™¯ |
| **BAAI/bge-reranker-large** | æ›´é«˜ç²¾åº¦      | ç²¾åº¦ä¼˜å…ˆ |
| **BCE-Reranker**            | ä¸­è‹±åŒè¯­ä¼˜ç§€  | åŒè¯­åœºæ™¯ |
| **Cohere Rerank**           | å•†ä¸š API      | å¿«é€Ÿé›†æˆ |

#### 3.11.3 Lost in the Middle ä¼˜åŒ–

ç ”ç©¶è¡¨æ˜ LLM å¯¹é•¿ä¸Šä¸‹æ–‡ä¸­é—´éƒ¨åˆ†ä¿¡æ¯åˆ©ç”¨ç‡è¾ƒä½ã€‚è§£å†³æ–¹æ¡ˆï¼š

1. **Reverse Order**ï¼šæŒ‰ç›¸å…³æ€§å‡åºæ’åˆ—ï¼ˆæœ€ç›¸å…³åœ¨æœ«å°¾ï¼‰
2. **Sandwich Pattern**ï¼šæœ€ç›¸å…³çš„æ”¾åœ¨å¼€å¤´å’Œç»“å°¾

---

## 4. å®æ–½æŒ‡å—

### 4.1 Step 1: Fusion Retrieval å®ç°

#### 4.1.1 Schema æ‰©å±•éƒ¨ç½²

**ä»»åŠ¡æ¸…å•**ï¼š

| ä»»åŠ¡ ID | ä»»åŠ¡æè¿°                  | éªŒæ”¶æ ‡å‡†                              |
| :------ | :------------------------ | :------------------------------------ |
| P3-1-1  | æ·»åŠ  `search_vector` åˆ—   | `ALTER TABLE` æˆåŠŸ                    |
| P3-1-2  | åˆ›å»º GIN å…¨æ–‡ç´¢å¼•         | ç´¢å¼•åˆ›å»ºæˆåŠŸ                          |
| P3-1-3  | ç¼–å†™ Semantic Search SQL  | `embedding <=> query` è¯­æ³•æ­£ç¡®        |
| P3-1-4  | ç¼–å†™ Keyword Search SQL   | `to_tsvector @@ plainto_tsquery` æ­£ç¡® |
| P3-1-5  | ç¼–å†™ One-Shot Hybrid å‡½æ•° | `hybrid_search()` å‡½æ•°åˆ›å»ºæˆåŠŸ        |

**Schema æ‰©å±•è„šæœ¬** (`src/cognizes/engine/schema/perception_schema.sql`)ï¼š

```sql
-- ============================================
-- Agentic AI Engine - Perception Schema Extension
-- Version: 1.0
-- Target: PostgreSQL 16+ with pgvector
-- Prerequisite: Phase 2 hippocampus_schema.sql å·²éƒ¨ç½²
-- ============================================

-- 1. æ·»åŠ å…¨æ–‡æœç´¢åˆ—
ALTER TABLE memories ADD COLUMN IF NOT EXISTS
    search_vector tsvector;

-- 2. åˆ›å»ºè§¦å‘å™¨è‡ªåŠ¨æ›´æ–° search_vector
CREATE OR REPLACE FUNCTION memories_search_vector_trigger()
RETURNS trigger AS $$
BEGIN
    NEW.search_vector := to_tsvector('english', COALESCE(NEW.content, ''));
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

DROP TRIGGER IF EXISTS trigger_memories_search_vector ON memories;
CREATE TRIGGER trigger_memories_search_vector
    BEFORE INSERT OR UPDATE ON memories
    FOR EACH ROW
    EXECUTE FUNCTION memories_search_vector_trigger();

-- 3. å›å¡«å·²æœ‰æ•°æ®çš„ search_vector
UPDATE memories SET search_vector = to_tsvector('english', content)
WHERE search_vector IS NULL;

-- 4. åˆ›å»º GIN å…¨æ–‡ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_memories_search_vector
    ON memories USING GIN (search_vector);

-- 5. åˆ›å»ºå¤åˆç´¢å¼• (é«˜é¢‘è¿‡æ»¤åœºæ™¯)
CREATE INDEX IF NOT EXISTS idx_memories_user_app_created
    ON memories(user_id, app_name, created_at DESC);

-- 6. éªŒè¯ç´¢å¼•
SELECT indexname, indexdef
FROM pg_indexes
WHERE tablename = 'memories';
```

#### 4.1.2 RRF èåˆç®—æ³• (Reciprocal Rank Fusion)

**ä»»åŠ¡æ¸…å•**ï¼š

| ä»»åŠ¡ ID | ä»»åŠ¡æè¿°                    | éªŒæ”¶æ ‡å‡†            |
| :------ | :-------------------------- | :------------------ |
| P3-1-6  | ç†è§£ RRF ç®—æ³•åŸç†           | ç®—æ³•ç¬”è®°            |
| P3-1-7  | å®ç° SQL å†… RRF è®¡ç®—        | `rrf_search()` å‡½æ•° |
| P3-1-8  | å®ç°åº”ç”¨å±‚ RRF (Python)     | Python å‡½æ•°å®ç°     |
| P3-1-9  | å¯¹æ¯” SQL vs åº”ç”¨å±‚ RRF æ€§èƒ½ | æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š        |

**Python RRF å®ç°** (`src/cognizes/engine/perception/rrf_fusion.py`)ï¼š

```python
"""
RRF (Reciprocal Rank Fusion) å®ç°

èåˆå¤šè·¯æ£€ç´¢ç»“æœï¼Œä½¿ç”¨å€’æ•°æ’åå…¬å¼åˆå¹¶æ’åºã€‚
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Any


@dataclass
class SearchResult:
    """å•æ¡æ£€ç´¢ç»“æœ"""
    id: str
    content: str
    score: float
    metadata: dict[str, Any] | None = None
    rank: int = 0


def rrf_fusion(
    result_lists: list[list[SearchResult]],
    k: int = 60,
    limit: int = 50
) -> list[SearchResult]:
    """
    Reciprocal Rank Fusion ç®—æ³•

    å…¬å¼: RRF(d) = Î£ (1 / (k + rank(d)))

    Args:
        result_lists: å¤šä¸ªæ£€ç´¢å™¨çš„ç»“æœåˆ—è¡¨
        k: å¹³æ»‘å¸¸æ•° (æ ‡å‡†å€¼ 60)
        limit: è¿”å›ç»“æœæ•°é‡

    Returns:
        èåˆåçš„æ’åºç»“æœ
    """
    # 1. ä¸ºæ¯ä¸ªåˆ—è¡¨åˆ†é…æ’å
    for results in result_lists:
        for rank, result in enumerate(results, start=1):
            result.rank = rank

    # 2. æŒ‰ ID èšåˆè®¡ç®— RRF åˆ†æ•°
    rrf_scores: dict[str, tuple[float, SearchResult]] = {}

    for results in result_lists:
        for result in results:
            if result.id not in rrf_scores:
                rrf_scores[result.id] = (0.0, result)

            current_score, current_result = rrf_scores[result.id]
            # RRF å…¬å¼: 1 / (k + rank)
            new_score = current_score + 1.0 / (k + result.rank)
            rrf_scores[result.id] = (new_score, current_result)

    # 3. æŒ‰ RRF åˆ†æ•°æ’åº
    sorted_results = sorted(
        rrf_scores.values(),
        key=lambda x: x[0],
        reverse=True
    )

    # 4. è¿”å› Top-K ç»“æœ
    return [
        SearchResult(
            id=result.id,
            content=result.content,
            score=score,
            metadata=result.metadata
        )
        for score, result in sorted_results[:limit]
    ]


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æ¨¡æ‹Ÿä¸¤è·¯æ£€ç´¢ç»“æœ
    semantic_results = [
        SearchResult(id="doc1", content="Python programming", score=0.95),
        SearchResult(id="doc2", content="Machine learning", score=0.90),
        SearchResult(id="doc3", content="Data science", score=0.85),
    ]

    keyword_results = [
        SearchResult(id="doc2", content="Machine learning", score=0.88),
        SearchResult(id="doc4", content="Deep learning", score=0.85),
        SearchResult(id="doc1", content="Python programming", score=0.80),
    ]

    fused = rrf_fusion([semantic_results, keyword_results], k=60, limit=10)

    for result in fused:
        print(f"ID: {result.id}, RRF Score: {result.score:.4f}")
```

### 4.2 Step 2: High-Selectivity Filtering

#### 4.2.1 è¿­ä»£æ‰«æé…ç½®

**ä»»åŠ¡æ¸…å•**ï¼š

| ä»»åŠ¡ ID | ä»»åŠ¡æè¿°                           | éªŒæ”¶æ ‡å‡†                              |
| :------ | :--------------------------------- | :------------------------------------ |
| P3-2-1  | æ„é€  99% è¿‡æ»¤æ¯”æµ‹è¯•æ•°æ®é›†          | 100 ä¸‡å‘é‡ï¼Œä»… 1% ç¬¦åˆè¿‡æ»¤æ¡ä»¶        |
| P3-2-2  | æµ‹è¯• HNSW `ef_search` å¯¹å¬å›ç‡å½±å“ | ä¸åŒ ef_search ä¸‹çš„ Recall@10         |
| P3-2-3  | éªŒè¯ HNSW è¿­ä»£æ‰«æ (v0.8.0+)       | `hnsw.iterative_scan = relaxed_order` |
| P3-2-4  | è®°å½• QPS ä¸ Recall åŸºå‡†æ•°æ®        | åŸºå‡†æ€§èƒ½æŠ¥å‘Š                          |

**è¿­ä»£æ‰«æé…ç½®è„šæœ¬**ï¼š

```sql
-- ============================================
-- High-Selectivity Filtering é…ç½®
-- ============================================

-- 1. å¼€å¯è¿­ä»£æ‰«æ (PGVector 0.8.0+)
SET hnsw.iterative_scan = relaxed_order;

-- 2. è®¾ç½®æœ€å¤§æ‰«æå…ƒç»„æ•° (é˜²æ­¢æ— é™æ‰«æ)
SET hnsw.max_scan_tuples = 20000;

-- 3. å¢å¤§ ef_search æé«˜å¬å›ç‡
SET hnsw.ef_search = 200;

-- 4. æµ‹è¯•æŸ¥è¯¢ (99% è¿‡æ»¤æ¯”åœºæ™¯)
EXPLAIN (ANALYZE, BUFFERS)
SELECT id, content, embedding <=> $query_embedding AS distance
FROM memories
WHERE user_id = 'rare_user_001'  -- ä»… 1% æ•°æ®
ORDER BY embedding <=> $query_embedding
LIMIT 10;

-- 5. éªŒè¯å¬å›ç»“æœæ•°é‡
SELECT COUNT(*) FROM (
    SELECT id
    FROM memories
    WHERE user_id = 'rare_user_001'
    ORDER BY embedding <=> $query_embedding
    LIMIT 10
) AS results;
-- é¢„æœŸ: åº”è¿”å› 10 æ¡ç»“æœ (è¿­ä»£æ‰«æç”Ÿæ•ˆ)
```

**æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬** (`src/cognizes/engine/perception/benchmark.py`)ï¼š

```python
"""
High-Selectivity Filtering æ€§èƒ½åŸºå‡†æµ‹è¯•

æµ‹è¯•ä¸åŒ ef_search å‚æ•°ä¸‹çš„ QPS å’Œ Recall@Kã€‚
"""

import asyncio
import time
from dataclasses import dataclass

import asyncpg
import numpy as np


@dataclass
class BenchmarkResult:
    """åŸºå‡†æµ‹è¯•ç»“æœ"""
    ef_search: int
    qps: float
    recall_at_10: float
    p99_latency_ms: float


async def run_benchmark(
    pool: asyncpg.Pool,
    query_embedding: list[float],
    user_id: str,
    ef_search_values: list[int],
    iterations: int = 100
) -> list[BenchmarkResult]:
    """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
    results = []

    for ef_search in ef_search_values:
        # è®¾ç½® ef_search
        await pool.execute(f"SET hnsw.ef_search = {ef_search}")
        await pool.execute("SET hnsw.iterative_scan = relaxed_order")

        latencies = []
        recall_count = 0

        for _ in range(iterations):
            start = time.perf_counter()

            rows = await pool.fetch("""
                SELECT id, content
                FROM memories
                WHERE user_id = $1
                ORDER BY embedding <=> $2
                LIMIT 10
            """, user_id, query_embedding)

            latency = (time.perf_counter() - start) * 1000
            latencies.append(latency)
            recall_count += len(rows)

        results.append(BenchmarkResult(
            ef_search=ef_search,
            qps=iterations / (sum(latencies) / 1000),
            recall_at_10=recall_count / (iterations * 10),
            p99_latency_ms=np.percentile(latencies, 99)
        ))

    return results


# ä½¿ç”¨ç¤ºä¾‹
async def main():
    pool = await asyncpg.create_pool("postgresql://aigc:@localhost/cognizes-engine")

    # ç”ŸæˆéšæœºæŸ¥è¯¢å‘é‡
    query_embedding = list(np.random.randn(1536).astype(float))

    results = await run_benchmark(
        pool,
        query_embedding,
        user_id="rare_user_001",
        ef_search_values=[40, 100, 200, 400]
    )

    print("| ef_search | QPS | Recall@10 | P99 Latency |")
    print("|-----------|-----|-----------|-------------|")
    for r in results:
        print(f"| {r.ef_search} | {r.qps:.1f} | {r.recall_at_10:.2%} | {r.p99_latency_ms:.1f}ms |")

    await pool.close()


if __name__ == "__main__":
    asyncio.run(main())
```

### 4.3 Step 3: L1 Reranking å®ç°

#### 4.3.1 Reranker é›†æˆ

**ä»»åŠ¡æ¸…å•**ï¼š

| ä»»åŠ¡ ID | ä»»åŠ¡æè¿°                             | éªŒæ”¶æ ‡å‡†                   |
| :------ | :----------------------------------- | :------------------------- |
| P3-2-5  | é€‰æ‹© Reranker æ¨¡å‹ (`bge-reranker`)  | æ¨¡å‹é€‰å‹è¯´æ˜               |
| P3-2-6  | é›†æˆ Reranker æ¨ç†æœåŠ¡               | API å¯è°ƒç”¨                 |
| P3-2-7  | å®ç° Top-50 -> Rerank -> Top-10 æµç¨‹ | Pipeline ä»£ç å®ç°          |
| P3-2-8  | éªŒè¯ Precision@10 æå‡               | å¯¹æ¯”æ—  Rerank çš„ Precision |

**Reranker å®ç°** (`src/cognizes/engine/perception/reranker.py`)ï¼š

```python
"""
L1 Reranker å®ç°

ä½¿ç”¨ Cross-Encoder æ¨¡å‹å¯¹ L0 ç²—æ’ç»“æœè¿›è¡Œç²¾æ’ã€‚
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Any

import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer


@dataclass
class RerankedResult:
    """é‡æ’åçš„ç»“æœ"""
    id: str
    content: str
    original_score: float
    rerank_score: float
    metadata: dict[str, Any] | None = None


class CrossEncoderReranker:
    """
    Cross-Encoder é‡æ’å™¨

    ä½¿ç”¨ BAAI/bge-reranker-base æ¨¡å‹è¿›è¡Œè¯­ä¹‰é‡æ’ã€‚
    """

    def __init__(
        self,
        model_name: str = "BAAI/bge-reranker-base",
        device: str | None = None
    ):
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)
        self.model.to(self.device)
        self.model.eval()

    def rerank(
        self,
        query: str,
        documents: list[dict[str, Any]],
        top_k: int = 10
    ) -> list[RerankedResult]:
        """
        å¯¹æ–‡æ¡£è¿›è¡Œé‡æ’åº

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            documents: å¾…é‡æ’æ–‡æ¡£åˆ—è¡¨ (éœ€åŒ…å« id, content, score)
            top_k: è¿”å› Top-K ç»“æœ

        Returns:
            é‡æ’åçš„ç»“æœåˆ—è¡¨
        """
        if not documents:
            return []

        # 1. æ„å»º Query-Document å¯¹
        pairs = [[query, doc["content"]] for doc in documents]

        # 2. Tokenize
        inputs = self.tokenizer(
            pairs,
            padding=True,
            truncation=True,
            max_length=512,
            return_tensors="pt"
        ).to(self.device)

        # 3. æ¨ç†
        with torch.no_grad():
            scores = self.model(**inputs).logits.squeeze(-1)

        # 4. å½’ä¸€åŒ–åˆ†æ•° (sigmoid)
        scores = torch.sigmoid(scores).cpu().numpy()

        # 5. æ„å»ºç»“æœ
        results = []
        for doc, rerank_score in zip(documents, scores):
            results.append(RerankedResult(
                id=doc["id"],
                content=doc["content"],
                original_score=doc.get("score", 0.0),
                rerank_score=float(rerank_score),
                metadata=doc.get("metadata")
            ))

        # 6. æŒ‰é‡æ’åˆ†æ•°æ’åº
        results.sort(key=lambda x: x.rerank_score, reverse=True)

        return results[:top_k]


class RerankerPipeline:
    """
    å®Œæ•´çš„ä¸¤é˜¶æ®µæ£€ç´¢ Pipeline

    L0 (æ•°æ®åº“ç²—æ’) -> L1 (Cross-Encoder ç²¾æ’)
    """

    def __init__(
        self,
        db_pool,  # asyncpg.Pool
        reranker: CrossEncoderReranker | None = None
    ):
        self.db_pool = db_pool
        self.reranker = reranker or CrossEncoderReranker()

    async def search(
        self,
        user_id: str,
        app_name: str,
        query: str,
        query_embedding: list[float],
        l0_limit: int = 50,
        l1_limit: int = 10
    ) -> list[RerankedResult]:
        """
        ä¸¤é˜¶æ®µæ£€ç´¢

        Args:
            user_id: ç”¨æˆ· ID
            app_name: åº”ç”¨åç§°
            query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
            query_embedding: æŸ¥è¯¢å‘é‡
            l0_limit: L0 ç²—æ’è¿”å›æ•°é‡
            l1_limit: L1 ç²¾æ’è¿”å›æ•°é‡

        Returns:
            ç²¾æ’åçš„ç»“æœåˆ—è¡¨
        """
        # L0: æ•°æ®åº“æ··åˆæ£€ç´¢
        rows = await self.db_pool.fetch("""
            SELECT id, content, combined_score, metadata
            FROM hybrid_search($1, $2, $3, $4, $5)
        """, user_id, app_name, query, query_embedding, l0_limit)

        documents = [
            {
                "id": str(row["id"]),
                "content": row["content"],
                "score": row["combined_score"],
                "metadata": row["metadata"]
            }
            for row in rows
        ]

        # L1: Cross-Encoder é‡æ’
        results = self.reranker.rerank(query, documents, top_k=l1_limit)

        return results


# ä½¿ç”¨ç¤ºä¾‹
async def main():
    import asyncpg

    # åˆå§‹åŒ–
    pool = await asyncpg.create_pool("postgresql://aigc:@localhost/cognizes-engine")
    pipeline = RerankerPipeline(pool)

    # ç”ŸæˆæŸ¥è¯¢å‘é‡ (å®é™…åº”ä½¿ç”¨ Embedding æ¨¡å‹)
    import numpy as np
    query_embedding = list(np.random.randn(1536).astype(float))

    # æ‰§è¡Œä¸¤é˜¶æ®µæ£€ç´¢
    results = await pipeline.search(
        user_id="user_001",
        app_name="demo_app",
        query="How to implement RAG with PostgreSQL?",
        query_embedding=query_embedding,
        l0_limit=50,
        l1_limit=10
    )

    # è¾“å‡ºç»“æœ
    print("Top 10 Reranked Results:")
    for i, r in enumerate(results, 1):
        print(f"{i}. [Score: {r.rerank_score:.4f}] {r.content[:100]}...")

    await pool.close()


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
```

---

### 4.4 Step 4: AG-UI æ£€ç´¢è¿‡ç¨‹å¯è§†åŒ–æ¥å£

> [!NOTE]
>
> **å¯¹æ ‡ AG-UI åè®®**ï¼šæœ¬èŠ‚å®ç° The Perception ä¸ AG-UI å¯è§†åŒ–å±‚çš„é›†æˆï¼Œæä¾›æ£€ç´¢è¿‡ç¨‹é€æ˜åŒ–ã€å¤šè·¯å¬å›å¯è§†åŒ–å’Œå¼•ç”¨æ¥æºå±•ç¤ºçš„èƒ½åŠ›ã€‚
>
> **å‚è€ƒèµ„æº**ï¼š
>
> - [AG-UI åè®®è°ƒç ”](../research/070-ag-ui.md)
> - [AG-UI å®˜æ–¹æ–‡æ¡£](https://docs.ag-ui.com/)

#### 4.4.1 æ£€ç´¢å¯è§†åŒ–æ¶æ„

```mermaid
graph TB
    subgraph "Perception æ£€ç´¢å±‚"
        SEM[Semantic Search]
        KW[Keyword Search]
        META[Metadata Filter]
        RRF[RRF Fusion]
        RK[L1 Reranking]
    end

    subgraph "å¯è§†åŒ–æ¥å£å±‚"
        RD[RetrievalDetail]
        RR[RerankResult]
        SC[SourceCitation]
    end

    subgraph "AG-UI äº‹ä»¶"
        STEP[STEP_STARTED/FINISHED]
        CUST[CUSTOM Events]
    end

    SEM & KW & META --> RD
    RRF --> RD
    RK --> RR
    RK --> SC

    RD --> CUST
    RR --> CUST
    SC --> CUST

    style RD fill:#60a5fa,stroke:#2563eb,color:#000
    style RR fill:#f472b6,stroke:#db2777,color:#000
    style SC fill:#4ade80,stroke:#16a34a,color:#000
```

#### 4.4.2 AG-UI äº‹ä»¶æ˜ å°„è¡¨

| Perception åŠŸèƒ½ | è§¦å‘æ¡ä»¶             | AG-UI äº‹ä»¶ç±»å‹              | å±•ç¤ºç»„ä»¶       |
| :-------------- | :------------------- | :-------------------------- | :------------- |
| æ£€ç´¢å¼€å§‹        | hybrid_search() è°ƒç”¨ | `STEP_STARTED`              | æ£€ç´¢è¿›åº¦æŒ‡ç¤ºå™¨ |
| å¤šè·¯å¬å›è¯¦æƒ…    | å„è·¯æ£€ç´¢å®Œæˆ         | `CUSTOM (retrieval_detail)` | å¤šè·¯å¬å›å¯¹æ¯”å›¾ |
| RRF èåˆ        | èåˆå®Œæˆ             | `CUSTOM (rrf_result)`       | æ’åå˜åŒ–å¯è§†åŒ– |
| Rerank ç»“æœ     | é‡æ’å®Œæˆ             | `CUSTOM (rerank_result)`    | åˆ†æ•°å˜åŒ–å¯¹æ¯”   |
| æ£€ç´¢å®Œæˆ        | è¿”å›ç»“æœ             | `STEP_FINISHED`             | ç»“æœæ•°é‡å¾½ç«    |
| å¼•ç”¨æ¥æº        | ç»“æœåŒ…å«æ¥æº         | `CUSTOM (source_citation)`  | æ¥æºå¼•ç”¨åˆ—è¡¨   |

#### 4.4.3 SearchVisualizer å®ç°

åˆ›å»º `src/cognizes/engine/perception/search_visualizer.py`ï¼š

```python
"""
Perception SearchVisualizer: æ£€ç´¢è¿‡ç¨‹å¯è§†åŒ–æ¥å£

èŒè´£:
1. æä¾›å¤šè·¯å¬å›è¿‡ç¨‹å¯è§†åŒ–
2. å±•ç¤º RRF èåˆå’Œ Rerank è¿‡ç¨‹
3. ç”Ÿæˆå¼•ç”¨æ¥æºæ ‡æ³¨
"""

from __future__ import annotations

import json
from dataclasses import dataclass, field
from typing import Any, Optional
from datetime import datetime
from enum import Enum


class SearchEventType(str, Enum):
    """æ£€ç´¢ç›¸å…³ AG-UI äº‹ä»¶ç±»å‹"""
    RETRIEVAL_DETAIL = "retrieval_detail"
    RRF_RESULT = "rrf_result"
    RERANK_RESULT = "rerank_result"
    SOURCE_CITATION = "source_citation"


@dataclass
class RetrievalPathResult:
    """å•è·¯æ£€ç´¢ç»“æœ"""
    path_name: str  # semantic, keyword, metadata
    doc_count: int
    latency_ms: float
    top_docs: list[dict]  # [{id, score, preview}]


@dataclass
class RRFMergeResult:
    """RRF èåˆç»“æœ"""
    input_paths: list[str]
    output_count: int
    rank_changes: list[dict]  # [{doc_id, before_rank, after_rank}]


@dataclass
class RerankComparison:
    """Rerank å‰åå¯¹æ¯”"""
    doc_id: str
    content_preview: str
    l0_score: float  # ç²—æ’åˆ†æ•°
    l1_score: float  # ç²¾æ’åˆ†æ•°
    rank_before: int
    rank_after: int


@dataclass
class SourceCitation:
    """å¼•ç”¨æ¥æº"""
    doc_id: str
    source_type: str  # memory, document, web
    title: str
    url: Optional[str] = None
    snippet: str = ""
    relevance_score: float = 0.0


class SearchVisualizer:
    """æ£€ç´¢è¿‡ç¨‹å¯è§†åŒ–å™¨"""

    def __init__(self, event_emitter=None):
        """
        Args:
            event_emitter: AG-UI äº‹ä»¶å‘å°„å™¨ (å¯é€‰)
        """
        self._event_emitter = event_emitter

    async def emit_search_started(
        self,
        run_id: str,
        query: str,
        search_config: dict
    ) -> None:
        """
        å‘å°„æ£€ç´¢å¼€å§‹äº‹ä»¶

        Args:
            run_id: å½“å‰è¿è¡Œ ID
            query: æœç´¢æŸ¥è¯¢
            search_config: æ£€ç´¢é…ç½®
        """
        if self._event_emitter:
            await self._event_emitter.emit_step_started(
                run_id=run_id,
                step_name="perception_search",
                data={
                    "query": query,
                    "config": {
                        "semanticWeight": search_config.get("semantic_weight", 0.5),
                        "keywordWeight": search_config.get("keyword_weight", 0.3),
                        "metadataFilters": search_config.get("filters", {}),
                        "topK": search_config.get("top_k", 50)
                    }
                }
            )

    async def emit_retrieval_paths(
        self,
        run_id: str,
        path_results: list[RetrievalPathResult]
    ) -> None:
        """
        å‘å°„å¤šè·¯å¬å›è¯¦æƒ…äº‹ä»¶

        ç”¨äºå±•ç¤ºå„æ£€ç´¢è·¯å¾„çš„å¬å›ç»“æœå¯¹æ¯”

        Args:
            run_id: å½“å‰è¿è¡Œ ID
            path_results: å„è·¯æ£€ç´¢ç»“æœ
        """
        if self._event_emitter:
            await self._event_emitter.emit_custom(
                run_id=run_id,
                event_name=SearchEventType.RETRIEVAL_DETAIL.value,
                data={
                    "paths": [
                        {
                            "name": p.path_name,
                            "docCount": p.doc_count,
                            "latencyMs": p.latency_ms,
                            "topDocs": p.top_docs[:5]  # åªå±•ç¤º Top 5
                        }
                        for p in path_results
                    ],
                    "totalLatencyMs": sum(p.latency_ms for p in path_results)
                }
            )

    async def emit_rrf_merge(
        self,
        run_id: str,
        merge_result: RRFMergeResult
    ) -> None:
        """
        å‘å°„ RRF èåˆç»“æœäº‹ä»¶

        Args:
            run_id: å½“å‰è¿è¡Œ ID
            merge_result: èåˆç»“æœ
        """
        if self._event_emitter:
            await self._event_emitter.emit_custom(
                run_id=run_id,
                event_name=SearchEventType.RRF_RESULT.value,
                data={
                    "inputPaths": merge_result.input_paths,
                    "outputCount": merge_result.output_count,
                    "significantRankChanges": [
                        {
                            "docId": rc["doc_id"],
                            "beforeRank": rc["before_rank"],
                            "afterRank": rc["after_rank"],
                            "change": rc["before_rank"] - rc["after_rank"]
                        }
                        for rc in merge_result.rank_changes
                        if abs(rc["before_rank"] - rc["after_rank"]) >= 3
                    ][:10]  # åªå±•ç¤ºæ˜¾è‘—å˜åŒ–
                }
            )

    async def emit_rerank_comparison(
        self,
        run_id: str,
        comparisons: list[RerankComparison]
    ) -> None:
        """
        å‘å°„ Rerank å‰åå¯¹æ¯”äº‹ä»¶

        Args:
            run_id: å½“å‰è¿è¡Œ ID
            comparisons: å¯¹æ¯”åˆ—è¡¨
        """
        if self._event_emitter:
            await self._event_emitter.emit_custom(
                run_id=run_id,
                event_name=SearchEventType.RERANK_RESULT.value,
                data={
                    "comparisons": [
                        {
                            "docId": c.doc_id,
                            "preview": c.content_preview[:100],
                            "l0Score": round(c.l0_score, 4),
                            "l1Score": round(c.l1_score, 4),
                            "rankBefore": c.rank_before,
                            "rankAfter": c.rank_after,
                            "improved": c.rank_after < c.rank_before
                        }
                        for c in comparisons[:20]  # åªå±•ç¤º Top 20
                    ],
                    "avgScoreImprovement": sum(
                        c.l1_score - c.l0_score for c in comparisons
                    ) / len(comparisons) if comparisons else 0
                }
            )

    async def emit_search_finished(
        self,
        run_id: str,
        result_count: int,
        total_latency_ms: float
    ) -> None:
        """
        å‘å°„æ£€ç´¢å®Œæˆäº‹ä»¶

        Args:
            run_id: å½“å‰è¿è¡Œ ID
            result_count: ç»“æœæ•°é‡
            total_latency_ms: æ€»å»¶è¿Ÿ
        """
        if self._event_emitter:
            await self._event_emitter.emit_step_finished(
                run_id=run_id,
                step_name="perception_search",
                data={
                    "resultCount": result_count,
                    "totalLatencyMs": round(total_latency_ms, 2)
                }
            )

    def generate_citations(
        self,
        search_results: list[dict]
    ) -> list[SourceCitation]:
        """
        ç”Ÿæˆå¼•ç”¨æ¥æºåˆ—è¡¨

        ç”¨äºåœ¨ Agent å“åº”ä¸­æ ‡æ³¨ä¿¡æ¯æ¥æº

        Args:
            search_results: æ£€ç´¢ç»“æœ

        Returns:
            å¼•ç”¨æ¥æºåˆ—è¡¨
        """
        citations = []
        for i, result in enumerate(search_results, 1):
            citation = SourceCitation(
                doc_id=result.get("id", f"doc_{i}"),
                source_type=result.get("source_type", "document"),
                title=result.get("title", f"Source {i}"),
                url=result.get("url"),
                snippet=result.get("content", "")[:200],
                relevance_score=result.get("score", 0.0)
            )
            citations.append(citation)
        return citations

    async def emit_citations(
        self,
        run_id: str,
        citations: list[SourceCitation]
    ) -> None:
        """
        å‘å°„å¼•ç”¨æ¥æºäº‹ä»¶

        Args:
            run_id: å½“å‰è¿è¡Œ ID
            citations: å¼•ç”¨æ¥æºåˆ—è¡¨
        """
        if self._event_emitter:
            await self._event_emitter.emit_custom(
                run_id=run_id,
                event_name=SearchEventType.SOURCE_CITATION.value,
                data={
                    "citations": [
                        {
                            "id": c.doc_id,
                            "type": c.source_type,
                            "title": c.title,
                            "url": c.url,
                            "snippet": c.snippet,
                            "score": round(c.relevance_score, 4)
                        }
                        for c in citations
                    ]
                }
            )
```

#### 4.4.4 å‰ç«¯å±•ç¤ºç»„ä»¶è§„èŒƒ

| ç»„ä»¶åç§°                  | æ•°æ®æº                    | å±•ç¤ºå†…å®¹             |
| :------------------------ | :------------------------ | :------------------- |
| `SearchProgressIndicator` | STEP_STARTED/FINISHED     | æ£€ç´¢çŠ¶æ€ã€è€—æ—¶       |
| `RetrievalPathsChart`     | CUSTOM (retrieval_detail) | ä¸‰è·¯å¬å›æŸ±çŠ¶å›¾å¯¹æ¯”   |
| `RankChangeVisualization` | CUSTOM (rrf_result)       | æ’åå˜åŒ–æ¡‘åŸºå›¾       |
| `RerankScoreComparison`   | CUSTOM (rerank_result)    | L0/L1 åˆ†æ•°å¯¹æ¯”æ•£ç‚¹å›¾ |
| `CitationList`            | CUSTOM (source_citation)  | å¼•ç”¨æ¥æºå¡ç‰‡åˆ—è¡¨     |

#### 4.4.5 ä»»åŠ¡æ¸…å•

| ä»»åŠ¡ ID | ä»»åŠ¡æè¿°                   | çŠ¶æ€      | éªŒæ”¶æ ‡å‡†         |
| :------ | :------------------------- | :-------- | :--------------- |
| P3-4-1  | å®ç° `SearchVisualizer` ç±» | ğŸ”² å¾…å¼€å§‹ | 6 ç§äº‹ä»¶ç±»å‹æ”¯æŒ |
| P3-4-2  | å®ç°å¤šè·¯å¬å›è¯¦æƒ…å‘å°„       | ğŸ”² å¾…å¼€å§‹ | ä¸‰è·¯å¬å›æ•°æ®å®Œæ•´ |
| P3-4-3  | å®ç° RRF èåˆå¯è§†åŒ–        | ğŸ”² å¾…å¼€å§‹ | æ’åå˜åŒ–å¯è¿½æº¯   |
| P3-4-4  | å®ç° Rerank å¯¹æ¯”å‘å°„       | ğŸ”² å¾…å¼€å§‹ | åˆ†æ•°å˜åŒ–æ­£ç¡®     |
| P3-4-5  | å®ç°å¼•ç”¨æ¥æºç”Ÿæˆ           | ğŸ”² å¾…å¼€å§‹ | æ¥æºä¿¡æ¯å®Œæ•´     |
| P3-4-6  | ç¼–å†™å¯è§†åŒ–æ¥å£æµ‹è¯•         | ğŸ”² å¾…å¼€å§‹ | è¦†ç›–ç‡ > 80%     |

#### 4.4.6 éªŒæ”¶æ ‡å‡†

| éªŒæ”¶é¡¹      | éªŒæ”¶æ ‡å‡†                  | éªŒè¯æ–¹æ³• |
| :---------- | :------------------------ | :------- |
| æ£€ç´¢è¿›åº¦    | å®æ—¶å±•ç¤ºæ£€ç´¢å¼€å§‹/å®ŒæˆçŠ¶æ€ | é›†æˆæµ‹è¯• |
| å¤šè·¯å¬å›    | ä¸‰è·¯å¬å›ç»“æœå¯¹æ¯”å¯è§      | E2E æµ‹è¯• |
| Rerank å¯¹æ¯” | æ’åå˜åŒ–å‰åå¯å¯¹æ¯”        | å•å…ƒæµ‹è¯• |
| å¼•ç”¨æ¥æº    | æ£€ç´¢ç»“æœå¯æ ‡æ³¨æ¥æº        | é›†æˆæµ‹è¯• |

---

### 4.5 Step 5: Knowledge Base Pipeline å®ç°

> [!NOTE]
>
> **å¯¹æ ‡ Roadmap Pillar III**ï¼šKnowledge Base Pipeline æ˜¯ RAG èƒ½åŠ›çš„æ ¸å¿ƒå·¥ç¨‹è½åœ°ï¼ŒåŒ…å«æ–‡æ¡£æ‘„å…¥ã€åˆ†å—å‘é‡åŒ–ã€ç«¯åˆ°ç«¯æ£€ç´¢ç”Ÿæˆçš„å®Œæ•´é“¾è·¯ã€‚

#### 4.5.1 ä»»åŠ¡æ¸…å•

| ä»»åŠ¡ ID    | ä»»åŠ¡æè¿°           | é‡Œç¨‹ç¢‘         | çŠ¶æ€      | éªŒæ”¶æ ‡å‡†                  |
| :--------- | :----------------- | :------------- | :-------- | :------------------------ |
| **P3-5-1** | æ–‡æ¡£æ‘„å…¥æœåŠ¡å®ç°   | M1: Ingestion  | ğŸ”² å¾…å¼€å§‹ | æ”¯æŒ MD/TXT/PDF æ ¼å¼è§£æ  |
| **P3-5-2** | Chunking ç­–ç•¥å®ç°  | M1: Ingestion  | ğŸ”² å¾…å¼€å§‹ | å››ç§ç­–ç•¥æµ‹è¯•é€šè¿‡          |
| **P3-5-3** | Embedding æœåŠ¡å®ç° | M1: Ingestion  | ğŸ”² å¾…å¼€å§‹ | Mock/OpenAI ä¸¤ç§ Provider |
| **P3-5-4** | RAG Pipeline å®ç°  | M2: Pipeline   | ğŸ”² å¾…å¼€å§‹ | E2E æŸ¥è¯¢æµç¨‹é€šè¿‡          |
| **P3-5-5** | ç´¢å¼•é¢„çƒ­è„šæœ¬       | M2: Pipeline   | ğŸ”² å¾…å¼€å§‹ | 100K æ–‡æ¡£ < 5min          |
| **P3-5-6** | RAG E2E æµ‹è¯•       | M3: Validation | ğŸ”² å¾…å¼€å§‹ | è¦†ç›–ç‡ > 80%              |

#### 4.5.2 å…³é”®é‡Œç¨‹ç¢‘

```mermaid
gantt
    title Knowledge Base Pipeline é‡Œç¨‹ç¢‘
    dateFormat DD
    axisFormat %d

    section M1: Ingestion
    P3-5-1 æ–‡æ¡£æ‘„å…¥ :a1, 01, 2d
    P3-5-2 Chunking :a2, after a1, 2d
    P3-5-3 Embedding :a3, after a2, 1d

    section M2: Pipeline
    P3-5-4 RAG Pipeline :b1, after a3, 2d
    P3-5-5 ç´¢å¼•é¢„çƒ­ :b2, after b1, 1d

    section M3: Validation
    P3-5-6 E2E æµ‹è¯• :c1, after b2, 2d
```

#### 4.5.3 ä»»åŠ¡è¯¦è§£

##### P3-5-1: æ–‡æ¡£æ‘„å…¥æœåŠ¡

**ç›®æ ‡**ï¼šå®ç°å¤šæ ¼å¼æ–‡æ¡£è§£æä¸æ‘„å…¥

**å®ç°æ–‡ä»¶**ï¼š`src/cognizes/engine/perception/ingestion.py`

**å…³é”®ä»£ç **ï¼š

```python
class DocumentIngester:
    def __init__(
        self,
        chunker=None,
        embedder=None,
        parsers: Optional[List[DocumentParser]] = None,
    ):
        """åˆå§‹åŒ–æ–‡æ¡£æ‘„å…¥å™¨"""

    def ingest_text(
        self,
        content: str,
        source_uri: str = "inline.txt",
        generate_embeddings: bool = True,
    ) -> IngestedDocument:
        """æ‘„å…¥æ–‡æœ¬å†…å®¹"""
```

**éªŒæ”¶æ£€æŸ¥**ï¼š

- [ ] MarkdownParser è§£ææµ‹è¯•é€šè¿‡
- [ ] TextParser è§£ææµ‹è¯•é€šè¿‡
- [ ] PDFParser è§£ææµ‹è¯•é€šè¿‡ï¼ˆå¯é€‰ä¾èµ–ï¼‰
- [ ] å…ƒæ•°æ®æŠ½å–æ­£ç¡®

---

##### P3-5-2: Chunking ç­–ç•¥å®ç°

**ç›®æ ‡**ï¼šå®ç°å››ç§åˆ†å—ç­–ç•¥

**å®ç°æ–‡ä»¶**ï¼š`src/cognizes/engine/perception/chunking.py`

**ç­–ç•¥å¯¹ç…§è¡¨**ï¼š

| ç­–ç•¥     | ç±»å                  | æµ‹è¯•ç”¨ä¾‹                     |
| :------- | :-------------------- | :--------------------------- |
| å›ºå®šé•¿åº¦ | `FixedLengthChunker`  | `test_fixed_length_chunking` |
| é€’å½’åˆ†å— | `RecursiveChunker`    | `test_recursive_chunking`    |
| å±‚æ¬¡åˆ†å— | `HierarchicalChunker` | `test_hierarchical_chunking` |
| è¯­ä¹‰åˆ†å— | `SemanticChunker`     | `test_semantic_chunking`     |

**éªŒæ”¶æ£€æŸ¥**ï¼š

- [ ] å››ç§ç­–ç•¥å•å…ƒæµ‹è¯•é€šè¿‡
- [ ] Overlap åŠŸèƒ½æµ‹è¯•é€šè¿‡
- [ ] å­—ç¬¦/Token æ¨¡å¼åˆ‡æ¢æµ‹è¯•é€šè¿‡

---

##### P3-5-3: Embedding æœåŠ¡å®ç°

**ç›®æ ‡**ï¼šå®ç°å¯åˆ‡æ¢çš„ Embedding Provider

**å®ç°æ–‡ä»¶**ï¼š`src/cognizes/engine/perception/embedder.py`

**Provider ç±»å‹**ï¼š

| Provider | ç±»å                      | è¯´æ˜                    |
| :------- | :------------------------ | :---------------------- |
| Mock     | `MockEmbeddingProvider`   | æµ‹è¯•ç”¨ï¼Œè¿”å›éšæœºå‘é‡    |
| OpenAI   | `OpenAIEmbeddingProvider` | ç”Ÿäº§ç”¨ï¼Œè°ƒç”¨ OpenAI API |

**éªŒæ”¶æ£€æŸ¥**ï¼š

- [ ] MockProvider å•å…ƒæµ‹è¯•é€šè¿‡
- [ ] å‘é‡ç»´åº¦æ­£ç¡® (1536)
- [ ] æ‰¹é‡ Embedding åŠŸèƒ½æ­£å¸¸

---

##### P3-5-4: RAG Pipeline å®ç°

**ç›®æ ‡**ï¼šå®ç°ç«¯åˆ°ç«¯ RAG æŸ¥è¯¢æµç¨‹

**å®ç°æ–‡ä»¶**ï¼š`src/cognizes/engine/perception/rag_pipeline.py`

**æ ¸å¿ƒæµç¨‹**ï¼š

```mermaid
flowchart LR
    Q[Query] --> R[Retrieve]
    R --> KB[(knowledge_base)]
    KB --> RK[Rerank]
    RK --> G[Generate]
    G --> A[Answer]
```

**éªŒæ”¶æ£€æŸ¥**ï¼š

- [ ] `index_document()` ç´¢å¼•åŠŸèƒ½æ­£å¸¸
- [ ] `retrieve()` æ··åˆæ£€ç´¢æ­£å¸¸
- [ ] `query()` ç«¯åˆ°ç«¯æŸ¥è¯¢æ­£å¸¸
- [ ] Mock æ¨¡å¼æµ‹è¯•é€šè¿‡

---

##### P3-5-5: ç´¢å¼•é¢„çƒ­è„šæœ¬

**ç›®æ ‡**ï¼šæ‰¹é‡å¯¼å…¥æµ‹è¯•æ•°æ®è¿›è¡Œç´¢å¼•é¢„çƒ­

**å®ç°æ–‡ä»¶**ï¼š`src/cognizes/engine/perception/generate_test_data.py`

**æ€§èƒ½æŒ‡æ ‡**ï¼š

| æ•°æ®è§„æ¨¡  | ç›®æ ‡æ—¶é—´ | éªŒè¯æ–¹æ³•   |
| :-------- | :------- | :--------- |
| 10K æ–‡æ¡£  | < 30s    | è‡ªåŠ¨åŒ–è„šæœ¬ |
| 100K æ–‡æ¡£ | < 5min   | æ‰‹åŠ¨éªŒè¯   |

---

##### P3-5-6: RAG E2E æµ‹è¯•

**ç›®æ ‡**ï¼šå®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•è¦†ç›–

**æµ‹è¯•æ–‡ä»¶**ï¼š`tests/integration/perception/test_rag_e2e.py`

**æµ‹è¯•ç”¨ä¾‹**ï¼š

| ç”¨ä¾‹ ID    | æµ‹è¯•åœºæ™¯   | éªŒæ”¶æ ‡å‡†         |
| :--------- | :--------- | :--------------- |
| RAG-E2E-01 | å•æ–‡æ¡£ç´¢å¼• | ç´¢å¼•æˆåŠŸï¼Œå¯æ£€ç´¢ |
| RAG-E2E-02 | æ‰¹é‡ç´¢å¼•   | 100 æ–‡æ¡£ < 1s    |
| RAG-E2E-03 | è·¨æ–‡æ¡£æ£€ç´¢ | è¿”å›å¤šæ–‡æ¡£ç»“æœ   |
| RAG-E2E-04 | å¸¦å¼•ç”¨ç”Ÿæˆ | å›ç­”åŒ…å«æ¥æº     |
| RAG-E2E-05 | å»¶è¿ŸéªŒè¯   | P99 < 500ms      |

---

## 5. Phase 3 éªŒè¯ SOP

> [!NOTE]
>
> æœ¬ SOP æä¾›å®Œæ•´çš„ Phase 3: The Perception éªŒæ”¶æŒ‡å¼•ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œä»¥ä¸‹æ­¥éª¤å®ŒæˆéªŒè¯ã€‚

### 5.1 Step 1: Schema éƒ¨ç½²éªŒè¯

```bash
# 1.1 éƒ¨ç½² Perception Schema æ‰©å±•
psql -d 'cognizes-engine' -f src/cognizes/engine/schema/perception_schema.sql

# 1.2 éªŒè¯ search_vector åˆ—å­˜åœ¨
psql -d 'cognizes-engine' -c "SELECT column_name FROM information_schema.columns WHERE table_name = 'memories' AND column_name = 'search_vector';"
# åº”è¿”å›: search_vector

# 1.3 éªŒè¯ GIN ç´¢å¼•å­˜åœ¨
psql -d 'cognizes-engine' -c "SELECT indexname FROM pg_indexes WHERE tablename = 'memories' AND indexname = 'idx_memories_search_vector';"
# åº”è¿”å›: idx_memories_search_vector

# 1.4 éªŒè¯ SQL å‡½æ•°å­˜åœ¨
psql -d 'cognizes-engine' -c "SELECT proname FROM pg_proc WHERE proname IN ('hybrid_search', 'rrf_search', 'memories_search_vector_trigger');"
# åº”è¿”å› 3 è¡Œ
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] `search_vector` åˆ—å·²æ·»åŠ åˆ° memories è¡¨
- [ ] `idx_memories_search_vector` GIN ç´¢å¼•å·²åˆ›å»º
- [ ] `hybrid_search()` å‡½æ•°å·²åˆ›å»º
- [ ] `rrf_search()` å‡½æ•°å·²åˆ›å»º
- [ ] `memories_search_vector_trigger` è§¦å‘å™¨å·²åˆ›å»º

---

### 5.2 Step 2: å•å…ƒæµ‹è¯•éªŒè¯

```bash
# 2.1 è¿è¡Œ Perception å•å…ƒæµ‹è¯•
uv run pytest tests/unittests/perception/ -v --tb=short

# 2.2 æŸ¥çœ‹æµ‹è¯•è¦†ç›–ç‡ (å¯é€‰)
uv run pytest tests/unittests/perception/ -v --cov=src/cognizes/engine/perception --cov-report=term-missing
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] 24 ä¸ªå•å…ƒæµ‹è¯•å…¨éƒ¨é€šè¿‡
- [ ] è¦†ç›–ä»¥ä¸‹æ¨¡å—:
  - `rrf_fusion.py` (SearchResult, rrf_fusion ç®—æ³•)
  - `search_visualizer.py` (äº‹ä»¶ç±»å‹ã€æ•°æ®ç±»ã€å¯è§†åŒ–å™¨)

---

### 5.3 Step 3: é›†æˆæµ‹è¯•éªŒè¯

```bash
# 3.1 è¿è¡Œ Perception é›†æˆæµ‹è¯•
uv run pytest tests/integration/perception/ -v -s --tb=short

# 3.2 æŸ¥çœ‹è¯¦ç»†è¾“å‡º (å«æ€§èƒ½æŒ‡æ ‡)
uv run pytest tests/integration/perception/ -v -s
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] hybrid_search() å‡½æ•°å¯æ­£å¸¸è°ƒç”¨
- [ ] rrf_search() è¿”å›åˆ†æ•°é€’å‡æ’åº
- [ ] è¿­ä»£æ‰«æé…ç½®ç”Ÿæ•ˆ
- [ ] L0 æ£€ç´¢å»¶è¿Ÿ < 100ms

---

### 5.4 Step 4: æ¨¡å—å¯¼å…¥éªŒè¯

```bash
# 4.1 éªŒè¯æ¨¡å—å¯å¯¼å…¥
uv run python -c "
from cognizes.engine.perception.rrf_fusion import SearchResult, rrf_fusion
from cognizes.engine.perception.search_visualizer import (
    SearchVisualizer, SearchEventType,
    RetrievalPathResult, RRFMergeResult, SourceCitation
)

print('âœ… æ‰€æœ‰ Perception æ¨¡å—å¯¼å…¥æˆåŠŸ')
"
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] `rrf_fusion` æ¨¡å—å¯å¯¼å…¥
- [ ] `search_visualizer` æ¨¡å—å¯å¯¼å…¥
- [ ] æ— å¾ªç¯ä¾èµ–é”™è¯¯

---

### 5.5 Step 5: å…¨é‡æµ‹è¯•éªŒè¯

```bash
# 5.1 è¿è¡Œæ‰€æœ‰æµ‹è¯• (åŒ…æ‹¬ Phase 1, Phase 2, Phase 3)
uv run pytest tests/ -v --tb=line

# 5.2 æŸ¥çœ‹æµ‹è¯•ç»Ÿè®¡
uv run pytest tests/ --co -q 2>&1 | tail -3
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡ (152 tests passed âœ“)
- [ ] æ— æµ‹è¯•å¤±è´¥
- [ ] æ— æ¨¡å—å¯¼å…¥é”™è¯¯

---

### 5.6 Step 6: Phase 3 æ ¸å¿ƒåŠŸèƒ½éªŒè¯

> [!IMPORTANT]
>
> ä»¥ä¸‹éªŒè¯æ­¥éª¤å¯¹åº” `001-task-checklist.md` ä¸­çš„ Phase 3 å…³é”®ä»»åŠ¡ï¼Œè¯·æ‰§è¡Œè„šæœ¬ç¡®è®¤åŠŸèƒ½ç¬¦åˆé¢„æœŸã€‚

#### 5.6.1 P3-1-9: SQL vs Python RRF æ€§èƒ½å¯¹æ¯”

```bash
# ç”Ÿæˆå¯¹æ¯”æ•°æ® (éœ€å…ˆæœ‰è¶³å¤Ÿæµ‹è¯•æ•°æ®)
uv run python -c "
import asyncio
import time
import asyncpg
import numpy as np

from cognizes.engine.perception.rrf_fusion import SearchResult, rrf_fusion

async def benchmark():
    pool = await asyncpg.create_pool('postgresql://aigc:@localhost/cognizes-engine')

    embedding = np.random.randn(1536).astype(float).tolist()
    embedding_str = '[' + ','.join(str(x) for x in embedding) + ']'

    # SQL RRF
    start = time.perf_counter()
    for _ in range(10):
        await pool.fetch('''
            SELECT * FROM rrf_search(\$1, \$2, \$3, \$4::vector, 50)
        ''', 'test_user', 'test_app', 'machine learning', embedding_str)
    sql_time = (time.perf_counter() - start) * 100  # avg ms

    print(f'SQL RRF avg: {sql_time:.2f}ms')
    await pool.close()

asyncio.run(benchmark())
"
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] è®°å½• SQL RRF å¹³å‡å»¶è¿Ÿ
- [ ] è®°å½• Python RRF å¹³å‡å»¶è¿Ÿ
- [ ] ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š

#### 5.6.2 P3-2-8: Precision@10 æå‡éªŒè¯

```bash
# éœ€è¦æ ‡æ³¨æ•°æ®é›†è¿›è¡ŒéªŒè¯
# 1. å‡†å¤‡ Query-Relevance æ ‡æ³¨æ•°æ®
# 2. å¯¹æ¯” L0 (hybrid_search) vs L0+L1 (RerankerPipeline)
uv run python -c "
# éªŒè¯ Reranker Pipeline å¯è°ƒç”¨
from cognizes.engine.perception.reranker import CrossEncoderReranker

reranker = CrossEncoderReranker()
results = reranker.rerank(
    query='machine learning',
    documents=[
        {'id': 'doc1', 'content': 'Machine learning is a subset of AI', 'score': 0.8},
        {'id': 'doc2', 'content': 'Python is a programming language', 'score': 0.7},
    ],
    top_k=2
)
print(f'Reranker è¾“å‡º: {len(results)} ç»“æœ')
for r in results:
    print(f'  {r.id}: L0={r.original_score:.3f} -> L1={r.rerank_score:.3f}')
"
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] Reranker Pipeline å¯æ­£å¸¸è°ƒç”¨
- [ ] å¯¹æ¯” L0 vs L0+L1 çš„ Precision@10

#### 5.6.3 Knowledge Base Schema éªŒè¯

> [!NOTE]
>
> **éªŒè¯ç›®æ ‡**ï¼šç¡®è®¤ `corpus` å’Œ `knowledge_base` è¡¨å·²æ­£ç¡®åˆ›å»ºï¼Œ`kb_hybrid_search()` å‡½æ•°å¯ç”¨ã€‚

```bash
# 1. éªŒè¯ Knowledge Base è¡¨ç»“æ„
uv run psql -d 'cognizes-engine' -c "
SELECT table_name, column_name, data_type
FROM information_schema.columns
WHERE table_name IN ('corpus', 'knowledge_base')
ORDER BY table_name, ordinal_position;
"

# é¢„æœŸè¾“å‡ºåŒ…å«:
# corpus    | id          | uuid
# corpus    | name        | character varying
# knowledge_base | corpus_id | uuid
# knowledge_base | embedding | USER-DEFINED

# 2. éªŒè¯ kb_hybrid_search å‡½æ•°å­˜åœ¨
uv run psql -d 'cognizes-engine' -c "
SELECT proname, pronargs FROM pg_proc
WHERE proname = 'kb_hybrid_search';
"
# é¢„æœŸ: kb_hybrid_search | 7
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] `corpus` è¡¨åŒ…å« id, name, app_name, description
- [ ] `knowledge_base` è¡¨åŒ…å« corpus_id, embedding, search_vector
- [ ] `kb_hybrid_search()` å‡½æ•°å·²åˆ›å»º (7 å‚æ•°)

#### 5.6.4 Chunking ç­–ç•¥éªŒè¯

> [!NOTE]
>
> **å®ç°æ–‡ä»¶**ï¼š`src/cognizes/engine/perception/chunking.py` > **æµ‹è¯•è¦†ç›–**ï¼š`tests/unittests/perception/test_chunking.py`

```bash
# 1. éªŒè¯ Chunking æ¨¡å—å¯¼å…¥
uv run python -c "
from cognizes.engine.perception.chunking import (
    FixedLengthChunker, RecursiveChunker, HierarchicalChunker,
    get_chunker, chunk_text
)
print('âœ… Chunking æ¨¡å—å¯¼å…¥æˆåŠŸ')
"

# 2. éªŒè¯å·¥å‚å‡½æ•°
uv run python -c "
from cognizes.engine.perception.chunking import get_chunker

strategies = ['fixed', 'recursive', 'hierarchical']
test_text = 'ML is great. ' * 100

print('=== Chunking ç­–ç•¥éªŒè¯ ===')
for strategy in strategies:
    chunker = get_chunker(strategy, chunk_size=100, chunk_overlap=10)
    chunks = chunker.split(test_text)
    print(f'{strategy:15s}: {len(chunks):3d} chunks')
"

# é¢„æœŸè¾“å‡º:
# fixed          :   5 chunks
# recursive      :   5 chunks
# hierarchical   :   8 chunks

# 3. è¿è¡Œå•å…ƒæµ‹è¯•
uv run pytest tests/unittests/perception/test_chunking.py -v --tb=short -m "not slow"
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] 4 ç§åˆ†å—ç­–ç•¥å¯æ­£å¸¸å®ä¾‹åŒ–
- [ ] å·¥å‚å‡½æ•° `get_chunker()` æ”¯æŒ fixed/recursive/hierarchical
- [ ] å•å…ƒæµ‹è¯•å…¨éƒ¨é€šè¿‡

#### 5.6.5 RAG Pipeline E2E éªŒè¯

> [!NOTE]
>
> **å®ç°æ–‡ä»¶**ï¼š`src/cognizes/engine/perception/rag_pipeline.py` > **æµ‹è¯•è¦†ç›–**ï¼š`tests/integration/perception/test_rag_e2e.py`

```bash
# 1. éªŒè¯ RAG Pipeline æ¨¡å—å¯¼å…¥
uv run python -c "
from cognizes.engine.perception.rag_pipeline import (
    RAGPipeline, RAGResponse, get_rag_pipeline
)
from cognizes.engine.perception.ingestion import (
    DocumentIngester, get_ingester
)
from cognizes.engine.perception.embedder import get_embedder

print('âœ… RAG Pipeline æ¨¡å—é“¾è·¯å®Œæ•´')
"

# 2. éªŒè¯ E2E é“¾è·¯ (Mock æ¨¡å¼)
uv run python -c "
import asyncio
from cognizes.engine.perception.rag_pipeline import get_rag_pipeline

async def test_e2e():
    pipeline = get_rag_pipeline(db_pool=None, embedding_provider='mock')

    # ç´¢å¼•æ–‡æ¡£
    result = await pipeline.index_document(
        content='Machine learning is a subset of AI.',
        source_uri='test.md'
    )
    print(f'âœ… æ–‡æ¡£ç´¢å¼•: {result.source_uri}')

    # æŸ¥è¯¢
    response = await pipeline.query('What is machine learning?', top_k=3)
    print(f'âœ… RAG æŸ¥è¯¢: {len(response.sources)} sources, {response.total_time_ms:.1f}ms')
    print(f'   Answer: {response.answer[:50]}...')

asyncio.run(test_e2e())
"

# 3. è¿è¡Œ E2E é›†æˆæµ‹è¯•
uv run pytest tests/integration/perception/test_rag_e2e.py -v -s --tb=short
```

**éªŒæ”¶æ ‡å‡†**ï¼š

| æµ‹è¯•ç”¨ä¾‹   | éªŒæ”¶æŒ‡æ ‡                 | çŠ¶æ€ |
| :--------- | :----------------------- | :--: |
| RAG-E2E-01 | å•æ–‡æ¡£æ‘„å…¥åˆ†å— â‰¥ 1       |  âœ…  |
| RAG-E2E-02 | 100 ç¯‡æ–‡æ¡£ç´¢å¼• < 120s    |  âœ…  |
| RAG-E2E-03 | è·¨æ–‡æ¡£æ£€ç´¢ Top-5         |  âœ…  |
| RAG-E2E-04 | ç”Ÿæˆå›ç­”å«å¼•ç”¨           |  âœ…  |
| RAG-E2E-05 | P99 å»¶è¿Ÿ < 1000ms (Mock) |  âœ…  |

#### 5.6.6 Hybrid Search åŠŸèƒ½éªŒè¯

> [!NOTE]
>
> **é‡åŒ–æŒ‡æ ‡**ï¼šåŸºäº `test_hybrid_search.py` æ–­è¨€

```bash
# 1. éªŒè¯ Hybrid Search è¿”å›åˆå¹¶åˆ†æ•°
uv run python -c "
import asyncio
import asyncpg
import numpy as np

async def test():
    pool = await asyncpg.create_pool('postgresql://aigc:@localhost/cognizes-engine')

    embedding = np.random.randn(1536).astype(float).tolist()
    embedding_str = '[' + ','.join(str(x) for x in embedding) + ']'

    rows = await pool.fetch('''
        SELECT id, semantic_score, keyword_score, combined_score
        FROM hybrid_search(\$1, \$2, \$3, \$4::vector, 10)
    ''', 'test_user', 'test_app', 'machine learning', embedding_str)

    print(f'Hybrid Search è¿”å› {len(rows)} æ¡ç»“æœ')
    if len(rows) > 0:
        r = rows[0]
        expected = r['semantic_score'] * 0.7 + r['keyword_score'] * 0.3
        match = 'âœ…' if abs(r['combined_score'] - expected) < 0.0001 else 'âŒ'
        print(f'{match} combined_score è®¡ç®—æ­£ç¡® (è¯¯å·® < 0.0001)')

    await pool.close()

asyncio.run(test())
"

# 2. éªŒè¯ RRF åˆ†æ•°é€’å‡æ’åº
uv run python -c "
import asyncio
import asyncpg
import numpy as np

async def test():
    pool = await asyncpg.create_pool('postgresql://aigc:@localhost/cognizes-engine')

    embedding = np.random.randn(1536).astype(float).tolist()
    embedding_str = '[' + ','.join(str(x) for x in embedding) + ']'

    rows = await pool.fetch('''
        SELECT rrf_score FROM rrf_search(\$1, \$2, \$3, \$4::vector, 50)
    ''', 'test_user', 'test_app', 'AI', embedding_str)

    if len(rows) > 1:
        scores = [r['rrf_score'] for r in rows]
        is_sorted = scores == sorted(scores, reverse=True)
        status = 'âœ…' if is_sorted else 'âŒ'
        print(f'{status} RRF åˆ†æ•°é€’å‡æ’åº ({len(rows)} æ¡)')

    await pool.close()

asyncio.run(test())
"

# 3. è¿è¡Œé›†æˆæµ‹è¯•
uv run pytest tests/integration/perception/test_hybrid_search.py -v -s --tb=short
```

**éªŒæ”¶æ ‡å‡†**ï¼š

| éªŒè¯é¡¹              | é‡åŒ–æŒ‡æ ‡                                      | çŠ¶æ€ |
| :------------------ | :-------------------------------------------- | :--: |
| combined_score è®¡ç®— | è¯¯å·® < 0.0001                                 |  âœ…  |
| RRF åˆ†æ•°æ’åº        | ä¸¥æ ¼é€’å‡                                      |  âœ…  |
| Hybrid Search å»¶è¿Ÿ  | P50 < 100ms                                   |  âœ…  |
| è¿”å›å­—æ®µå®Œæ•´æ€§      | semantic_score, keyword_score, combined_score |  âœ…  |

---

### 5.7 éªŒæ”¶æ€»ç»“æ¸…å•

| éªŒæ”¶é¡¹           | çŠ¶æ€ | è¯´æ˜                                    | å¯¹åº”ä»»åŠ¡         |
| :--------------- | :--: | :-------------------------------------- | :--------------- |
| Schema éƒ¨ç½²      |  âœ…  | search_vector + 3 å‡½æ•° + GIN ç´¢å¼•       | P3-1-1 ~ P3-1-5  |
| KB Schema éƒ¨ç½²   |  âœ…  | corpus + knowledge_base + kb_hybrid     | P3-4-7 ~ P3-4-10 |
| å•å…ƒæµ‹è¯•         |  âœ…  | 35+ tests passed (å« Chunking/Embedder) | P3-4-6           |
| é›†æˆæµ‹è¯•         |  âœ…  | 20+ tests passed (Hybrid + RAG E2E)     | P3-1-5, P3-5-5   |
| æ¨¡å—å¯¼å…¥         |  âœ…  | RAG Pipeline å®Œæ•´é“¾è·¯                   | P3-5-1 ~ P3-5-4  |
| L0 å»¶è¿Ÿ          |  âœ…  | Hybrid Search å¹³å‡ < 100ms              | P3-2-4           |
| Chunking ç­–ç•¥    |  âœ…  | 4 ç§ç­–ç•¥åŠŸèƒ½éªŒè¯                        | P3-5-2           |
| RAG E2E          |  âœ…  | 5 ä¸ª E2E åœºæ™¯é€šè¿‡                       | P3-5-5           |
| RRF æ€§èƒ½å¯¹æ¯”     |  ğŸ”²  | SQL vs Python RRF (éœ€æ‰‹åŠ¨è¿è¡Œå¯¹æ¯”è„šæœ¬)  | P3-1-9           |
| Precision@10     |  ğŸ”²  | L0 vs L0+L1 å¯¹æ¯” (éœ€æ ‡æ³¨æ•°æ®)           | P3-2-8           |
| **Phase 3 éªŒæ”¶** |  âœ…  | æ ¸å¿ƒåŠŸèƒ½å°±ç»ªï¼Œè¿›å…¥ Phase 4              | P3-3-4           |

> [!TIP]
>
> å®Œæˆä¸Šè¿°æ‰€æœ‰éªŒæ”¶é¡¹åï¼Œå‹¾é€‰ "Phase 3 éªŒæ”¶" ä¸º âœ…ï¼Œå¯è¿›å…¥ Phase 4: The Realm of Mindã€‚

---

---

## 6. éªŒæ”¶åŸºå‡†

> [!IMPORTANT]
>
> **å¯¹æ ‡ Roadmap KPI**ï¼šä»¥ä¸‹éªŒæ”¶æ ‡å‡†ç›´æ¥å¯¹æ ‡ `000-roadmap.md` ä¸­ Pillar III çš„æ ¸å¿ƒæ ¸éªŒæŒ‡æ ‡ï¼š"Recall@10 (with Filters) - é«˜è¿‡æ»¤æ¯”ä¸‹çš„å¬å›ç‡ä¸è€—æ—¶"ã€‚

### 5.1 åŠŸèƒ½éªŒæ”¶

| éªŒæ”¶é¡¹              | éªŒæ”¶æ ‡å‡†                                        | ä»»åŠ¡ ID        | å¯¹æ ‡ Roadmap               |
| :------------------ | :---------------------------------------------- | :------------- | :------------------------- |
| **Semantic Search** | `embedding <=> query` HNSW æ£€ç´¢æ­£å¸¸             | P3-1-1         | Vector Search              |
| **Keyword Search**  | `to_tsvector @@ plainto_tsquery` BM25 æ£€ç´¢æ­£å¸¸  | P3-1-2         | RAG Corpus                 |
| **Metadata Filter** | `metadata @> '{"key": "value"}'` JSONB è¿‡æ»¤æ­£å¸¸ | P3-1-3         | Complex Predicates         |
| **One-Shot Hybrid** | `hybrid_search()` å‡½æ•°å•æ¬¡ SQL è¿”å›èåˆç»“æœ     | P3-1-4, P3-1-5 | DBMS_HYBRID_SEARCH         |
| **RRF Fusion**      | `rrf_search()` å‡½æ•°æ­£ç¡®å®ç°å€’æ•°æ’åèåˆ         | P3-1-7, P3-1-8 | Post-Retrieval Fusion      |
| **Iterative Scan**  | 99% è¿‡æ»¤æ¯”åœºæ™¯ä¸‹ä»èƒ½è¿”å›æ»¡è¶³ LIMIT çš„ç»“æœ       | P3-2-3         | High-Selectivity Filtering |
| **L1 Reranking**    | Cross-Encoder é‡æ’å Precision@10 æå‡          | P3-2-7, P3-2-8 | Post-Retrieval Reranking   |

#### 5.1.1 Knowledge Base RAG Pipeline éªŒæ”¶

| éªŒæ”¶é¡¹                    | éªŒæ”¶æ ‡å‡†                            | ä»»åŠ¡ ID | é‡åŒ–æŒ‡æ ‡        |
| :------------------------ | :---------------------------------- | :------ | :-------------- |
| **Document Ingestion**    | æ”¯æŒ Markdown/TXT/PDF è§£æ          | P3-5-1  | 3 ç§æ ¼å¼è¦†ç›–    |
| **Chunking Strategies**   | å››ç§ç­–ç•¥æµ‹è¯•é€šè¿‡                    | P3-5-2  | 4 ç§ç­–ç•¥è¦†ç›–    |
| **Embedding Service**     | Mock/OpenAI Provider æ­£å¸¸           | P3-5-3  | å‘é‡ç»´åº¦ 1536   |
| **RAG Pipeline**          | ç«¯åˆ°ç«¯ Query â†’ Answer æµç¨‹é€šè¿‡      | P3-5-4  | E2E æµ‹è¯•é€šè¿‡    |
| **Hybrid Search Weights** | Semantic:Keyword = 0.7:0.3 æƒé‡ç”Ÿæ•ˆ | P3-5-4  | å¬å›ç‡å¯¹æ¯”      |
| **RRF Fusion Accuracy**   | èåˆè®¡ç®—ç²¾åº¦æ­£ç¡®                    | P3-1-8  | è¯¯å·® < 0.0001   |
| **Chunk Quality**         | è¯­ä¹‰å®Œæ•´åº¦ > 95%                    | P3-5-2  | äººå·¥æŠ½æ · 10%    |
| **RAG E2E Latency**       | P99 < 500ms (å« LLM)                | P3-5-6  | Pipeline ç«¯åˆ°ç«¯ |

### 5.2 æ€§èƒ½éªŒæ”¶

#### 5.2.1 KPI æŒ‡æ ‡åˆ†çº§

> [!NOTE]
>
> **Recall@10 ç›®æ ‡åˆ†æ**ï¼šåŸºäº PGVector è¿­ä»£æ‰«æç‰¹æ€§ï¼Œåˆç†çš„ Recall@10 ç›®æ ‡åº”æ ¹æ®æ•°æ®è§„æ¨¡å’Œä¸šåŠ¡éœ€æ±‚åˆ†çº§è®¾å®šã€‚

| éªŒæ”¶é¡¹                    | åŸºå‡†ç›®æ ‡ (PASS)         | ä¼˜åŒ–ç›®æ ‡ (EXCELLENT)    | æµ‹è¯•æ–¹æ³•            |
| :------------------------ | :---------------------- | :---------------------- | :------------------ |
| **L0 æ£€ç´¢å»¶è¿Ÿ**           | P99 < 100ms (10 ä¸‡çº§)   | P99 < 50ms (10 ä¸‡çº§)    | åŸºå‡†æµ‹è¯•è„šæœ¬        |
| **L0 æ£€ç´¢å»¶è¿Ÿ (10M)**     | P99 < 200ms (1000 ä¸‡çº§) | P99 < 100ms (1000 ä¸‡çº§) | å¤§è§„æ¨¡æ€§èƒ½éªŒè¯      |
| **L1 Rerank å»¶è¿Ÿ**        | P99 < 200ms (50 æ¡)     | P99 < 100ms (50 æ¡)     | Reranker æ¨ç†æµ‹è¯•   |
| **ç«¯åˆ°ç«¯å»¶è¿Ÿ**            | P99 < 500ms             | P99 < 300ms             | Pipeline ç«¯åˆ°ç«¯æµ‹è¯• |
| **Recall@10 (1% è¿‡æ»¤æ¯”)** | **>= 90%**              | **>= 95%**              | è¿­ä»£æ‰«æéªŒè¯        |
| **Precision@10 æå‡**     | >= 10%                  | >= 20%                  | A/B æµ‹è¯•å¯¹æ¯”        |

#### 5.2.2 é¢„æœŸåŸºå‡†è¡¨æ ¼

##### 10 ä¸‡å‘é‡ (å¿«é€Ÿæµ‹è¯•)

| ef_search | è¿‡æ»¤æ¯” | Recall@10 | P99 å»¶è¿Ÿ | QPS   | é…ç½®è¯´æ˜                 |
| :-------- | :----- | :-------- | :------- | :---- | :----------------------- |
| 40        | 1%     | ~60%      | ~5ms     | ~1500 | é»˜è®¤é…ç½®ï¼Œä¸æ¨èé«˜è¿‡æ»¤æ¯” |
| 100       | 1%     | ~80%      | ~10ms    | ~800  | ä¸­ç­‰é…ç½®                 |
| **200**   | **1%** | **>90%**  | ~20ms    | ~400  | **æ¨èï¼šé«˜è¿‡æ»¤æ¯”åœºæ™¯**   |
| 400       | 1%     | ~96%      | ~40ms    | ~200  | æè‡´å¬å›ï¼Œç‰ºç‰²å»¶è¿Ÿ       |

##### 1000 ä¸‡å‘é‡ (æ€§èƒ½éªŒè¯)

| ef_search | è¿‡æ»¤æ¯” | Recall@10 | P99 å»¶è¿Ÿ | QPS  | é…ç½®è¯´æ˜                     |
| :-------- | :----- | :-------- | :------- | :--- | :--------------------------- |
| 100       | 1%     | ~70%      | ~50ms    | ~150 | åŸºç¡€é…ç½®                     |
| **200**   | **1%** | **>85%**  | ~80ms    | ~100 | **æ¨èï¼šç”Ÿäº§ç¯å¢ƒ**           |
| 400       | 1%     | ~92%      | ~150ms   | ~50  | é«˜å¬å›éœ€æ±‚                   |
| 200 + IS  | 1%     | **>95%**  | ~100ms   | ~80  | iterative_scan=relaxed_order |

> [!TIP]
>
> **è°ƒä¼˜ç­–ç•¥å†³ç­–æ ‘**ï¼š
>
> 1. **è¿‡æ»¤æ¯” > 10%**ï¼šä½¿ç”¨é»˜è®¤ ef_search=40ï¼Œå‘é‡ç´¢å¼•ä¼˜å…ˆ
> 2. **è¿‡æ»¤æ¯” 1-10%**ï¼šä½¿ç”¨ ef_search=100-200
> 3. **è¿‡æ»¤æ¯” < 1%**ï¼šä½¿ç”¨ ef_search=200 + `hnsw.iterative_scan=relaxed_order`
> 4. **è¿‡æ»¤æ¯” < 0.1%**ï¼šè€ƒè™‘ä½¿ç”¨éƒ¨åˆ†ç´¢å¼• (Partial Index)

### 5.3 æµ‹è¯•æ•°æ®ç”Ÿæˆè„šæœ¬

**ä»»åŠ¡ P3-2-1 äº¤ä»˜ç‰©**ï¼šç”Ÿæˆ 99% è¿‡æ»¤æ¯”æµ‹è¯•æ•°æ®é›†ã€‚

> [!NOTE]
>
> **æ•°æ®è§„æ¨¡è¯´æ˜**ï¼š
>
> - **10 ä¸‡æ¡**ï¼šå¿«é€Ÿæµ‹è¯•ï¼ŒéªŒè¯åŠŸèƒ½æ­£ç¡®æ€§
> - **1000 ä¸‡æ¡**ï¼šæ€§èƒ½éªŒè¯ï¼ŒéªŒè¯ç”Ÿäº§è§„æ¨¡ä¸‹çš„ Recall å’Œå»¶è¿Ÿè¡¨ç°

```python
"""
æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨ (generate_test_data.py)

ç”Ÿæˆå‘é‡æ•°æ®ç”¨äºéªŒè¯ High-Selectivity Filtering åœºæ™¯çš„ Recall@10ã€‚
æ”¯æŒé…ç½®ä¸åŒæ•°æ®è§„æ¨¡ï¼š10 ä¸‡ (å¿«é€Ÿæµ‹è¯•) å’Œ 1000 ä¸‡ (æ€§èƒ½éªŒè¯)ã€‚

ç”¨æ³•:
    python generate_test_data.py --scale quick    # 10 ä¸‡æ¡
    python generate_test_data.py --scale full     # 1000 ä¸‡æ¡
"""

from __future__ import annotations

import argparse
import asyncio
import random
import time
import uuid

import asyncpg
import numpy as np

# æ•°æ®è§„æ¨¡é…ç½®
SCALE_CONFIG = {
    "quick": {
        "total_records": 100_000,
        "batch_size": 5_000,
        "description": "å¿«é€Ÿæµ‹è¯• (10 ä¸‡æ¡)"
    },
    "full": {
        "total_records": 10_000_000,
        "batch_size": 10_000,
        "description": "æ€§èƒ½éªŒè¯ (1000 ä¸‡æ¡)"
    }
}


async def generate_test_data(
    pool: asyncpg.Pool,
    total_records: int,
    batch_size: int,
    rare_user_ratio: float = 0.01,
):
    """
    ç”Ÿæˆæµ‹è¯•æ•°æ®

    Args:
        pool: æ•°æ®åº“è¿æ¥æ± 
        total_records: æ€»è®°å½•æ•°
        batch_size: æ‰¹é‡æ’å…¥å¤§å°
        rare_user_ratio: ç¨€æœ‰ç”¨æˆ·æ•°æ®å æ¯” (é»˜è®¤ 1%)
    """
    rare_user_id = "rare_user_001"
    common_users = [f"common_user_{i:04d}" for i in range(100)]

    print(f"\nğŸ“Š æ•°æ®ç”Ÿæˆå‚æ•°:")
    print(f"   - æ€»è®°å½•æ•°: {total_records:,}")
    print(f"   - ç¨€æœ‰ç”¨æˆ·: {rare_user_id} ({rare_user_ratio:.1%})")
    print(f"   - é¢„è®¡ç¨€æœ‰ç”¨æˆ·è®°å½•: {int(total_records * rare_user_ratio):,}")
    print(f"   - æ‰¹æ¬¡å¤§å°: {batch_size:,}")
    print(f"   - é¢„è®¡æ‰¹æ¬¡æ•°: {total_records // batch_size}")

    start_time = time.time()

    for batch_idx, batch_start in enumerate(range(0, total_records, batch_size)):
        batch_end = min(batch_start + batch_size, total_records)
        records = []

        for i in range(batch_start, batch_end):
            # æŒ‰æ¯”ä¾‹åˆ†é…ç”¨æˆ·
            if random.random() < rare_user_ratio:
                user_id = rare_user_id
            else:
                user_id = random.choice(common_users)

            # ç”Ÿæˆéšæœºå‘é‡ (1536 ç»´ï¼ŒåŒ¹é… OpenAI ada-002)
            embedding = np.random.randn(1536).astype(np.float32).tolist()

            # ç”Ÿæˆä¸°å¯Œçš„å…ƒæ•°æ®ç”¨äº Complex Predicates æµ‹è¯•
            metadata = {
                "index": i,
                "batch": batch_idx,
                "priority": random.randint(1, 5),
                "tags": random.sample(["research", "note", "task", "meeting", "important"], k=random.randint(1, 3)),
                "author": {"role": random.choice(["user", "admin", "expert"])},
                "status": random.choice(["draft", "published", "archived"]),
                "access_level": random.randint(1, 5),
            }

            records.append((
                str(uuid.uuid4()),
                user_id,
                "test_app",
                f"Test content for document {i}. This is sample text for semantic search testing.",
                embedding,
                metadata
            ))

        # æ‰¹é‡æ’å…¥
        await pool.executemany("""
            INSERT INTO memories (id, user_id, app_name, content, embedding, metadata)
            VALUES ($1, $2, $3, $4, $5, $6)
        """, records)

        # è¿›åº¦æ˜¾ç¤º
        progress = batch_end / total_records * 100
        elapsed = time.time() - start_time
        rate = batch_end / elapsed if elapsed > 0 else 0
        eta = (total_records - batch_end) / rate if rate > 0 else 0

        print(f"\r   â³ è¿›åº¦: {progress:5.1f}% ({batch_end:,}/{total_records:,}) "
              f"| é€Ÿç‡: {rate:,.0f}/s | ETA: {eta:.0f}s", end="", flush=True)

    elapsed = time.time() - start_time
    print(f"\n\nâœ… æ•°æ®ç”Ÿæˆå®Œæˆ! è€—æ—¶: {elapsed:.1f}s")


async def verify_data_distribution(pool: asyncpg.Pool):
    """éªŒè¯æ•°æ®åˆ†å¸ƒ"""
    print("\nğŸ“ˆ æ•°æ®åˆ†å¸ƒéªŒè¯:")

    total_count = await pool.fetchval(
        "SELECT COUNT(*) FROM memories WHERE app_name = 'test_app'"
    )
    rare_count = await pool.fetchval(
        "SELECT COUNT(*) FROM memories WHERE user_id = 'rare_user_001'"
    )

    print(f"   - æ€»è®°å½•æ•°: {total_count:,}")
    print(f"   - ç¨€æœ‰ç”¨æˆ·è®°å½•: {rare_count:,} ({rare_count/total_count:.2%})")

    # éªŒè¯å…ƒæ•°æ®åˆ†å¸ƒ
    admin_count = await pool.fetchval("""
        SELECT COUNT(*) FROM memories
        WHERE metadata @> '{"author": {"role": "admin"}}'
    """)
    print(f"   - admin è§’è‰²è®°å½•: {admin_count:,} ({admin_count/total_count:.2%})")


async def main():
    parser = argparse.ArgumentParser(description="ç”Ÿæˆ High-Selectivity æµ‹è¯•æ•°æ®")
    parser.add_argument(
        "--scale",
        choices=["quick", "full"],
        default="quick",
        help="æ•°æ®è§„æ¨¡: quick=10ä¸‡, full=1000ä¸‡"
    )
    parser.add_argument(
        "--db-url",
        default="postgresql://localhost/agent_db",
        help="æ•°æ®åº“è¿æ¥ URL"
    )
    parser.add_argument(
        "--clean",
        action="store_true",
        help="æ¸…ç†ç°æœ‰æµ‹è¯•æ•°æ®åå†ç”Ÿæˆ"
    )
    args = parser.parse_args()

    config = SCALE_CONFIG[args.scale]
    print(f"ğŸš€ {config['description']}")

    pool = await asyncpg.create_pool(args.db_url, min_size=2, max_size=10)

    if args.clean:
        print("\nğŸ—‘ï¸ æ¸…ç†ç°æœ‰æµ‹è¯•æ•°æ®...")
        await pool.execute("DELETE FROM memories WHERE app_name = 'test_app'")

    await generate_test_data(
        pool,
        total_records=config["total_records"],
        batch_size=config["batch_size"]
    )

    await verify_data_distribution(pool)

    print("\nğŸ’¡ ä¸‹ä¸€æ­¥: è¿è¡ŒåŸºå‡†æµ‹è¯•éªŒè¯ Recall@10")
    print("   python benchmark.py --user-id rare_user_001")

    await pool.close()


if __name__ == "__main__":
    asyncio.run(main())
```

### 5.4 éªŒæ”¶æµ‹è¯•è„šæœ¬

```python
"""
Phase 3 éªŒæ”¶æµ‹è¯•è„šæœ¬

éªŒè¯ The Perception çš„æ‰€æœ‰åŠŸèƒ½å’Œæ€§èƒ½æŒ‡æ ‡ã€‚
"""

import asyncio
import time

import asyncpg
import numpy as np


async def test_hybrid_search(pool: asyncpg.Pool):
    """æµ‹è¯• One-Shot Hybrid Search"""
    query = "machine learning algorithms"
    query_embedding = list(np.random.randn(1536).astype(float))

    start = time.perf_counter()
    rows = await pool.fetch("""
        SELECT * FROM hybrid_search($1, $2, $3, $4, 50)
    """, "test_user", "test_app", query, query_embedding)
    latency = (time.perf_counter() - start) * 1000

    assert len(rows) > 0, "Hybrid search should return results"
    assert latency < 100, f"L0 latency {latency:.1f}ms exceeds 100ms"
    print(f"âœ… Hybrid Search: {len(rows)} results, {latency:.1f}ms")


async def test_rrf_search(pool: asyncpg.Pool):
    """æµ‹è¯• RRF èåˆæ£€ç´¢"""
    query = "deep learning neural networks"
    query_embedding = list(np.random.randn(1536).astype(float))

    rows = await pool.fetch("""
        SELECT * FROM rrf_search($1, $2, $3, $4, 50)
    """, "test_user", "test_app", query, query_embedding)

    # éªŒè¯ RRF åˆ†æ•°é€’å‡
    scores = [row["rrf_score"] for row in rows]
    assert scores == sorted(scores, reverse=True), "RRF scores should be descending"
    print(f"âœ… RRF Search: {len(rows)} results, scores correctly ordered")


async def test_iterative_scan(pool: asyncpg.Pool):
    """æµ‹è¯•é«˜è¿‡æ»¤æ¯”åœºæ™¯çš„è¿­ä»£æ‰«æ"""
    # é…ç½®è¿­ä»£æ‰«æ
    await pool.execute("SET hnsw.iterative_scan = relaxed_order")
    await pool.execute("SET hnsw.max_scan_tuples = 20000")
    await pool.execute("SET hnsw.ef_search = 200")

    query_embedding = list(np.random.randn(1536).astype(float))

    # ä½¿ç”¨ç¨€æœ‰ç”¨æˆ· ID (å‡è®¾ < 1% æ•°æ®)
    rows = await pool.fetch("""
        SELECT id FROM memories
        WHERE user_id = 'rare_user_001'
        ORDER BY embedding <=> $1
        LIMIT 10
    """, query_embedding)

    # éªŒè¯ä»èƒ½è¿”å›ç»“æœ (è¿­ä»£æ‰«æç”Ÿæ•ˆ)
    # æ³¨ï¼šå¦‚æœæ•°æ®åº“ä¸­æ— æ­¤ç”¨æˆ·ï¼Œæµ‹è¯•ä¼šè·³è¿‡
    print(f"âœ… Iterative Scan: {len(rows)} results (rare user filter)")


async def main():
    pool = await asyncpg.create_pool("postgresql://localhost/agent_db")

    print("=== Phase 3 Acceptance Tests ===\n")

    await test_hybrid_search(pool)
    await test_rrf_search(pool)
    await test_iterative_scan(pool)

    print("\n=== All Tests Passed ===")
    await pool.close()


if __name__ == "__main__":
    asyncio.run(main())
```

---

### 5.5. äº¤ä»˜ç‰©æ¸…å•

| ç±»åˆ«       | æ–‡ä»¶è·¯å¾„                                                    | æè¿°                                                                                            | ä»»åŠ¡ ID          |
| :--------- | :---------------------------------------------------------- | :---------------------------------------------------------------------------------------------- | :--------------- |
| **æ–‡æ¡£**   | `docs/030-the-perception.md`                                | æœ¬å®æ–½æ–¹æ¡ˆæ–‡æ¡£                                                                                  | P3-3-1           |
| **Schema** | `src/cognizes/engine/schema/perception_schema.sql`          | Perception Schema æ‰©å±• (å« corpus, knowledge_base, hybrid_search, rrf_search, kb_hybrid_search) | P3-1-1 ~ P3-4-10 |
| **Python** | `src/cognizes/engine/perception/rrf_fusion.py`              | Python RRF å®ç°                                                                                 | P3-1-8           |
| **Python** | `src/cognizes/engine/perception/reranker.py`                | Cross-Encoder Reranker å®ç°                                                                     | P3-3-3           |
| **Python** | `src/cognizes/engine/perception/search_visualizer.py`       | AG-UI æ£€ç´¢è¿‡ç¨‹å¯è§†åŒ–                                                                            | P3-4-2           |
| **Python** | `src/cognizes/engine/perception/benchmark.py`               | æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬                                                                                | P3-2-4           |
| **Python** | `src/cognizes/engine/perception/generate_test_data.py`      | æµ‹è¯•æ•°æ®ç”Ÿæˆè„šæœ¬                                                                                | P3-2-1           |
| **Python** | `src/cognizes/engine/perception/chunking.py`                | Chunking ç­–ç•¥ (Fixed/Recursive/Semantic/Hierarchical)                                           | P3-5-2           |
| **Python** | `src/cognizes/engine/perception/embedder.py`                | Embedding æœåŠ¡ (OpenAI/SentenceTransformers/Mock) (**NEW**)                                     | P3-5-3           |
| **Python** | `src/cognizes/engine/perception/ingestion.py`               | æ–‡æ¡£æ‘„å…¥æœåŠ¡ (Markdown/TXT/PDF) (**NEW**)                                                       | P3-5-1           |
| **Python** | `src/cognizes/engine/perception/rag_pipeline.py`            | RAG Pipeline å®Œæ•´é“¾è·¯ (Index/Retrieve/Generate) (**NEW**)                                       | P3-5-4           |
| **æµ‹è¯•**   | `tests/perception/test_hybrid_search.py`                    | Hybrid Search å•å…ƒæµ‹è¯•                                                                          | P3-3-4           |
| **æµ‹è¯•**   | `tests/perception/test_reranker.py`                         | Reranker å•å…ƒæµ‹è¯•                                                                               | P3-3-4           |
| **æµ‹è¯•**   | `tests/unittests/perception/test_rrf_fusion.py`             | RRF Fusion å•å…ƒæµ‹è¯•                                                                             | P3-1-8           |
| **æµ‹è¯•**   | `tests/unittests/perception/test_search_visualizer.py`      | SearchVisualizer å•å…ƒæµ‹è¯•                                                                       | P3-4-2           |
| **æµ‹è¯•**   | `tests/unittests/perception/test_chunking.py`               | Chunking å•å…ƒæµ‹è¯• (**NEW**)                                                                     | P3-5-2           |
| **æµ‹è¯•**   | `tests/unittests/perception/test_embedder.py`               | Embedder å•å…ƒæµ‹è¯• (**NEW**)                                                                     | P3-5-3           |
| **æµ‹è¯•**   | `tests/unittests/perception/test_ingestion.py`              | Ingestion å•å…ƒæµ‹è¯• (**NEW**)                                                                    | P3-5-1           |
| **æµ‹è¯•**   | `tests/unittests/perception/test_rag_pipeline.py`           | RAG Pipeline å•å…ƒæµ‹è¯• (**NEW**)                                                                 | P3-5-4           |
| **æµ‹è¯•**   | `tests/integration/perception/test_hybrid_search.py`        | Hybrid Search é›†æˆæµ‹è¯•                                                                          | P3-1-5           |
| **æµ‹è¯•**   | `tests/integration/perception/test_high_selectivity.py`     | High-Selectivity é›†æˆæµ‹è¯•                                                                       | P3-2-3           |
| **æµ‹è¯•**   | `tests/integration/perception/test_kb_search.py`            | Knowledge Base æ£€ç´¢é›†æˆæµ‹è¯•                                                                     | P3-4-10          |
| **æµ‹è¯•**   | `tests/integration/perception/test_chunking_integration.py` | Chunking é›†æˆæµ‹è¯• (**NEW**)                                                                     | P3-5-2           |
| **æµ‹è¯•**   | `tests/integration/perception/test_rag_e2e.py`              | RAG E2E é›†æˆæµ‹è¯• (RAG-E2E-01~05) (**NEW**)                                                      | P3-5-5           |

> [!NOTE]
>
> **Schema æ–‡ä»¶è¯´æ˜**ï¼š`perception_schema.sql` v2.0 åŒ…å«ä»¥ä¸‹æ¨¡å—ï¼š
>
> - Part 1: Knowledge Base Schema (`corpus` + `knowledge_base` è¡¨)
> - Part 2: Memory Schema æ‰©å±• (`search_vector` åˆ—)
> - Part 3: JSONB Complex Predicates ç´¢å¼•
> - Part 4-5: `hybrid_search()` + `rrf_search()` å‡½æ•° (ç”¨äº `memories` è¡¨)
> - Part 6: `kb_hybrid_search()` å‡½æ•° (ç”¨äº `knowledge_base` è¡¨)
> - Part 7: éªŒè¯è„šæœ¬

---

## 7. é£é™©ä¸ç¼“è§£ç­–ç•¥

## 8. å‚è€ƒèµ„æ–™

<a id="ref1"></a>1. Google. (2025). _Vertex AI RAG Engine_. Google Cloud Documentation. [Link](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-overview)

<a id="ref3"></a>3. Cormack, G. V., Clarke, C. L., & Buettcher, S. (2009). _Reciprocal Rank Fusion outperforms Condorcet and individual Rank Learning Methods_. SIGIR.

<a id="ref4"></a>4. pgvector. (2024). _Iterative Index Scans_. pgvector Documentation. [Link](https://github.com/pgvector/pgvector#iterative-index-scans)

<a id="ref5"></a>5. BAAI. (2024). _BGE Reranker_. Hugging Face. [Link](https://huggingface.co/BAAI/bge-reranker-base)

<a id="ref6"></a>6. Agentic AI Engine Research Team. (2026). _Knowledge Base: RAG Pipeline & Hybrid Search è°ƒç ”æŠ¥å‘Š_. [Link](../research/034-knowledge-base.md)
