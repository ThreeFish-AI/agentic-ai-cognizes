---
id: the-perception-implementation
sidebar_position: 1.4
title: Phase 3ï¼šThe Perception éªŒè¯å®æ–½æ–¹æ¡ˆ
last_update:
  author: Aurelius Huang
  created_at: 2026-01-09
  updated_at: 2026-01-09
  version: 1.0
  status: Draft
tags:
  - The Perception
  - Unified Search
  - Fusion Retrieval
  - Implementation Plan
  - PostgreSQL
  - Hybrid Search
---

> [!NOTE]
>
> **æ–‡æ¡£å®šä½**ï¼šæœ¬æ–‡æ¡£æ˜¯ [000-roadmap.md](./000-roadmap.md) Phase 3 çš„è¯¦ç»†å·¥ç¨‹å®æ–½æ–¹æ¡ˆï¼Œç”¨äºæŒ‡å¯¼ã€Œ**The Perception (ç¥ç»æ„ŸçŸ¥)**ã€çš„å®Œæ•´è½åœ°éªŒè¯å·¥ä½œã€‚æ¶µç›–æŠ€æœ¯è°ƒç ”ã€æ¶æ„è®¾è®¡ã€ä»£ç å®ç°ã€æµ‹è¯•éªŒè¯ç­‰å…¨æµç¨‹ã€‚
>
> **å‰ç½®ä¾èµ–**ï¼šæœ¬é˜¶æ®µä¾èµ– [010-the-pulse.md](./010-the-pulse.md) Phase 1 å’Œ [020-the-hippocampus.md](./020-the-hippocampus.md) Phase 2 çš„å®Œæˆï¼Œéœ€å¤ç”¨å…¶ç»Ÿä¸€å­˜å‚¨åŸºåº§ (Unified Schema) å’Œè®°å¿†ç®¡ç†èƒ½åŠ›ã€‚

---

## 1. æ‰§è¡Œæ¦‚è§ˆ

### 1.1 Phase 3 å®šä½ä¸ç›®æ ‡

**Phase 3: The Perception** æ˜¯æ•´ä¸ªéªŒè¯è®¡åˆ’çš„æ£€ç´¢æ ¸å¿ƒé˜¶æ®µï¼Œå¯¹æ ‡äººç±»å¤§è„‘çš„**æ„ŸçŸ¥ç³»ç»Ÿ (Perception System)** â€”â€” è´Ÿè´£ä»æµ·é‡ä¿¡æ¯ä¸­å¿«é€Ÿå®šä½å’Œè¯†åˆ«ç›®æ ‡çš„ç¥ç»ä¸­æ¢ã€‚æ ¸å¿ƒç›®æ ‡æ˜¯ï¼š

1. **æ„å»º One-Shot Integrated æ£€ç´¢é“¾è·¯**ï¼šå®ç°å•æ¬¡ SQL æŸ¥è¯¢èåˆ Semantic (å‘é‡) + Keyword (BM25) + Structural (å…ƒæ•°æ®) ä¸‰ç§æ£€ç´¢ä¿¡å·
2. **éªŒè¯ RRF èåˆç®—æ³•**ï¼šå®ç° Reciprocal Rank Fusion ç®—æ³•ï¼Œåˆå¹¶å¤šè·¯å¬å›ç»“æœ
3. **éªŒè¯é«˜è¿‡æ»¤æ¯”åœºæ™¯**ï¼šéªŒè¯ HNSW è¿­ä»£æ‰«æåœ¨ 99% è¿‡æ»¤æ¯”ä¸‹çš„å¬å›ç‡ä¸æ€§èƒ½
4. **éªŒè¯ L1 Reranking**ï¼šé›†æˆè½»é‡çº§ Cross-Encoder æ¨¡å‹ï¼Œæå‡æ£€ç´¢ç²¾åº¦

```mermaid
graph LR
    subgraph "Phase 3: The Perception"
        F[Phase 1/2 åŸºåº§<br>Session + Memory] --> P1[Fusion Retrieval<br>èåˆæ£€ç´¢]
        F --> P2[High-Selectivity<br>é«˜è¿‡æ»¤æ¯”å¬å›]
        F --> P3[L1 Reranking<br>è¯­ä¹‰é‡æ’]
    end

    P1 & P2 & P3 --> V[Verification<br>éªŒæ”¶é€šè¿‡]
    V --> Phase4[Phase 4: Realm of Mind]

    style F fill:#065f46,stroke:#34d399,color:#fff
    style P1 fill:#7c2d12,stroke:#fb923c,color:#fff
    style P2 fill:#7c2d12,stroke:#fb923c,color:#fff
    style P3 fill:#7c2d12,stroke:#fb923c,color:#fff
```

### 1.2 æ ¸å¿ƒæ¦‚å¿µè§£æ

#### 1.2.1 æ£€ç´¢ä¿¡å·ç±»å‹

The Perception çš„æ ¸å¿ƒæ˜¯å°†ä¸‰ç§æ­£äº¤çš„æ£€ç´¢ä¿¡å·èåˆä¸ºç»Ÿä¸€çš„æ£€ç´¢ç»“æœï¼š

| æ£€ç´¢ä¿¡å·     | å®šä¹‰                            | é€‚ç”¨åœºæ™¯           | PostgreSQL å®ç°                          |
| :----------- | :------------------------------ | :----------------- | :--------------------------------------- |
| **Semantic** | è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢ï¼ˆå‘é‡è·ç¦»ï¼‰      | è¯­ä¹‰ç†è§£ã€æ¦‚å¿µåŒ¹é… | `embedding <=> query_embedding` (HNSW)   |
| **Keyword**  | å…³é”®è¯åŒ¹é…æ£€ç´¢ï¼ˆBM25/å…¨æ–‡æœç´¢ï¼‰ | ç²¾ç¡®è¯æ±‡ã€æŠ€æœ¯æœ¯è¯­ | `to_tsvector @@ plainto_tsquery` (GIN)   |
| **Metadata** | ç»“æ„åŒ–å…ƒæ•°æ®è¿‡æ»¤ï¼ˆJSONB/æ ‡é‡ï¼‰  | æƒé™æ§åˆ¶ã€æ—¶é—´èŒƒå›´ | `metadata @> '{"key": "value"}'` (BTREE) |

#### 1.2.2 æ£€ç´¢é“¾è·¯æ¶æ„

```mermaid
graph TB
    subgraph "æ£€ç´¢é“¾è·¯ (Retrieval Pipeline)"
        Q[User Query] --> E[Embedding<br>å‘é‡åŒ–]
        Q --> T[Tokenize<br>åˆ†è¯]
        Q --> F[Filter Parse<br>è¿‡æ»¤è§£æ]

        E --> S1[Semantic Search<br>HNSW å‘é‡æ£€ç´¢]
        T --> S2[Keyword Search<br>BM25 å…¨æ–‡æ£€ç´¢]
        F --> S3[Metadata Filter<br>JSONB è¿‡æ»¤]

        S1 & S2 & S3 --> RRF[RRF Fusion<br>å€’æ•°æ’åèåˆ]
        RRF --> L0[L0 ç²—æ’ç»“æœ<br>Top-50]
        L0 --> RK[L1 Reranking<br>Cross-Encoder]
        RK --> R[Final Results<br>Top-10]
    end

    style Q fill:#1e3a5f,stroke:#60a5fa,color:#fff
    style RRF fill:#065f46,stroke:#34d399,color:#fff
    style RK fill:#7c2d12,stroke:#fb923c,color:#fff
    style R fill:#059669,stroke:#34d399,color:#fff
```

#### 1.2.3 Two-Stage Retrieval (ä¸¤é˜¶æ®µæ£€ç´¢)

> [!IMPORTANT]
>
> **å¯¹æ ‡ Roadmap Pillar III**ï¼šThe Perception é‡‡ç”¨ä¸¤é˜¶æ®µæ£€ç´¢æ¶æ„ï¼Œå®ç°ã€Œç²—æ’ (L0)ã€ä¸ã€Œç²¾æ’ (L1)ã€çš„åˆ†ç¦»ã€‚

| é˜¶æ®µ        | å®šä¹‰             | æŠ€æœ¯å®ç°            | ç›®æ ‡                        |
| :---------- | :--------------- | :------------------ | :-------------------------- |
| **L0 ç²—æ’** | æ•°æ®åº“å±‚èåˆæ£€ç´¢ | PostgreSQL One-Shot | é«˜å¬å›ç‡ (Recall@50 > 95%)  |
| **L1 ç²¾æ’** | åº”ç”¨å±‚è¯­ä¹‰é‡æ’   | Cross-Encoder Model | é«˜ç²¾åº¦ (Precision@10 > 90%) |

### 1.3 å¯¹æ ‡åˆ†æï¼šGoogle RAG Engine

åŸºäº Google Vertex AI RAG Engine å’Œ ADK æ–‡æ¡£<sup>[[1]](#ref1)</sup>çš„åˆ†æï¼Œæˆ‘ä»¬éœ€è¦å¤åˆ»ä»¥ä¸‹æ ¸å¿ƒèƒ½åŠ›ï¼š

| Google æ ¸å¿ƒèƒ½åŠ›             | å®šä¹‰                    | PostgreSQL å¤åˆ»ç­–ç•¥       |
| :-------------------------- | :---------------------- | :------------------------ |
| **Vertex AI Vector Search** | æ‰˜ç®¡å‘é‡æ£€ç´¢æœåŠ¡        | PGVector HNSW ç´¢å¼•        |
| **RAG Corpus**              | æ£€ç´¢è¯­æ–™åº“ç®¡ç†          | `memories` + `facts` è¡¨   |
| **Hybrid Retrieval**        | å‘é‡ + ç¨€ç–å‘é‡æ··åˆæ£€ç´¢ | `DBMS_HYBRID_SEARCH` å‡½æ•° |
| **Ranking API**             | LLM é©±åŠ¨çš„é‡æ’æœåŠ¡      | Cross-Encoder æœ¬åœ°æ¨ç†    |
| **Filter-Based Retrieval**  | å…ƒæ•°æ®è¿‡æ»¤æ£€ç´¢          | JSONB æ¡ä»¶ + éƒ¨åˆ†ç´¢å¼•     |

#### 1.3.1 Google RAG Pipeline å¯¹æ ‡

```mermaid
sequenceDiagram
    participant User
    participant Agent
    participant RAG as RAG Engine
    participant VS as Vector Search
    participant LLM as Ranking LLM

    User->>Agent: ç”¨æˆ·æŸ¥è¯¢
    Agent->>RAG: retrieve(query, filters)

    par å¹¶è¡Œæ£€ç´¢
        RAG->>VS: å‘é‡æ£€ç´¢ (Semantic)
        RAG->>VS: ç¨€ç–å‘é‡æ£€ç´¢ (Sparse)
    end

    VS-->>RAG: å¤šè·¯å¬å›ç»“æœ
    RAG->>RAG: RRF èåˆ
    RAG->>LLM: Rerank (Top-50)
    LLM-->>RAG: é‡æ’ç»“æœ (Top-10)
    RAG-->>Agent: ç²¾æ’ Chunks
    Agent->>User: ç”Ÿæˆå›ç­”
```

**å…³é”®æ´å¯Ÿ**ï¼š

1. **å¹¶è¡Œå¬å›**ï¼šå‘é‡æ£€ç´¢ä¸å…³é”®è¯æ£€ç´¢å¹¶è¡Œæ‰§è¡Œï¼Œå‡å°‘æ€»å»¶è¿Ÿ
2. **ä¸¤é˜¶æ®µæ’åº**ï¼šL0 (RRF) + L1 (Rerank) åˆ†å±‚å¤„ç†ï¼Œå¹³è¡¡æ•ˆç‡ä¸ç²¾åº¦
3. **åŠ¨æ€è¿‡æ»¤**ï¼šå…ƒæ•°æ®è¿‡æ»¤ä¸æ£€ç´¢èåˆï¼Œè€Œéåç½®è¿‡æ»¤

### 1.4 ä»»åŠ¡-ç« èŠ‚å¯¹ç…§è¡¨

> [!NOTE]
>
> ä»¥ä¸‹è¡¨æ ¼å°† [001-task-checklist.md](./001-task-checklist.md) çš„ä»»åŠ¡ ID ä¸æœ¬æ–‡æ¡£ç« èŠ‚è¿›è¡Œå¯¹ç…§ï¼Œä¾¿äºè¿½è¸ªæ‰§è¡Œè¿›åº¦ã€‚

| ä»»åŠ¡æ¨¡å—          | ä»»åŠ¡ ID èŒƒå›´    | å¯¹åº”ç« èŠ‚                                                                        |
| :---------------- | :-------------- | :------------------------------------------------------------------------------ |
| Hybrid Search SQL | P3-1-1 ~ P3-1-5 | [4.1 Step 1: Fusion Retrieval å®ç°](#41-step-1-fusion-retrieval-å®ç°)           |
| RRF èåˆç®—æ³•      | P3-1-6 ~ P3-1-9 | [4.1.2 RRF èåˆç®—æ³•](#412-rrf-èåˆç®—æ³•-reciprocal-rank-fusion)                  |
| High-Selectivity  | P3-2-1 ~ P3-2-4 | [4.2 Step 2: High-Selectivity Filtering](#42-step-2-high-selectivity-filtering) |
| L1 Reranking      | P3-2-5 ~ P3-2-8 | [4.3 Step 3: L1 Reranking å®ç°](#43-step-3-l1-reranking-å®ç°)                   |
| éªŒæ”¶ä¸æ–‡æ¡£        | P3-3-1 ~ P3-3-4 | [5. éªŒæ”¶æ ‡å‡†](#5-éªŒæ”¶æ ‡å‡†) + [6. äº¤ä»˜ç‰©](#6-äº¤ä»˜ç‰©æ¸…å•)                         |

### 1.5 å·¥æœŸè§„åˆ’

| é˜¶æ®µ | ä»»åŠ¡æ¨¡å—         | ä»»åŠ¡ ID         | é¢„ä¼°å·¥æœŸ | äº¤ä»˜ç‰©                         |
| :--- | :--------------- | :-------------- | :------- | :----------------------------- |
| 3.1  | Fusion Retrieval | P3-1-1 ~ P3-1-9 | 0.5 Day  | `hybrid_search.sql` + RRF å‡½æ•° |
| 3.2  | High-Selectivity | P3-2-1 ~ P3-2-4 | 0.25 Day | è¿­ä»£æ‰«æé…ç½® + æ€§èƒ½åŸºå‡†æŠ¥å‘Š    |
| 3.3  | L1 Reranking     | P3-2-5 ~ P3-2-8 | 0.25 Day | `reranker.py` + Precision éªŒè¯ |
| 3.4  | æµ‹è¯•ä¸éªŒæ”¶       | P3-3-1 ~ P3-3-4 | 0.25 Day | æµ‹è¯•æŠ¥å‘Š + æŠ€æœ¯æ–‡æ¡£            |

---

## 2. æŠ€æœ¯è°ƒç ”ï¼šæ£€ç´¢æœºåˆ¶æ·±åº¦åˆ†æ

### 2.1 æ··åˆæ£€ç´¢ç­–ç•¥å¯¹æ¯”

ç°ä»£ RAG ç³»ç»Ÿæ™®éé‡‡ç”¨æ··åˆæ£€ç´¢ç­–ç•¥<sup>[[2]](#ref2)</sup>ï¼Œç»“åˆå‘é‡æ£€ç´¢å’Œå…³é”®è¯æ£€ç´¢çš„ä¼˜åŠ¿ï¼š

| æ£€ç´¢ç±»å‹       | ä¼˜åŠ¿                       | åŠ£åŠ¿                             | å…¸å‹åœºæ™¯           |
| :------------- | :------------------------- | :------------------------------- | :----------------- |
| **å‘é‡æ£€ç´¢**   | è¯­ä¹‰ç†è§£å¼ºï¼Œæ³›åŒ–èƒ½åŠ›å¥½     | å¯¹ç²¾ç¡®è¯æ±‡åŒ¹é…å¼±ï¼Œå¯èƒ½"è¯­ä¹‰æ¼‚ç§»" | æ¦‚å¿µæŸ¥è¯¢ã€åŒä¹‰è½¬æ¢ |
| **å…³é”®è¯æ£€ç´¢** | ç²¾ç¡®åŒ¹é…ï¼Œå¯¹ä¸“ä¸šæœ¯è¯­æ•æ„Ÿ   | ç¼ºä¹è¯­ä¹‰ç†è§£ï¼Œå¯¹åŒä¹‰è¯æ— åŠ›       | ä»£ç æœç´¢ã€æœ¯è¯­æŸ¥è¯¢ |
| **æ··åˆæ£€ç´¢**   | ç»¼åˆä¸¤è€…ä¼˜åŠ¿ï¼Œè¦†ç›–æ›´å¤šåœºæ™¯ | å®ç°å¤æ‚åº¦é«˜ï¼Œéœ€è¦èåˆç­–ç•¥       | ä¼ä¸š RAGã€é€šç”¨æœç´¢ |

#### 2.1.1 PostgreSQL æ··åˆæ£€ç´¢èƒ½åŠ›

PostgreSQL å¤©ç„¶æ”¯æŒæ··åˆæ£€ç´¢ï¼Œæ— éœ€å¤–éƒ¨ç³»ç»Ÿæ‹¼æ¥ï¼š

```sql
-- One-Shot æ··åˆæ£€ç´¢ç¤ºä¾‹
SELECT id, content,
    -- å‘é‡ç›¸ä¼¼åº¦åˆ†æ•° (è½¬ä¸º 0-1 èŒƒå›´)
    1 - (embedding <=> $query_embedding) AS semantic_score,
    -- BM25 å…¨æ–‡åŒ¹é…åˆ†æ•°
    ts_rank_cd(search_vector, plainto_tsquery($query)) AS keyword_score
FROM memories
WHERE
    -- å…ƒæ•°æ®è¿‡æ»¤
    app_name = $app_name AND user_id = $user_id
    -- å¯é€‰ï¼šå…³é”®è¯å¿…é¡»åŒ¹é…
    AND search_vector @@ plainto_tsquery($query)
ORDER BY
    -- èåˆæ’åº (å¯æ›¿æ¢ä¸º RRF)
    semantic_score * 0.7 + keyword_score * 0.3 DESC
LIMIT 50;
```

### 2.2 RRF ç®—æ³•åŸç†

**Reciprocal Rank Fusion (RRF)** æ˜¯ä¸€ç§æ— å‚æ•°çš„å¤šè·¯å¬å›èåˆç®—æ³•<sup>[[3]](#ref3)</sup>ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š

> **æ’åé å‰çš„æ–‡æ¡£ï¼Œæ— è®ºæ¥è‡ªå“ªä¸ªæ£€ç´¢å™¨ï¼Œéƒ½åº”è¯¥è·å¾—æ›´é«˜çš„èåˆåˆ†æ•°ã€‚**

#### 2.2.1 RRF æ•°å­¦å…¬å¼

$$
\text{RRF}(d) = \sum_{r \in R} \frac{1}{k + r(d)}
$$

å…¶ä¸­ï¼š

- $d$ æ˜¯æ–‡æ¡£
- $R$ æ˜¯æ‰€æœ‰æ£€ç´¢å™¨çš„æ’ååˆ—è¡¨
- $r(d)$ æ˜¯æ–‡æ¡£ $d$ åœ¨æ£€ç´¢å™¨ä¸­çš„æ’å (ä» 1 å¼€å§‹)
- $k$ æ˜¯å¹³æ»‘å¸¸æ•° (é€šå¸¸å– 60)

#### 2.2.2 RRF ç¤ºä¾‹è®¡ç®—

| æ–‡æ¡£ | å‘é‡æ£€ç´¢æ’å | å…³é”®è¯æ£€ç´¢æ’å | RRF åˆ†æ•° (k=60)              |
| :--- | :----------- | :------------- | :--------------------------- |
| A    | 1            | 3              | 1/(60+1) + 1/(60+3) = 0.0325 |
| B    | 2            | 1              | 1/(60+2) + 1/(60+1) = 0.0325 |
| C    | 3            | 2              | 1/(60+3) + 1/(60+2) = 0.0322 |
| D    | 5            | -              | 1/(60+5) = 0.0154            |

**è§‚å¯Ÿ**ï¼šæ–‡æ¡£ A å’Œ B çš„ RRF åˆ†æ•°ç›¸åŒï¼Œè¯´æ˜ RRF å¯¹ä¸åŒæ£€ç´¢å™¨çš„æ’åç»™äºˆç­‰æƒé‡ã€‚

### 2.3 é«˜è¿‡æ»¤æ¯”æ£€ç´¢é—®é¢˜

> [!WARNING]
>
> **High-Selectivity Filtering é™·é˜±**ï¼šå½“è¿‡æ»¤æ¡ä»¶éå¸¸ä¸¥æ ¼ (å¦‚ `user_id = 'xxx'` ä»…åŒ¹é… 1% æ•°æ®) æ—¶ï¼Œå‘é‡ç´¢å¼•çš„ Top-K å¬å›å¯èƒ½ä¸åŒ…å«ä»»ä½•ç¬¦åˆè¿‡æ»¤æ¡ä»¶çš„ç»“æœï¼

#### 2.3.1 é—®é¢˜åœºæ™¯

```sql
-- åœºæ™¯ï¼šç”¨æˆ· 'alice' åªæœ‰ 100 æ¡è®°å¿†ï¼Œæ€»è¡¨æœ‰ 100 ä¸‡æ¡
-- é—®é¢˜ï¼šHNSW é»˜è®¤çš„ ef_search=40 å¯èƒ½åªæ‰«æåˆ°å…¶ä»–ç”¨æˆ·çš„æ•°æ®

SELECT * FROM memories
WHERE user_id = 'alice'  -- ä»… 0.01% çš„æ•°æ®
ORDER BY embedding <=> $query LIMIT 10;

-- ç»“æœï¼šå¯èƒ½è¿”å› 0 æ¡æ•°æ®ï¼
```

#### 2.3.2 è§£å†³æ–¹æ¡ˆï¼šè¿­ä»£ç´¢å¼•æ‰«æ

PGVector 0.8.0+ å¼•å…¥äº† **Iterative Index Scan**<sup>[[4]](#ref4)</sup>ï¼Œè‡ªåŠ¨æ‰©å¤§æ£€ç´¢èŒƒå›´ç›´åˆ°æ»¡è¶³ LIMITï¼š

```sql
-- å¼€å¯è¿­ä»£æ‰«æ
SET hnsw.iterative_scan = relaxed_order;
SET hnsw.max_scan_tuples = 20000;  -- æœ€å¤§æ‰«æå…ƒç»„æ•°

-- ç°åœ¨ä¼šè‡ªåŠ¨æ‰©å±•æ£€ç´¢ï¼Œç›´åˆ°æ‰¾åˆ° 10 æ¡ç¬¦åˆæ¡ä»¶çš„ç»“æœ
SELECT * FROM memories
WHERE user_id = 'alice'
ORDER BY embedding <=> $query LIMIT 10;
```

### 2.4 Reranking æŠ€æœ¯æ ˆ

L1 Reranking ä½¿ç”¨ Cross-Encoder æ¨¡å‹å¯¹ç²—æ’ç»“æœè¿›è¡Œç²¾æ’<sup>[[5]](#ref5)</sup>ï¼š

| æ¨¡å‹ç±»å‹          | ç‰¹ç‚¹                              | æ¨ç†é€Ÿåº¦ | ç²¾åº¦   |
| :---------------- | :-------------------------------- | :------- | :----- |
| **Bi-Encoder**    | Query å’Œ Doc åˆ†åˆ«ç¼–ç ï¼Œå¯é¢„è®¡ç®—   | âš¡ æå¿«  | ä¸­ç­‰   |
| **Cross-Encoder** | Query å’Œ Doc è”åˆç¼–ç ï¼Œä¸å¯é¢„è®¡ç®— | ğŸ¢ è¾ƒæ…¢  | **é«˜** |

> [!TIP]
>
> **ä¸¤é˜¶æ®µæ£€ç´¢çš„æœ¬è´¨**ï¼šç”¨ Bi-Encoder (å‘é‡æ£€ç´¢) å¿«é€Ÿå¬å›å€™é€‰ï¼Œç”¨ Cross-Encoder ç²¾ç»†æ’åºã€‚

#### 2.4.1 æ¨è Reranker æ¨¡å‹

| æ¨¡å‹                       | å‚æ•°é‡ | è¯­è¨€æ”¯æŒ | æ¨ç†é€Ÿåº¦ | æ¨èåœºæ™¯     |
| :------------------------- | :----- | :------- | :------- | :----------- |
| `BAAI/bge-reranker-base`   | 278M   | ä¸­è‹±     | ä¸­ç­‰     | **æ¨èé¦–é€‰** |
| `BAAI/bge-reranker-v2-m3`  | 568M   | å¤šè¯­è¨€   | è¾ƒæ…¢     | å¤šè¯­è¨€åœºæ™¯   |
| `cross-encoder/ms-marco-*` | 66M    | è‹±æ–‡     | å¿«       | è‹±æ–‡ä¸“ç”¨     |
| `jinaai/jina-reranker-v2`  | 137M   | å¤šè¯­è¨€   | ä¸­ç­‰     | API å‹å¥½     |

### 2.5 è°ƒç ”äº¤ä»˜ç‰©æ‘˜è¦

> [!NOTE]
>
> æœ¬èŠ‚å¯¹åº”ä»»åŠ¡ **P3-1-6** (ç†è§£ RRF ç®—æ³•åŸç†) çš„è°ƒç ”äº¤ä»˜ç‰©ã€‚

#### 2.5.1 æ£€ç´¢ç­–ç•¥å¯¹æ¯”è¡¨

| è¯„ä¼°ç»´åº¦       | çº¯å‘é‡æ£€ç´¢ | çº¯å…³é”®è¯æ£€ç´¢ | æ··åˆæ£€ç´¢ (RRF) |
| :------------- | :--------- | :----------- | :------------- |
| **è¯­ä¹‰ç†è§£**   | â­â­â­     | â­           | â­â­â­         |
| **ç²¾ç¡®åŒ¹é…**   | â­         | â­â­â­       | â­â­â­         |
| **å®ç°å¤æ‚åº¦** | â­         | â­           | â­â­           |
| **å¬å›ç‡**     | ä¸­ç­‰       | ä¸­ç­‰         | **é«˜**         |
| **é€‚ç”¨åœºæ™¯**   | æ¦‚å¿µæœç´¢   | æœ¯è¯­æœç´¢     | **é€šç”¨ RAG**   |

#### 2.5.2 PostgreSQL vs ä¸“ç”¨å‘é‡åº“å¯¹æ¯”

| ç»´åº¦           | PostgreSQL + PGVector | Milvus / Weaviate |
| :------------- | :-------------------- | :---------------- |
| **æ··åˆæ£€ç´¢**   | âœ… One-Shot SQL       | âš ï¸ éœ€åº”ç”¨å±‚æ‹¼æ¥   |
| **äº‹åŠ¡æ”¯æŒ**   | âœ… å®Œæ•´ ACID          | âŒ æœ‰é™           |
| **å…ƒæ•°æ®è¿‡æ»¤** | âœ… åŸç”Ÿ SQL           | âš ï¸ ä¸“ç”¨ DSL       |
| **è¿ç»´å¤æ‚åº¦** | â­ (å·²æœ‰ PG)          | â­â­â­ (æ–°å¢ç»„ä»¶) |
| **æç«¯è§„æ¨¡**   | äº¿çº§éœ€è°ƒä¼˜            | è®¾è®¡ç›®æ ‡å³ä¸ºäº¿çº§  |

---

## 3. æ¶æ„è®¾è®¡ï¼šPerception Schema

### 3.1 ä¸ Phase 2 çš„æ¶æ„å…³è”

> [!NOTE]
>
> **Zero-ETL ç­–ç•¥å»¶ç»­**ï¼šThe Perception å®Œå…¨å¤ç”¨ Phase 2 (Hippocampus) å·²å»ºç«‹çš„ `memories` å’Œ `facts` è¡¨ï¼Œæ— éœ€æ–°å¢æ ¸å¿ƒè¡¨ï¼Œä»…éœ€æ·»åŠ å…¨æ–‡æœç´¢æ”¯æŒã€‚è¿™æ˜¯ "Just use PostgreSQL" ç­–ç•¥çš„æ ¸å¿ƒä½“ç°ã€‚

#### 3.1.1 Perception ER å›¾

```mermaid
erDiagram
    threads ||--o{ sessions : "has"
    sessions ||--o{ memories : "contains"
    memories ||--o{ facts : "extracts"

    memories {
        uuid id PK "ä¸»é”®"
        varchar user_id FK "ç”¨æˆ·æ ‡è¯†"
        varchar app_name FK "åº”ç”¨æ ‡è¯†"
        text content "è®°å¿†å†…å®¹"
        vector embedding "å‘é‡åµŒå…¥ (1536D)"
        tsvector search_vector "å…¨æ–‡æœç´¢å‘é‡ (NEW)"
        jsonb metadata "å…ƒæ•°æ®"
        float retention_score "è®°å¿†ä¿ç•™åˆ†æ•°"
        timestamp created_at "åˆ›å»ºæ—¶é—´"
    }

    facts {
        uuid id PK "ä¸»é”®"
        uuid memory_id FK "å…³è”è®°å¿†"
        text fact_content "æå–çš„äº‹å®"
        vector embedding "å‘é‡åµŒå…¥"
        tsvector search_vector "å…¨æ–‡æœç´¢å‘é‡ (NEW)"
    }
```

**å…³é”®è¯´æ˜**ï¼š

| åˆ—              | æ¥æº    | ç”¨é€”                       | ç´¢å¼•ç±»å‹    |
| :-------------- | :------ | :------------------------- | :---------- |
| `embedding`     | Phase 2 | Semantic Search (å‘é‡æ£€ç´¢) | HNSW        |
| `search_vector` | **NEW** | Keyword Search (BM25 å…¨æ–‡) | GIN         |
| `metadata`      | Phase 2 | Structural Filter (å…ƒæ•°æ®) | BTREE / GIN |

### 3.2 Schema æ‰©å±•ï¼šå…¨æ–‡æœç´¢

#### 3.2.1 æ–°å¢ tsvector åˆ—

```sql
-- åœ¨ memories è¡¨æ·»åŠ å…¨æ–‡æœç´¢å‘é‡åˆ—
ALTER TABLE memories ADD COLUMN IF NOT EXISTS
    search_vector tsvector;

-- åˆ›å»ºè§¦å‘å™¨è‡ªåŠ¨æ›´æ–° search_vector
CREATE OR REPLACE FUNCTION memories_search_vector_trigger()
RETURNS trigger AS $$
BEGIN
    NEW.search_vector := to_tsvector('english', COALESCE(NEW.content, ''));
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER trigger_memories_search_vector
    BEFORE INSERT OR UPDATE ON memories
    FOR EACH ROW
    EXECUTE FUNCTION memories_search_vector_trigger();

-- åˆ›å»º GIN ç´¢å¼•åŠ é€Ÿå…¨æ–‡æœç´¢
CREATE INDEX IF NOT EXISTS idx_memories_search_vector
    ON memories USING GIN (search_vector);
```

### 3.3 JSONB Complex Predicates è®¾è®¡

> [!IMPORTANT]
>
> **å¯¹æ ‡ Roadmap Pillar III**: Complex Predicates æ”¯æŒåŸºäº JSONB çš„ä»»æ„æ·±åº¦çš„å¸ƒå°”é€»è¾‘è¿‡æ»¤ï¼Œæ˜¯ The Perception åŒºåˆ«äºç®€å•å‘é‡æ£€ç´¢çš„æ ¸å¿ƒèƒ½åŠ›ã€‚

#### 3.3.1 JSONB è¿‡æ»¤è¯­æ³•å‚è€ƒ

| åœºæ™¯             | SQL è¯­æ³•                                      | è¯´æ˜                     |
| :--------------- | :-------------------------------------------- | :----------------------- | ------------ |
| **ç®€å•é”®å€¼åŒ¹é…** | `metadata @> '{"type": "note"}'`              | åŒ…å«æŒ‡å®šé”®å€¼å¯¹           |
| **åµŒå¥—å¯¹è±¡åŒ¹é…** | `metadata @> '{"author": {"role": "admin"}}'` | ä»»æ„æ·±åº¦åµŒå¥—             |
| **æ•°ç»„å…ƒç´ åŒ…å«** | `metadata @> '{"tags": ["important"]}'`       | æ•°ç»„åŒ…å«æŒ‡å®šå…ƒç´          |
| **è·¯å¾„å–å€¼æ¯”è¾ƒ** | `metadata->'author'->>'role' = 'admin'`       | æå–è·¯å¾„å€¼è¿›è¡Œæ¯”è¾ƒ       |
| **æ•°å€¼èŒƒå›´è¿‡æ»¤** | `(metadata->>'priority')::int > 5`            | ç±»å‹è½¬æ¢åæ•°å€¼æ¯”è¾ƒ       |
| **å­˜åœ¨æ€§æ£€æŸ¥**   | `metadata ? 'urgent'`                         | æ£€æŸ¥ key æ˜¯å¦å­˜åœ¨        |
| **å¤šé”®å­˜åœ¨æ£€æŸ¥** | `metadata ?& array['type', 'status']`         | åŒæ—¶å­˜åœ¨å¤šä¸ª key         |
| **ä»»ä¸€é”®å­˜åœ¨**   | `metadata ?                                   | array['vip', 'premium']` | å­˜åœ¨ä»»ä¸€ key |

#### 3.3.2 ä¸»æµä¸šåŠ¡åœºæ™¯ç¤ºä¾‹

> [!NOTE]
>
> ä»¥ä¸‹ä¸šåŠ¡åœºæ™¯ç»è¿‡æ­£äº¤åˆ†æï¼Œè¦†ç›– RAG ç³»ç»Ÿçš„ä¸»æµè¿‡æ»¤éœ€æ±‚ç»´åº¦ã€‚

##### åœºæ™¯ 1ï¼šå¤šç§Ÿæˆ·éš”ç¦» (Multi-Tenant Isolation)

```sql
-- ä¸šåŠ¡éœ€æ±‚ï¼šSaaS å¹³å°ä¸­æ¯ä¸ªç§Ÿæˆ·åªèƒ½æ£€ç´¢è‡ªå·±çš„çŸ¥è¯†åº“
-- è¿‡æ»¤æ¡ä»¶ï¼štenant_id (å¼ºè¿‡æ»¤ï¼Œé«˜é€‰æ‹©æ€§)
SELECT id, content, embedding <=> $query_embedding AS distance
FROM memories
WHERE
    metadata @> '{"tenant_id": "org_acme_corp"}'
    AND user_id = $user_id
ORDER BY embedding <=> $query_embedding
LIMIT 10;

-- ä¼˜åŒ–ï¼šä¸ºé«˜é¢‘ç§Ÿæˆ·åˆ›å»ºéƒ¨åˆ†ç´¢å¼•
CREATE INDEX idx_memories_tenant_acme
    ON memories USING hnsw (embedding vector_cosine_ops)
    WHERE metadata @> '{"tenant_id": "org_acme_corp"}';
```

##### åœºæ™¯ 2ï¼šæƒé™æ§åˆ¶ (Access Control)

```sql
-- ä¸šåŠ¡éœ€æ±‚ï¼šæ ¹æ®ç”¨æˆ·è§’è‰²è¿‡æ»¤å¯è®¿é—®çš„çŸ¥è¯†
-- è¿‡æ»¤æ¡ä»¶ï¼šaccess_level, department (ç»„åˆæ¡ä»¶)
SELECT id, content, embedding <=> $query_embedding AS distance
FROM memories
WHERE
    -- è®¿é—®çº§åˆ«æ£€æŸ¥ï¼šç”¨æˆ·çº§åˆ« >= æ–‡æ¡£çº§åˆ«
    (metadata->>'access_level')::int <= $user_access_level
    -- éƒ¨é—¨å½’å±æ£€æŸ¥ï¼šç”¨æˆ·æ‰€å±éƒ¨é—¨æˆ–å…¬å¼€æ–‡æ¡£
    AND (
        metadata @> '{"visibility": "public"}'
        OR metadata->'departments' @> $user_department::jsonb
    )
ORDER BY embedding <=> $query_embedding
LIMIT 10;
```

##### åœºæ™¯ 3ï¼šæ—¶é—´èŒƒå›´è¿‡æ»¤ (Time-Based Filtering)

```sql
-- ä¸šåŠ¡éœ€æ±‚ï¼šåªæ£€ç´¢ç‰¹å®šæ—¶é—´æ®µå†…çš„è®°å¿†
-- è¿‡æ»¤æ¡ä»¶ï¼šcreated_at, updated_at (èŒƒå›´è¿‡æ»¤)
SELECT id, content, embedding <=> $query_embedding AS distance
FROM memories
WHERE
    -- æ—¶é—´èŒƒå›´è¿‡æ»¤
    created_at >= $start_time AND created_at <= $end_time
    -- å¯é€‰ï¼šåªè¦æœ€è¿‘æ›´æ–°çš„
    AND (updated_at IS NULL OR updated_at >= NOW() - INTERVAL '7 days')
    -- å…ƒæ•°æ®æ—¶é—´æˆ³è¿‡æ»¤ï¼ˆå­˜å‚¨åœ¨ JSONB ä¸­çš„ä¸šåŠ¡æ—¶é—´ï¼‰
    AND (metadata->>'event_time')::timestamp >= $event_start
ORDER BY embedding <=> $query_embedding
LIMIT 10;

-- ä¼˜åŒ–ï¼šåˆ›å»ºå¤åˆç´¢å¼•è¦†ç›–æ—¶é—´èŒƒå›´æŸ¥è¯¢
CREATE INDEX idx_memories_created_at_embedding
    ON memories (created_at DESC, user_id);
```

##### åœºæ™¯ 4ï¼šæ ‡ç­¾ç³»ç»Ÿ (Tag-Based Filtering)

```sql
-- ä¸šåŠ¡éœ€æ±‚ï¼šæ ¹æ®æ ‡ç­¾ç»„åˆè¿‡æ»¤çŸ¥è¯†
-- è¿‡æ»¤æ¡ä»¶ï¼štags æ•°ç»„ (åŒ…å«/æ’é™¤é€»è¾‘)
SELECT id, content, embedding <=> $query_embedding AS distance
FROM memories
WHERE
    -- å¿…é¡»åŒ…å«æ‰€æœ‰æŒ‡å®šæ ‡ç­¾ (AND è¯­ä¹‰)
    metadata @> '{"tags": ["machine-learning", "research"]}'
    -- æ’é™¤ç‰¹å®šæ ‡ç­¾
    AND NOT metadata @> '{"tags": ["deprecated"]}'
    -- å¯é€‰ï¼šåŒ…å«ä»»ä¸€æ ‡ç­¾ (OR è¯­ä¹‰ï¼Œéœ€åº”ç”¨å±‚å¤„ç†)
ORDER BY embedding <=> $query_embedding
LIMIT 10;

-- ä¼˜åŒ–ï¼šGIN ç´¢å¼•æ”¯æŒæ•°ç»„åŒ…å«æŸ¥è¯¢
CREATE INDEX idx_memories_tags
    ON memories USING GIN ((metadata->'tags'));
```

##### åœºæ™¯ 5ï¼šå¤åˆæ¡ä»¶ä¸ä¼˜å…ˆçº§ (Complex Business Logic)

```sql
-- ä¸šåŠ¡éœ€æ±‚ï¼šä¼ä¸šçŸ¥è¯†åº“çš„å¤æ‚æ£€ç´¢æ¡ä»¶
-- è¿‡æ»¤æ¡ä»¶ï¼šå¤šç»´åº¦ç»„åˆ (è§’è‰² + çŠ¶æ€ + ç±»å‹ + ä¼˜å…ˆçº§)
SELECT id, content, embedding <=> $query_embedding AS distance
FROM memories
WHERE
    -- æ–‡æ¡£ç±»å‹
    metadata @> '{"doc_type": "policy"}'
    -- çŠ¶æ€ï¼šå·²å‘å¸ƒ
    AND metadata @> '{"status": "published"}'
    -- åˆ›å»ºè€…è§’è‰²ï¼šç®¡ç†å‘˜æˆ–ä¸“å®¶
    AND (
        metadata @> '{"author": {"role": "admin"}}'
        OR metadata @> '{"author": {"role": "expert"}}'
    )
    -- ä¼˜å…ˆçº§ >= é«˜
    AND (metadata->>'priority')::int >= 3
    -- æœªè¿‡æœŸ
    AND (
        metadata->>'expires_at' IS NULL
        OR (metadata->>'expires_at')::timestamp > NOW()
    )
ORDER BY embedding <=> $query_embedding
LIMIT 10;
```

#### 3.3.3 JSONB ç´¢å¼•ç­–ç•¥

```sql
-- 1. GIN ç´¢å¼•ï¼šæ”¯æŒ @>ã€?ã€?&ã€?| æ“ä½œç¬¦
CREATE INDEX idx_memories_metadata_gin
    ON memories USING GIN (metadata);

-- 2. è¡¨è¾¾å¼ç´¢å¼•ï¼šé’ˆå¯¹é«˜é¢‘æŸ¥è¯¢è·¯å¾„
-- åœºæ™¯ï¼šé¢‘ç¹æŒ‰ author.role è¿‡æ»¤
CREATE INDEX idx_memories_author_role
    ON memories ((metadata->'author'->>'role'));

-- 3. éƒ¨åˆ†ç´¢å¼•ï¼šé’ˆå¯¹ç‰¹å®šä¸šåŠ¡åœºæ™¯
-- åœºæ™¯ï¼šä»…ç´¢å¼• admin ç”¨æˆ·çš„è®°å¿†ï¼ˆå‡å°‘ç´¢å¼•å¤§å°ï¼‰
CREATE INDEX idx_memories_admin_only
    ON memories USING hnsw (embedding vector_cosine_ops)
    WHERE metadata @> '{"author": {"role": "admin"}}';
```

### 3.4 ç´¢å¼•ç­–ç•¥è®¾è®¡

> [!IMPORTANT]
>
> **ä¸‰é‡ç´¢å¼•ç­–ç•¥**ï¼šä¸ºæ”¯æŒ One-Shot Hybrid Searchï¼Œéœ€è¦åŒæ—¶ç»´æŠ¤ä¸‰ç±»ç´¢å¼•ã€‚

| ç´¢å¼•ç±»å‹     | ç›®æ ‡åˆ—                | ç´¢å¼•ç®—æ³• | ç”¨é€”            |
| :----------- | :-------------------- | :------- | :-------------- |
| **å‘é‡ç´¢å¼•** | `embedding`           | HNSW     | è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢  |
| **å…¨æ–‡ç´¢å¼•** | `search_vector`       | GIN      | BM25 å…³é”®è¯æ£€ç´¢ |
| **æ ‡é‡ç´¢å¼•** | `user_id`, etc.       | BTREE    | å…ƒæ•°æ®è¿‡æ»¤      |
| **å¤åˆç´¢å¼•** | `(user_id, app_name)` | BTREE    | é«˜é¢‘è¿‡æ»¤åœºæ™¯    |

### 3.3 æ ¸å¿ƒ SQL å‡½æ•°è®¾è®¡

#### 3.3.1 One-Shot Hybrid Search å‡½æ•°

```sql
-- æ ¸å¿ƒå‡½æ•°ï¼šOne-Shot æ··åˆæ£€ç´¢
CREATE OR REPLACE FUNCTION hybrid_search(
    p_user_id VARCHAR(255),
    p_app_name VARCHAR(255),
    p_query TEXT,
    p_query_embedding vector(1536),
    p_limit INTEGER DEFAULT 50,
    p_semantic_weight FLOAT DEFAULT 0.7,
    p_keyword_weight FLOAT DEFAULT 0.3,
    p_metadata_filter JSONB DEFAULT NULL
)
RETURNS TABLE (
    id UUID,
    content TEXT,
    semantic_score FLOAT,
    keyword_score FLOAT,
    combined_score FLOAT,
    metadata JSONB
) AS $$
BEGIN
    RETURN QUERY
    WITH
    -- 1. è¯­ä¹‰æ£€ç´¢ (å‘é‡)
    semantic_results AS (
        SELECT
            m.id,
            m.content,
            1 - (m.embedding <=> p_query_embedding) AS score,
            m.metadata
        FROM memories m
        WHERE m.user_id = p_user_id
          AND m.app_name = p_app_name
          AND (p_metadata_filter IS NULL OR m.metadata @> p_metadata_filter)
        ORDER BY m.embedding <=> p_query_embedding
        LIMIT p_limit * 2  -- å¬å› 2 å€ç”¨äºèåˆ
    ),
    -- 2. å…³é”®è¯æ£€ç´¢ (BM25)
    keyword_results AS (
        SELECT
            m.id,
            m.content,
            ts_rank_cd(m.search_vector, plainto_tsquery('english', p_query)) AS score,
            m.metadata
        FROM memories m
        WHERE m.user_id = p_user_id
          AND m.app_name = p_app_name
          AND m.search_vector @@ plainto_tsquery('english', p_query)
          AND (p_metadata_filter IS NULL OR m.metadata @> p_metadata_filter)
        ORDER BY score DESC
        LIMIT p_limit * 2
    ),
    -- 3. åˆå¹¶å»é‡
    combined AS (
        SELECT
            COALESCE(s.id, k.id) AS id,
            COALESCE(s.content, k.content) AS content,
            COALESCE(s.score, 0) AS semantic_score,
            COALESCE(k.score, 0) AS keyword_score,
            COALESCE(s.metadata, k.metadata) AS metadata
        FROM semantic_results s
        FULL OUTER JOIN keyword_results k ON s.id = k.id
    )
    -- 4. åŠ æƒèåˆæ’åº
    SELECT
        c.id,
        c.content,
        c.semantic_score,
        c.keyword_score,
        (c.semantic_score * p_semantic_weight + c.keyword_score * p_keyword_weight) AS combined_score,
        c.metadata
    FROM combined c
    ORDER BY combined_score DESC
    LIMIT p_limit;
END;
$$ LANGUAGE plpgsql;
```

#### 3.3.2 RRF èåˆå‡½æ•°

```sql
-- RRF (Reciprocal Rank Fusion) èåˆå‡½æ•°
CREATE OR REPLACE FUNCTION rrf_search(
    p_user_id VARCHAR(255),
    p_app_name VARCHAR(255),
    p_query TEXT,
    p_query_embedding vector(1536),
    p_limit INTEGER DEFAULT 50,
    p_k INTEGER DEFAULT 60  -- RRF å¹³æ»‘å¸¸æ•°
)
RETURNS TABLE (
    id UUID,
    content TEXT,
    rrf_score FLOAT,
    semantic_rank INTEGER,
    keyword_rank INTEGER,
    metadata JSONB
) AS $$
BEGIN
    RETURN QUERY
    WITH
    -- 1. è¯­ä¹‰æ£€ç´¢ + æ’å
    semantic_ranked AS (
        SELECT
            m.id, m.content, m.metadata,
            ROW_NUMBER() OVER (ORDER BY m.embedding <=> p_query_embedding) AS rank
        FROM memories m
        WHERE m.user_id = p_user_id AND m.app_name = p_app_name
        ORDER BY m.embedding <=> p_query_embedding
        LIMIT p_limit * 3
    ),
    -- 2. å…³é”®è¯æ£€ç´¢ + æ’å
    keyword_ranked AS (
        SELECT
            m.id, m.content, m.metadata,
            ROW_NUMBER() OVER (
                ORDER BY ts_rank_cd(m.search_vector, plainto_tsquery('english', p_query)) DESC
            ) AS rank
        FROM memories m
        WHERE m.user_id = p_user_id
          AND m.app_name = p_app_name
          AND m.search_vector @@ plainto_tsquery('english', p_query)
        ORDER BY ts_rank_cd(m.search_vector, plainto_tsquery('english', p_query)) DESC
        LIMIT p_limit * 3
    ),
    -- 3. RRF èåˆ
    rrf_combined AS (
        SELECT
            COALESCE(s.id, k.id) AS id,
            COALESCE(s.content, k.content) AS content,
            COALESCE(s.metadata, k.metadata) AS metadata,
            s.rank AS semantic_rank,
            k.rank AS keyword_rank,
            -- RRF å…¬å¼: sum(1 / (k + rank))
            COALESCE(1.0 / (p_k + s.rank), 0) +
            COALESCE(1.0 / (p_k + k.rank), 0) AS rrf_score
        FROM semantic_ranked s
        FULL OUTER JOIN keyword_ranked k ON s.id = k.id
    )
    -- 4. æŒ‰ RRF åˆ†æ•°æ’åº
    SELECT
        c.id,
        c.content,
        c.rrf_score,
        c.semantic_rank::INTEGER,
        c.keyword_rank::INTEGER,
        c.metadata
    FROM rrf_combined c
    ORDER BY c.rrf_score DESC
    LIMIT p_limit;
END;
$$ LANGUAGE plpgsql;
```

---

## 4. å®æ–½è®¡åˆ’ï¼šåˆ†æ­¥æ‰§è¡ŒæŒ‡å—

### 4.1 Step 1: Fusion Retrieval å®ç°

#### 4.1.1 Schema æ‰©å±•éƒ¨ç½²

**ä»»åŠ¡æ¸…å•**ï¼š

| ä»»åŠ¡ ID | ä»»åŠ¡æè¿°                  | éªŒæ”¶æ ‡å‡†                              |
| :------ | :------------------------ | :------------------------------------ |
| P3-1-1  | æ·»åŠ  `search_vector` åˆ—   | `ALTER TABLE` æˆåŠŸ                    |
| P3-1-2  | åˆ›å»º GIN å…¨æ–‡ç´¢å¼•         | ç´¢å¼•åˆ›å»ºæˆåŠŸ                          |
| P3-1-3  | ç¼–å†™ Semantic Search SQL  | `embedding <=> query` è¯­æ³•æ­£ç¡®        |
| P3-1-4  | ç¼–å†™ Keyword Search SQL   | `to_tsvector @@ plainto_tsquery` æ­£ç¡® |
| P3-1-5  | ç¼–å†™ One-Shot Hybrid å‡½æ•° | `hybrid_search()` å‡½æ•°åˆ›å»ºæˆåŠŸ        |

**Schema æ‰©å±•è„šæœ¬** (`docs/practice/schema/perception_schema.sql`)ï¼š

```sql
-- ============================================
-- Agentic AI Engine - Perception Schema Extension
-- Version: 1.0
-- Target: PostgreSQL 16+ with pgvector
-- Prerequisite: Phase 2 hippocampus_schema.sql å·²éƒ¨ç½²
-- ============================================

-- 1. æ·»åŠ å…¨æ–‡æœç´¢åˆ—
ALTER TABLE memories ADD COLUMN IF NOT EXISTS
    search_vector tsvector;

-- 2. åˆ›å»ºè§¦å‘å™¨è‡ªåŠ¨æ›´æ–° search_vector
CREATE OR REPLACE FUNCTION memories_search_vector_trigger()
RETURNS trigger AS $$
BEGIN
    NEW.search_vector := to_tsvector('english', COALESCE(NEW.content, ''));
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

DROP TRIGGER IF EXISTS trigger_memories_search_vector ON memories;
CREATE TRIGGER trigger_memories_search_vector
    BEFORE INSERT OR UPDATE ON memories
    FOR EACH ROW
    EXECUTE FUNCTION memories_search_vector_trigger();

-- 3. å›å¡«å·²æœ‰æ•°æ®çš„ search_vector
UPDATE memories SET search_vector = to_tsvector('english', content)
WHERE search_vector IS NULL;

-- 4. åˆ›å»º GIN å…¨æ–‡ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_memories_search_vector
    ON memories USING GIN (search_vector);

-- 5. åˆ›å»ºå¤åˆç´¢å¼• (é«˜é¢‘è¿‡æ»¤åœºæ™¯)
CREATE INDEX IF NOT EXISTS idx_memories_user_app_created
    ON memories(user_id, app_name, created_at DESC);

-- 6. éªŒè¯ç´¢å¼•
SELECT indexname, indexdef
FROM pg_indexes
WHERE tablename = 'memories';
```

#### 4.1.2 RRF èåˆç®—æ³• (Reciprocal Rank Fusion)

**ä»»åŠ¡æ¸…å•**ï¼š

| ä»»åŠ¡ ID | ä»»åŠ¡æè¿°                    | éªŒæ”¶æ ‡å‡†            |
| :------ | :-------------------------- | :------------------ |
| P3-1-6  | ç†è§£ RRF ç®—æ³•åŸç†           | ç®—æ³•ç¬”è®°            |
| P3-1-7  | å®ç° SQL å†… RRF è®¡ç®—        | `rrf_search()` å‡½æ•° |
| P3-1-8  | å®ç°åº”ç”¨å±‚ RRF (Python)     | Python å‡½æ•°å®ç°     |
| P3-1-9  | å¯¹æ¯” SQL vs åº”ç”¨å±‚ RRF æ€§èƒ½ | æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š        |

**Python RRF å®ç°** (`docs/practice/engine/perception/rrf_fusion.py`)ï¼š

```python
"""
RRF (Reciprocal Rank Fusion) å®ç°

èåˆå¤šè·¯æ£€ç´¢ç»“æœï¼Œä½¿ç”¨å€’æ•°æ’åå…¬å¼åˆå¹¶æ’åºã€‚
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Any


@dataclass
class SearchResult:
    """å•æ¡æ£€ç´¢ç»“æœ"""
    id: str
    content: str
    score: float
    metadata: dict[str, Any] | None = None
    rank: int = 0


def rrf_fusion(
    result_lists: list[list[SearchResult]],
    k: int = 60,
    limit: int = 50
) -> list[SearchResult]:
    """
    Reciprocal Rank Fusion ç®—æ³•

    å…¬å¼: RRF(d) = Î£ (1 / (k + rank(d)))

    Args:
        result_lists: å¤šä¸ªæ£€ç´¢å™¨çš„ç»“æœåˆ—è¡¨
        k: å¹³æ»‘å¸¸æ•° (æ ‡å‡†å€¼ 60)
        limit: è¿”å›ç»“æœæ•°é‡

    Returns:
        èåˆåçš„æ’åºç»“æœ
    """
    # 1. ä¸ºæ¯ä¸ªåˆ—è¡¨åˆ†é…æ’å
    for results in result_lists:
        for rank, result in enumerate(results, start=1):
            result.rank = rank

    # 2. æŒ‰ ID èšåˆè®¡ç®— RRF åˆ†æ•°
    rrf_scores: dict[str, tuple[float, SearchResult]] = {}

    for results in result_lists:
        for result in results:
            if result.id not in rrf_scores:
                rrf_scores[result.id] = (0.0, result)

            current_score, current_result = rrf_scores[result.id]
            # RRF å…¬å¼: 1 / (k + rank)
            new_score = current_score + 1.0 / (k + result.rank)
            rrf_scores[result.id] = (new_score, current_result)

    # 3. æŒ‰ RRF åˆ†æ•°æ’åº
    sorted_results = sorted(
        rrf_scores.values(),
        key=lambda x: x[0],
        reverse=True
    )

    # 4. è¿”å› Top-K ç»“æœ
    return [
        SearchResult(
            id=result.id,
            content=result.content,
            score=score,
            metadata=result.metadata
        )
        for score, result in sorted_results[:limit]
    ]


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æ¨¡æ‹Ÿä¸¤è·¯æ£€ç´¢ç»“æœ
    semantic_results = [
        SearchResult(id="doc1", content="Python programming", score=0.95),
        SearchResult(id="doc2", content="Machine learning", score=0.90),
        SearchResult(id="doc3", content="Data science", score=0.85),
    ]

    keyword_results = [
        SearchResult(id="doc2", content="Machine learning", score=0.88),
        SearchResult(id="doc4", content="Deep learning", score=0.85),
        SearchResult(id="doc1", content="Python programming", score=0.80),
    ]

    fused = rrf_fusion([semantic_results, keyword_results], k=60, limit=10)

    for result in fused:
        print(f"ID: {result.id}, RRF Score: {result.score:.4f}")
```

### 4.2 Step 2: High-Selectivity Filtering

#### 4.2.1 è¿­ä»£æ‰«æé…ç½®

**ä»»åŠ¡æ¸…å•**ï¼š

| ä»»åŠ¡ ID | ä»»åŠ¡æè¿°                           | éªŒæ”¶æ ‡å‡†                              |
| :------ | :--------------------------------- | :------------------------------------ |
| P3-2-1  | æ„é€  99% è¿‡æ»¤æ¯”æµ‹è¯•æ•°æ®é›†          | 100 ä¸‡å‘é‡ï¼Œä»… 1% ç¬¦åˆè¿‡æ»¤æ¡ä»¶        |
| P3-2-2  | æµ‹è¯• HNSW `ef_search` å¯¹å¬å›ç‡å½±å“ | ä¸åŒ ef_search ä¸‹çš„ Recall@10         |
| P3-2-3  | éªŒè¯ HNSW è¿­ä»£æ‰«æ (v0.8.0+)       | `hnsw.iterative_scan = relaxed_order` |
| P3-2-4  | è®°å½• QPS ä¸ Recall åŸºå‡†æ•°æ®        | åŸºå‡†æ€§èƒ½æŠ¥å‘Š                          |

**è¿­ä»£æ‰«æé…ç½®è„šæœ¬**ï¼š

```sql
-- ============================================
-- High-Selectivity Filtering é…ç½®
-- ============================================

-- 1. å¼€å¯è¿­ä»£æ‰«æ (PGVector 0.8.0+)
SET hnsw.iterative_scan = relaxed_order;

-- 2. è®¾ç½®æœ€å¤§æ‰«æå…ƒç»„æ•° (é˜²æ­¢æ— é™æ‰«æ)
SET hnsw.max_scan_tuples = 20000;

-- 3. å¢å¤§ ef_search æé«˜å¬å›ç‡
SET hnsw.ef_search = 200;

-- 4. æµ‹è¯•æŸ¥è¯¢ (99% è¿‡æ»¤æ¯”åœºæ™¯)
EXPLAIN (ANALYZE, BUFFERS)
SELECT id, content, embedding <=> $query_embedding AS distance
FROM memories
WHERE user_id = 'rare_user_001'  -- ä»… 1% æ•°æ®
ORDER BY embedding <=> $query_embedding
LIMIT 10;

-- 5. éªŒè¯å¬å›ç»“æœæ•°é‡
SELECT COUNT(*) FROM (
    SELECT id
    FROM memories
    WHERE user_id = 'rare_user_001'
    ORDER BY embedding <=> $query_embedding
    LIMIT 10
) AS results;
-- é¢„æœŸ: åº”è¿”å› 10 æ¡ç»“æœ (è¿­ä»£æ‰«æç”Ÿæ•ˆ)
```

**æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬** (`docs/practice/engine/perception/benchmark.py`)ï¼š

```python
"""
High-Selectivity Filtering æ€§èƒ½åŸºå‡†æµ‹è¯•

æµ‹è¯•ä¸åŒ ef_search å‚æ•°ä¸‹çš„ QPS å’Œ Recall@Kã€‚
"""

import asyncio
import time
from dataclasses import dataclass

import asyncpg
import numpy as np


@dataclass
class BenchmarkResult:
    """åŸºå‡†æµ‹è¯•ç»“æœ"""
    ef_search: int
    qps: float
    recall_at_10: float
    p99_latency_ms: float


async def run_benchmark(
    pool: asyncpg.Pool,
    query_embedding: list[float],
    user_id: str,
    ef_search_values: list[int],
    iterations: int = 100
) -> list[BenchmarkResult]:
    """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
    results = []

    for ef_search in ef_search_values:
        # è®¾ç½® ef_search
        await pool.execute(f"SET hnsw.ef_search = {ef_search}")
        await pool.execute("SET hnsw.iterative_scan = relaxed_order")

        latencies = []
        recall_count = 0

        for _ in range(iterations):
            start = time.perf_counter()

            rows = await pool.fetch("""
                SELECT id, content
                FROM memories
                WHERE user_id = $1
                ORDER BY embedding <=> $2
                LIMIT 10
            """, user_id, query_embedding)

            latency = (time.perf_counter() - start) * 1000
            latencies.append(latency)
            recall_count += len(rows)

        results.append(BenchmarkResult(
            ef_search=ef_search,
            qps=iterations / (sum(latencies) / 1000),
            recall_at_10=recall_count / (iterations * 10),
            p99_latency_ms=np.percentile(latencies, 99)
        ))

    return results


# ä½¿ç”¨ç¤ºä¾‹
async def main():
    pool = await asyncpg.create_pool("postgresql://localhost/agent_db")

    # ç”ŸæˆéšæœºæŸ¥è¯¢å‘é‡
    query_embedding = list(np.random.randn(1536).astype(float))

    results = await run_benchmark(
        pool,
        query_embedding,
        user_id="rare_user_001",
        ef_search_values=[40, 100, 200, 400]
    )

    print("| ef_search | QPS | Recall@10 | P99 Latency |")
    print("|-----------|-----|-----------|-------------|")
    for r in results:
        print(f"| {r.ef_search} | {r.qps:.1f} | {r.recall_at_10:.2%} | {r.p99_latency_ms:.1f}ms |")

    await pool.close()


if __name__ == "__main__":
    asyncio.run(main())
```

### 4.3 Step 3: L1 Reranking å®ç°

#### 4.3.1 Reranker é›†æˆ

**ä»»åŠ¡æ¸…å•**ï¼š

| ä»»åŠ¡ ID | ä»»åŠ¡æè¿°                             | éªŒæ”¶æ ‡å‡†                   |
| :------ | :----------------------------------- | :------------------------- |
| P3-2-5  | é€‰æ‹© Reranker æ¨¡å‹ (`bge-reranker`)  | æ¨¡å‹é€‰å‹è¯´æ˜               |
| P3-2-6  | é›†æˆ Reranker æ¨ç†æœåŠ¡               | API å¯è°ƒç”¨                 |
| P3-2-7  | å®ç° Top-50 -> Rerank -> Top-10 æµç¨‹ | Pipeline ä»£ç å®ç°          |
| P3-2-8  | éªŒè¯ Precision@10 æå‡               | å¯¹æ¯”æ—  Rerank çš„ Precision |

**Reranker å®ç°** (`docs/practice/engine/perception/reranker.py`)ï¼š

```python
"""
L1 Reranker å®ç°

ä½¿ç”¨ Cross-Encoder æ¨¡å‹å¯¹ L0 ç²—æ’ç»“æœè¿›è¡Œç²¾æ’ã€‚
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Any

import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer


@dataclass
class RerankedResult:
    """é‡æ’åçš„ç»“æœ"""
    id: str
    content: str
    original_score: float
    rerank_score: float
    metadata: dict[str, Any] | None = None


class CrossEncoderReranker:
    """
    Cross-Encoder é‡æ’å™¨

    ä½¿ç”¨ BAAI/bge-reranker-base æ¨¡å‹è¿›è¡Œè¯­ä¹‰é‡æ’ã€‚
    """

    def __init__(
        self,
        model_name: str = "BAAI/bge-reranker-base",
        device: str | None = None
    ):
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)
        self.model.to(self.device)
        self.model.eval()

    def rerank(
        self,
        query: str,
        documents: list[dict[str, Any]],
        top_k: int = 10
    ) -> list[RerankedResult]:
        """
        å¯¹æ–‡æ¡£è¿›è¡Œé‡æ’åº

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            documents: å¾…é‡æ’æ–‡æ¡£åˆ—è¡¨ (éœ€åŒ…å« id, content, score)
            top_k: è¿”å› Top-K ç»“æœ

        Returns:
            é‡æ’åçš„ç»“æœåˆ—è¡¨
        """
        if not documents:
            return []

        # 1. æ„å»º Query-Document å¯¹
        pairs = [[query, doc["content"]] for doc in documents]

        # 2. Tokenize
        inputs = self.tokenizer(
            pairs,
            padding=True,
            truncation=True,
            max_length=512,
            return_tensors="pt"
        ).to(self.device)

        # 3. æ¨ç†
        with torch.no_grad():
            scores = self.model(**inputs).logits.squeeze(-1)

        # 4. å½’ä¸€åŒ–åˆ†æ•° (sigmoid)
        scores = torch.sigmoid(scores).cpu().numpy()

        # 5. æ„å»ºç»“æœ
        results = []
        for doc, rerank_score in zip(documents, scores):
            results.append(RerankedResult(
                id=doc["id"],
                content=doc["content"],
                original_score=doc.get("score", 0.0),
                rerank_score=float(rerank_score),
                metadata=doc.get("metadata")
            ))

        # 6. æŒ‰é‡æ’åˆ†æ•°æ’åº
        results.sort(key=lambda x: x.rerank_score, reverse=True)

        return results[:top_k]


class RerankerPipeline:
    """
    å®Œæ•´çš„ä¸¤é˜¶æ®µæ£€ç´¢ Pipeline

    L0 (æ•°æ®åº“ç²—æ’) -> L1 (Cross-Encoder ç²¾æ’)
    """

    def __init__(
        self,
        db_pool,  # asyncpg.Pool
        reranker: CrossEncoderReranker | None = None
    ):
        self.db_pool = db_pool
        self.reranker = reranker or CrossEncoderReranker()

    async def search(
        self,
        user_id: str,
        app_name: str,
        query: str,
        query_embedding: list[float],
        l0_limit: int = 50,
        l1_limit: int = 10
    ) -> list[RerankedResult]:
        """
        ä¸¤é˜¶æ®µæ£€ç´¢

        Args:
            user_id: ç”¨æˆ· ID
            app_name: åº”ç”¨åç§°
            query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
            query_embedding: æŸ¥è¯¢å‘é‡
            l0_limit: L0 ç²—æ’è¿”å›æ•°é‡
            l1_limit: L1 ç²¾æ’è¿”å›æ•°é‡

        Returns:
            ç²¾æ’åçš„ç»“æœåˆ—è¡¨
        """
        # L0: æ•°æ®åº“æ··åˆæ£€ç´¢
        rows = await self.db_pool.fetch("""
            SELECT id, content, combined_score, metadata
            FROM hybrid_search($1, $2, $3, $4, $5)
        """, user_id, app_name, query, query_embedding, l0_limit)

        documents = [
            {
                "id": str(row["id"]),
                "content": row["content"],
                "score": row["combined_score"],
                "metadata": row["metadata"]
            }
            for row in rows
        ]

        # L1: Cross-Encoder é‡æ’
        results = self.reranker.rerank(query, documents, top_k=l1_limit)

        return results


# ä½¿ç”¨ç¤ºä¾‹
async def main():
    import asyncpg

    # åˆå§‹åŒ–
    pool = await asyncpg.create_pool("postgresql://localhost/agent_db")
    pipeline = RerankerPipeline(pool)

    # ç”ŸæˆæŸ¥è¯¢å‘é‡ (å®é™…åº”ä½¿ç”¨ Embedding æ¨¡å‹)
    import numpy as np
    query_embedding = list(np.random.randn(1536).astype(float))

    # æ‰§è¡Œä¸¤é˜¶æ®µæ£€ç´¢
    results = await pipeline.search(
        user_id="user_001",
        app_name="demo_app",
        query="How to implement RAG with PostgreSQL?",
        query_embedding=query_embedding,
        l0_limit=50,
        l1_limit=10
    )

    # è¾“å‡ºç»“æœ
    print("Top 10 Reranked Results:")
    for i, r in enumerate(results, 1):
        print(f"{i}. [Score: {r.rerank_score:.4f}] {r.content[:100]}...")

    await pool.close()


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
```

---

## 5. éªŒæ”¶æ ‡å‡†

> [!IMPORTANT]
>
> **å¯¹æ ‡ Roadmap KPI**ï¼šä»¥ä¸‹éªŒæ”¶æ ‡å‡†ç›´æ¥å¯¹æ ‡ `000-roadmap.md` ä¸­ Pillar III çš„æ ¸å¿ƒæ ¸éªŒæŒ‡æ ‡ï¼š"Recall@10 (with Filters) - é«˜è¿‡æ»¤æ¯”ä¸‹çš„å¬å›ç‡ä¸è€—æ—¶"ã€‚

### 5.1 åŠŸèƒ½éªŒæ”¶

| éªŒæ”¶é¡¹              | éªŒæ”¶æ ‡å‡†                                        | ä»»åŠ¡ ID        | å¯¹æ ‡ Roadmap               |
| :------------------ | :---------------------------------------------- | :------------- | :------------------------- |
| **Semantic Search** | `embedding <=> query` HNSW æ£€ç´¢æ­£å¸¸             | P3-1-1         | Vector Search              |
| **Keyword Search**  | `to_tsvector @@ plainto_tsquery` BM25 æ£€ç´¢æ­£å¸¸  | P3-1-2         | RAG Corpus                 |
| **Metadata Filter** | `metadata @> '{"key": "value"}'` JSONB è¿‡æ»¤æ­£å¸¸ | P3-1-3         | Complex Predicates         |
| **One-Shot Hybrid** | `hybrid_search()` å‡½æ•°å•æ¬¡ SQL è¿”å›èåˆç»“æœ     | P3-1-4, P3-1-5 | DBMS_HYBRID_SEARCH         |
| **RRF Fusion**      | `rrf_search()` å‡½æ•°æ­£ç¡®å®ç°å€’æ•°æ’åèåˆ         | P3-1-7, P3-1-8 | Post-Retrieval Fusion      |
| **Iterative Scan**  | 99% è¿‡æ»¤æ¯”åœºæ™¯ä¸‹ä»èƒ½è¿”å›æ»¡è¶³ LIMIT çš„ç»“æœ       | P3-2-3         | High-Selectivity Filtering |
| **L1 Reranking**    | Cross-Encoder é‡æ’å Precision@10 æå‡          | P3-2-7, P3-2-8 | Post-Retrieval Reranking   |

### 5.2 æ€§èƒ½éªŒæ”¶

#### 5.2.1 KPI æŒ‡æ ‡åˆ†çº§

> [!NOTE]
>
> **Recall@10 ç›®æ ‡åˆ†æ**ï¼šåŸºäº PGVector è¿­ä»£æ‰«æç‰¹æ€§ï¼Œåˆç†çš„ Recall@10 ç›®æ ‡åº”æ ¹æ®æ•°æ®è§„æ¨¡å’Œä¸šåŠ¡éœ€æ±‚åˆ†çº§è®¾å®šã€‚

| éªŒæ”¶é¡¹                    | åŸºå‡†ç›®æ ‡ (PASS)         | ä¼˜åŒ–ç›®æ ‡ (EXCELLENT)    | æµ‹è¯•æ–¹æ³•            |
| :------------------------ | :---------------------- | :---------------------- | :------------------ |
| **L0 æ£€ç´¢å»¶è¿Ÿ**           | P99 < 100ms (10 ä¸‡çº§)   | P99 < 50ms (10 ä¸‡çº§)    | åŸºå‡†æµ‹è¯•è„šæœ¬        |
| **L0 æ£€ç´¢å»¶è¿Ÿ (10M)**     | P99 < 200ms (1000 ä¸‡çº§) | P99 < 100ms (1000 ä¸‡çº§) | å¤§è§„æ¨¡æ€§èƒ½éªŒè¯      |
| **L1 Rerank å»¶è¿Ÿ**        | P99 < 200ms (50 æ¡)     | P99 < 100ms (50 æ¡)     | Reranker æ¨ç†æµ‹è¯•   |
| **ç«¯åˆ°ç«¯å»¶è¿Ÿ**            | P99 < 500ms             | P99 < 300ms             | Pipeline ç«¯åˆ°ç«¯æµ‹è¯• |
| **Recall@10 (1% è¿‡æ»¤æ¯”)** | **>= 90%**              | **>= 95%**              | è¿­ä»£æ‰«æéªŒè¯        |
| **Precision@10 æå‡**     | >= 10%                  | >= 20%                  | A/B æµ‹è¯•å¯¹æ¯”        |

#### 5.2.2 é¢„æœŸåŸºå‡†è¡¨æ ¼

##### 10 ä¸‡å‘é‡ (å¿«é€Ÿæµ‹è¯•)

| ef_search | è¿‡æ»¤æ¯” | Recall@10 | P99 å»¶è¿Ÿ | QPS   | é…ç½®è¯´æ˜                 |
| :-------- | :----- | :-------- | :------- | :---- | :----------------------- |
| 40        | 1%     | ~60%      | ~5ms     | ~1500 | é»˜è®¤é…ç½®ï¼Œä¸æ¨èé«˜è¿‡æ»¤æ¯” |
| 100       | 1%     | ~80%      | ~10ms    | ~800  | ä¸­ç­‰é…ç½®                 |
| **200**   | **1%** | **>90%**  | ~20ms    | ~400  | **æ¨èï¼šé«˜è¿‡æ»¤æ¯”åœºæ™¯**   |
| 400       | 1%     | ~96%      | ~40ms    | ~200  | æè‡´å¬å›ï¼Œç‰ºç‰²å»¶è¿Ÿ       |

##### 1000 ä¸‡å‘é‡ (æ€§èƒ½éªŒè¯)

| ef_search | è¿‡æ»¤æ¯” | Recall@10 | P99 å»¶è¿Ÿ | QPS  | é…ç½®è¯´æ˜                     |
| :-------- | :----- | :-------- | :------- | :--- | :--------------------------- |
| 100       | 1%     | ~70%      | ~50ms    | ~150 | åŸºç¡€é…ç½®                     |
| **200**   | **1%** | **>85%**  | ~80ms    | ~100 | **æ¨èï¼šç”Ÿäº§ç¯å¢ƒ**           |
| 400       | 1%     | ~92%      | ~150ms   | ~50  | é«˜å¬å›éœ€æ±‚                   |
| 200 + IS  | 1%     | **>95%**  | ~100ms   | ~80  | iterative_scan=relaxed_order |

> [!TIP]
>
> **è°ƒä¼˜ç­–ç•¥å†³ç­–æ ‘**ï¼š
>
> 1. **è¿‡æ»¤æ¯” > 10%**ï¼šä½¿ç”¨é»˜è®¤ ef_search=40ï¼Œå‘é‡ç´¢å¼•ä¼˜å…ˆ
> 2. **è¿‡æ»¤æ¯” 1-10%**ï¼šä½¿ç”¨ ef_search=100-200
> 3. **è¿‡æ»¤æ¯” < 1%**ï¼šä½¿ç”¨ ef_search=200 + `hnsw.iterative_scan=relaxed_order`
> 4. **è¿‡æ»¤æ¯” < 0.1%**ï¼šè€ƒè™‘ä½¿ç”¨éƒ¨åˆ†ç´¢å¼• (Partial Index)

### 5.3 æµ‹è¯•æ•°æ®ç”Ÿæˆè„šæœ¬

**ä»»åŠ¡ P3-2-1 äº¤ä»˜ç‰©**ï¼šç”Ÿæˆ 99% è¿‡æ»¤æ¯”æµ‹è¯•æ•°æ®é›†ã€‚

> [!NOTE]
>
> **æ•°æ®è§„æ¨¡è¯´æ˜**ï¼š
>
> - **10 ä¸‡æ¡**ï¼šå¿«é€Ÿæµ‹è¯•ï¼ŒéªŒè¯åŠŸèƒ½æ­£ç¡®æ€§
> - **1000 ä¸‡æ¡**ï¼šæ€§èƒ½éªŒè¯ï¼ŒéªŒè¯ç”Ÿäº§è§„æ¨¡ä¸‹çš„ Recall å’Œå»¶è¿Ÿè¡¨ç°

```python
"""
æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨ (generate_test_data.py)

ç”Ÿæˆå‘é‡æ•°æ®ç”¨äºéªŒè¯ High-Selectivity Filtering åœºæ™¯çš„ Recall@10ã€‚
æ”¯æŒé…ç½®ä¸åŒæ•°æ®è§„æ¨¡ï¼š10 ä¸‡ (å¿«é€Ÿæµ‹è¯•) å’Œ 1000 ä¸‡ (æ€§èƒ½éªŒè¯)ã€‚

ç”¨æ³•:
    python generate_test_data.py --scale quick    # 10 ä¸‡æ¡
    python generate_test_data.py --scale full     # 1000 ä¸‡æ¡
"""

from __future__ import annotations

import argparse
import asyncio
import random
import time
import uuid

import asyncpg
import numpy as np

# æ•°æ®è§„æ¨¡é…ç½®
SCALE_CONFIG = {
    "quick": {
        "total_records": 100_000,
        "batch_size": 5_000,
        "description": "å¿«é€Ÿæµ‹è¯• (10 ä¸‡æ¡)"
    },
    "full": {
        "total_records": 10_000_000,
        "batch_size": 10_000,
        "description": "æ€§èƒ½éªŒè¯ (1000 ä¸‡æ¡)"
    }
}


async def generate_test_data(
    pool: asyncpg.Pool,
    total_records: int,
    batch_size: int,
    rare_user_ratio: float = 0.01,
):
    """
    ç”Ÿæˆæµ‹è¯•æ•°æ®

    Args:
        pool: æ•°æ®åº“è¿æ¥æ± 
        total_records: æ€»è®°å½•æ•°
        batch_size: æ‰¹é‡æ’å…¥å¤§å°
        rare_user_ratio: ç¨€æœ‰ç”¨æˆ·æ•°æ®å æ¯” (é»˜è®¤ 1%)
    """
    rare_user_id = "rare_user_001"
    common_users = [f"common_user_{i:04d}" for i in range(100)]

    print(f"\nğŸ“Š æ•°æ®ç”Ÿæˆå‚æ•°:")
    print(f"   - æ€»è®°å½•æ•°: {total_records:,}")
    print(f"   - ç¨€æœ‰ç”¨æˆ·: {rare_user_id} ({rare_user_ratio:.1%})")
    print(f"   - é¢„è®¡ç¨€æœ‰ç”¨æˆ·è®°å½•: {int(total_records * rare_user_ratio):,}")
    print(f"   - æ‰¹æ¬¡å¤§å°: {batch_size:,}")
    print(f"   - é¢„è®¡æ‰¹æ¬¡æ•°: {total_records // batch_size}")

    start_time = time.time()

    for batch_idx, batch_start in enumerate(range(0, total_records, batch_size)):
        batch_end = min(batch_start + batch_size, total_records)
        records = []

        for i in range(batch_start, batch_end):
            # æŒ‰æ¯”ä¾‹åˆ†é…ç”¨æˆ·
            if random.random() < rare_user_ratio:
                user_id = rare_user_id
            else:
                user_id = random.choice(common_users)

            # ç”Ÿæˆéšæœºå‘é‡ (1536 ç»´ï¼ŒåŒ¹é… OpenAI ada-002)
            embedding = np.random.randn(1536).astype(np.float32).tolist()

            # ç”Ÿæˆä¸°å¯Œçš„å…ƒæ•°æ®ç”¨äº Complex Predicates æµ‹è¯•
            metadata = {
                "index": i,
                "batch": batch_idx,
                "priority": random.randint(1, 5),
                "tags": random.sample(["research", "note", "task", "meeting", "important"], k=random.randint(1, 3)),
                "author": {"role": random.choice(["user", "admin", "expert"])},
                "status": random.choice(["draft", "published", "archived"]),
                "access_level": random.randint(1, 5),
            }

            records.append((
                str(uuid.uuid4()),
                user_id,
                "test_app",
                f"Test content for document {i}. This is sample text for semantic search testing.",
                embedding,
                metadata
            ))

        # æ‰¹é‡æ’å…¥
        await pool.executemany("""
            INSERT INTO memories (id, user_id, app_name, content, embedding, metadata)
            VALUES ($1, $2, $3, $4, $5, $6)
        """, records)

        # è¿›åº¦æ˜¾ç¤º
        progress = batch_end / total_records * 100
        elapsed = time.time() - start_time
        rate = batch_end / elapsed if elapsed > 0 else 0
        eta = (total_records - batch_end) / rate if rate > 0 else 0

        print(f"\r   â³ è¿›åº¦: {progress:5.1f}% ({batch_end:,}/{total_records:,}) "
              f"| é€Ÿç‡: {rate:,.0f}/s | ETA: {eta:.0f}s", end="", flush=True)

    elapsed = time.time() - start_time
    print(f"\n\nâœ… æ•°æ®ç”Ÿæˆå®Œæˆ! è€—æ—¶: {elapsed:.1f}s")


async def verify_data_distribution(pool: asyncpg.Pool):
    """éªŒè¯æ•°æ®åˆ†å¸ƒ"""
    print("\nğŸ“ˆ æ•°æ®åˆ†å¸ƒéªŒè¯:")

    total_count = await pool.fetchval(
        "SELECT COUNT(*) FROM memories WHERE app_name = 'test_app'"
    )
    rare_count = await pool.fetchval(
        "SELECT COUNT(*) FROM memories WHERE user_id = 'rare_user_001'"
    )

    print(f"   - æ€»è®°å½•æ•°: {total_count:,}")
    print(f"   - ç¨€æœ‰ç”¨æˆ·è®°å½•: {rare_count:,} ({rare_count/total_count:.2%})")

    # éªŒè¯å…ƒæ•°æ®åˆ†å¸ƒ
    admin_count = await pool.fetchval("""
        SELECT COUNT(*) FROM memories
        WHERE metadata @> '{"author": {"role": "admin"}}'
    """)
    print(f"   - admin è§’è‰²è®°å½•: {admin_count:,} ({admin_count/total_count:.2%})")


async def main():
    parser = argparse.ArgumentParser(description="ç”Ÿæˆ High-Selectivity æµ‹è¯•æ•°æ®")
    parser.add_argument(
        "--scale",
        choices=["quick", "full"],
        default="quick",
        help="æ•°æ®è§„æ¨¡: quick=10ä¸‡, full=1000ä¸‡"
    )
    parser.add_argument(
        "--db-url",
        default="postgresql://localhost/agent_db",
        help="æ•°æ®åº“è¿æ¥ URL"
    )
    parser.add_argument(
        "--clean",
        action="store_true",
        help="æ¸…ç†ç°æœ‰æµ‹è¯•æ•°æ®åå†ç”Ÿæˆ"
    )
    args = parser.parse_args()

    config = SCALE_CONFIG[args.scale]
    print(f"ğŸš€ {config['description']}")

    pool = await asyncpg.create_pool(args.db_url, min_size=2, max_size=10)

    if args.clean:
        print("\nğŸ—‘ï¸ æ¸…ç†ç°æœ‰æµ‹è¯•æ•°æ®...")
        await pool.execute("DELETE FROM memories WHERE app_name = 'test_app'")

    await generate_test_data(
        pool,
        total_records=config["total_records"],
        batch_size=config["batch_size"]
    )

    await verify_data_distribution(pool)

    print("\nğŸ’¡ ä¸‹ä¸€æ­¥: è¿è¡ŒåŸºå‡†æµ‹è¯•éªŒè¯ Recall@10")
    print("   python benchmark.py --user-id rare_user_001")

    await pool.close()


if __name__ == "__main__":
    asyncio.run(main())
```

### 5.4 éªŒæ”¶æµ‹è¯•è„šæœ¬

```python
"""
Phase 3 éªŒæ”¶æµ‹è¯•è„šæœ¬

éªŒè¯ The Perception çš„æ‰€æœ‰åŠŸèƒ½å’Œæ€§èƒ½æŒ‡æ ‡ã€‚
"""

import asyncio
import time

import asyncpg
import numpy as np


async def test_hybrid_search(pool: asyncpg.Pool):
    """æµ‹è¯• One-Shot Hybrid Search"""
    query = "machine learning algorithms"
    query_embedding = list(np.random.randn(1536).astype(float))

    start = time.perf_counter()
    rows = await pool.fetch("""
        SELECT * FROM hybrid_search($1, $2, $3, $4, 50)
    """, "test_user", "test_app", query, query_embedding)
    latency = (time.perf_counter() - start) * 1000

    assert len(rows) > 0, "Hybrid search should return results"
    assert latency < 100, f"L0 latency {latency:.1f}ms exceeds 100ms"
    print(f"âœ… Hybrid Search: {len(rows)} results, {latency:.1f}ms")


async def test_rrf_search(pool: asyncpg.Pool):
    """æµ‹è¯• RRF èåˆæ£€ç´¢"""
    query = "deep learning neural networks"
    query_embedding = list(np.random.randn(1536).astype(float))

    rows = await pool.fetch("""
        SELECT * FROM rrf_search($1, $2, $3, $4, 50)
    """, "test_user", "test_app", query, query_embedding)

    # éªŒè¯ RRF åˆ†æ•°é€’å‡
    scores = [row["rrf_score"] for row in rows]
    assert scores == sorted(scores, reverse=True), "RRF scores should be descending"
    print(f"âœ… RRF Search: {len(rows)} results, scores correctly ordered")


async def test_iterative_scan(pool: asyncpg.Pool):
    """æµ‹è¯•é«˜è¿‡æ»¤æ¯”åœºæ™¯çš„è¿­ä»£æ‰«æ"""
    # é…ç½®è¿­ä»£æ‰«æ
    await pool.execute("SET hnsw.iterative_scan = relaxed_order")
    await pool.execute("SET hnsw.max_scan_tuples = 20000")
    await pool.execute("SET hnsw.ef_search = 200")

    query_embedding = list(np.random.randn(1536).astype(float))

    # ä½¿ç”¨ç¨€æœ‰ç”¨æˆ· ID (å‡è®¾ < 1% æ•°æ®)
    rows = await pool.fetch("""
        SELECT id FROM memories
        WHERE user_id = 'rare_user_001'
        ORDER BY embedding <=> $1
        LIMIT 10
    """, query_embedding)

    # éªŒè¯ä»èƒ½è¿”å›ç»“æœ (è¿­ä»£æ‰«æç”Ÿæ•ˆ)
    # æ³¨ï¼šå¦‚æœæ•°æ®åº“ä¸­æ— æ­¤ç”¨æˆ·ï¼Œæµ‹è¯•ä¼šè·³è¿‡
    print(f"âœ… Iterative Scan: {len(rows)} results (rare user filter)")


async def main():
    pool = await asyncpg.create_pool("postgresql://localhost/agent_db")

    print("=== Phase 3 Acceptance Tests ===\n")

    await test_hybrid_search(pool)
    await test_rrf_search(pool)
    await test_iterative_scan(pool)

    print("\n=== All Tests Passed ===")
    await pool.close()


if __name__ == "__main__":
    asyncio.run(main())
```

---

## 6. äº¤ä»˜ç‰©æ¸…å•

| ç±»åˆ«         | æ–‡ä»¶è·¯å¾„                                                | æè¿°                        | ä»»åŠ¡ ID |
| :----------- | :------------------------------------------------------ | :-------------------------- | :------ |
| **æ–‡æ¡£**     | `docs/practice/030-the-perception.md`                   | æœ¬å®æ–½æ–¹æ¡ˆæ–‡æ¡£              | P3-3-1  |
| **Schema**   | `docs/practice/schema/perception_schema.sql`            | Perception Schema æ‰©å±•è„šæœ¬  | P3-1-1  |
| **SQL å‡½æ•°** | `docs/practice/engine/perception/hybrid_search.sql`     | One-Shot Hybrid Search å‡½æ•° | P3-1-5  |
| **SQL å‡½æ•°** | `docs/practice/engine/perception/rrf_search.sql`        | RRF èåˆæ£€ç´¢å‡½æ•°            | P3-1-7  |
| **Python**   | `docs/practice/engine/perception/rrf_fusion.py`         | Python RRF å®ç°             | P3-1-8  |
| **Python**   | `docs/practice/engine/perception/reranker.py`           | Cross-Encoder Reranker å®ç° | P3-3-3  |
| **Python**   | `docs/practice/engine/perception/benchmark.py`          | æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬            | P3-2-4  |
| **Python**   | `docs/practice/engine/perception/generate_test_data.py` | æµ‹è¯•æ•°æ®ç”Ÿæˆè„šæœ¬            | P3-2-1  |
| **æµ‹è¯•**     | `docs/practice/tests/perception/test_hybrid_search.py`  | Hybrid Search å•å…ƒæµ‹è¯•      | P3-3-4  |
| **æµ‹è¯•**     | `docs/practice/tests/perception/test_reranker.py`       | Reranker å•å…ƒæµ‹è¯•           | P3-3-4  |

---

## 7. å‚è€ƒèµ„æ–™

<a id="ref1"></a>1. Google. (2025). _Vertex AI RAG Engine_. Google Cloud Documentation. [Link](https://cloud.google.com/vertex-ai/generative-ai/docs/rag-overview)

<a id="ref2"></a>2. Anthropic. (2025). _Hybrid Search for RAG_. Anthropic Blog. [Link](https://docs.anthropic.com/en/docs/build-with-claude/retrieval)

<a id="ref3"></a>3. Cormack, G. V., Clarke, C. L., & Buettcher, S. (2009). _Reciprocal Rank Fusion outperforms Condorcet and individual Rank Learning Methods_. SIGIR.

<a id="ref4"></a>4. pgvector. (2024). _Iterative Index Scans_. pgvector Documentation. [Link](https://github.com/pgvector/pgvector#iterative-index-scans)

<a id="ref5"></a>5. BAAI. (2024). _BGE Reranker_. Hugging Face. [Link](https://huggingface.co/BAAI/bge-reranker-base)
